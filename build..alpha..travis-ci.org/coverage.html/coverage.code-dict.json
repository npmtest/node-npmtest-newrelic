{"/home/travis/build/npmtest/node-npmtest-newrelic/test.js":"/* istanbul instrument in package npmtest_newrelic */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        switch (local.modeJs) {\n        // re-init local from window.local\n        case 'browser':\n            local = local.global.utility2.objectSetDefault(\n                local.global.utility2_rollup || local.global.local,\n                local.global.utility2\n            );\n            break;\n        // re-init local from example.js\n        case 'node':\n            local = (local.global.utility2_rollup || require('utility2'))\n                .requireExampleJsFromReadme();\n            break;\n        }\n        // export local\n        local.global.local = local;\n    }());\n\n\n\n    // run shared js-env code - function\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - function\n    case 'browser':\n        break;\n\n\n\n    // run node js-env code - function\n    case 'node':\n        break;\n    }\n\n\n\n    // run shared js-env code - post-init\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - post-init\n    case 'browser':\n        // run tests\n        local.nop(local.modeTest &&\n            document.querySelector('#testRunButton1') &&\n            document.querySelector('#testRunButton1').click());\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        local.testCase_buildApidoc_default = local.testCase_buildApidoc_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApidoc's default handling-behavior-behavior\n         */\n            options = { modulePathList: module.paths };\n            local.buildApidoc(options, onError);\n        };\n\n        local.testCase_buildApp_default = local.testCase_buildApp_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApp's default handling-behavior-behavior\n         */\n            local.testCase_buildReadme_default(options, local.onErrorThrow);\n            local.testCase_buildLib_default(options, local.onErrorThrow);\n            local.testCase_buildTest_default(options, local.onErrorThrow);\n            local.testCase_buildCustomOrg_default(options, local.onErrorThrow);\n            options = [];\n            local.buildApp(options, onError);\n        };\n\n        local.testCase_buildCustomOrg_default = local.testCase_buildCustomOrg_default ||\n            function (options, onError) {\n            /*\n             * this function will test buildCustomOrg's default handling-behavior\n             */\n                options = {};\n                local.buildCustomOrg(options, onError);\n            };\n\n        local.testCase_buildLib_default = local.testCase_buildLib_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildLib's default handling-behavior\n         */\n            options = {};\n            local.buildLib(options, onError);\n        };\n\n        local.testCase_buildReadme_default = local.testCase_buildReadme_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildReadme's default handling-behavior-behavior\n         */\n            options = {};\n            local.buildReadme(options, onError);\n        };\n\n        local.testCase_buildTest_default = local.testCase_buildTest_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildTest's default handling-behavior\n         */\n            options = {};\n            local.buildTest(options, onError);\n        };\n\n        local.testCase_webpage_default = local.testCase_webpage_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test webpage's default handling-behavior\n         */\n            options = { modeCoverageMerge: true, url: local.serverLocalHost + '?modeTest=1' };\n            local.browserTest(options, onError);\n        };\n\n        // run test-server\n        local.testRunServer(local);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-newrelic/lib.npmtest_newrelic.js":"/* istanbul instrument in package npmtest_newrelic */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || local;\n        // init lib\n        local.local = local.npmtest_newrelic = local;\n        // init exports\n        if (local.modeJs === 'browser') {\n            local.global.utility2_npmtest_newrelic = local;\n        } else {\n            module.exports = local;\n            module.exports.__dirname = __dirname;\n            module.exports.module = module;\n        }\n    }());\n}());\n","/home/travis/build/npmtest/node-npmtest-newrelic/example.js":"/*\nexample.js\n\nquickstart example\n\ninstruction\n    1. save this script as example.js\n    2. run the shell command:\n        $ npm install npmtest-newrelic && PORT=8081 node example.js\n    3. play with the browser-demo on http://127.0.0.1:8081\n*/\n\n\n\n/* istanbul instrument in package npmtest_newrelic */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || (local.modeJs === 'browser'\n            ? local.global.utility2_npmtest_newrelic\n            : global.utility2_moduleExports);\n        // export local\n        local.global.local = local;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // post-init\n    // run browser js-env code - post-init\n    /* istanbul ignore next */\n    case 'browser':\n        local.testRunBrowser = function (event) {\n            if (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('onreset'))) {\n                // reset output\n                Array.from(\n                    document.querySelectorAll('body > .resettable')\n                ).forEach(function (element) {\n                    switch (element.tagName) {\n                    case 'INPUT':\n                    case 'TEXTAREA':\n                        element.value = '';\n                        break;\n                    default:\n                        element.textContent = '';\n                    }\n                });\n            }\n            switch (event && event.currentTarget && event.currentTarget.id) {\n            case 'testRunButton1':\n                // show tests\n                if (document.querySelector('#testReportDiv1').style.display === 'none') {\n                    document.querySelector('#testReportDiv1').style.display = 'block';\n                    document.querySelector('#testRunButton1').textContent =\n                        'hide internal test';\n                    local.modeTest = true;\n                    local.testRunDefault(local);\n                // hide tests\n                } else {\n                    document.querySelector('#testReportDiv1').style.display = 'none';\n                    document.querySelector('#testRunButton1').textContent = 'run internal test';\n                }\n                break;\n            // custom-case\n            default:\n                break;\n            }\n            if (document.querySelector('#inputTextareaEval1') && (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('oneval')))) {\n                // try to eval input-code\n                try {\n                    /*jslint evil: true*/\n                    eval(document.querySelector('#inputTextareaEval1').value);\n                } catch (errorCaught) {\n                    console.error(errorCaught);\n                }\n            }\n        };\n        // log stderr and stdout to #outputTextareaStdout1\n        ['error', 'log'].forEach(function (key) {\n            console[key + '_original'] = console[key];\n            console[key] = function () {\n                var element;\n                console[key + '_original'].apply(console, arguments);\n                element = document.querySelector('#outputTextareaStdout1');\n                if (!element) {\n                    return;\n                }\n                // append text to #outputTextareaStdout1\n                element.value += Array.from(arguments).map(function (arg) {\n                    return typeof arg === 'string'\n                        ? arg\n                        : JSON.stringify(arg, null, 4);\n                }).join(' ') + '\\n';\n                // scroll textarea to bottom\n                element.scrollTop = element.scrollHeight;\n            };\n        });\n        // init event-handling\n        ['change', 'click', 'keyup'].forEach(function (event) {\n            Array.from(document.querySelectorAll('.on' + event)).forEach(function (element) {\n                element.addEventListener(event, local.testRunBrowser);\n            });\n        });\n        // run tests\n        local.testRunBrowser();\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        // export local\n        module.exports = local;\n        // require modules\n        local.fs = require('fs');\n        local.http = require('http');\n        local.url = require('url');\n        // init assets\n        local.assetsDict = local.assetsDict || {};\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.index.template.html'] = '\\\n<!doctype html>\\n\\\n<html lang=\"en\">\\n\\\n<head>\\n\\\n<meta charset=\"UTF-8\">\\n\\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\\n<title>{{env.npm_package_name}} (v{{env.npm_package_version}})</title>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n    box-sizing: false,\\n\\\n    universal-selector: false\\n\\\n*/\\n\\\n* {\\n\\\n    box-sizing: border-box;\\n\\\n}\\n\\\nbody {\\n\\\n    background: #dde;\\n\\\n    font-family: Arial, Helvetica, sans-serif;\\n\\\n    margin: 2rem;\\n\\\n}\\n\\\nbody > * {\\n\\\n    margin-bottom: 1rem;\\n\\\n}\\n\\\n.utility2FooterDiv {\\n\\\n    margin-top: 20px;\\n\\\n    text-align: center;\\n\\\n}\\n\\\n</style>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n*/\\n\\\ntextarea {\\n\\\n    font-family: monospace;\\n\\\n    height: 10rem;\\n\\\n    width: 100%;\\n\\\n}\\n\\\ntextarea[readonly] {\\n\\\n    background: #ddd;\\n\\\n}\\n\\\n</style>\\n\\\n</head>\\n\\\n<body>\\n\\\n<!-- utility2-comment\\n\\\n<div id=\"ajaxProgressDiv1\" style=\"background: #d00; height: 2px; left: 0; margin: 0; padding: 0; position: fixed; top: 0; transition: background 0.5s, width 1.5s; width: 25%;\"></div>\\n\\\nutility2-comment -->\\n\\\n<h1>\\n\\\n<!-- utility2-comment\\n\\\n    <a\\n\\\n        {{#if env.npm_package_homepage}}\\n\\\n        href=\"{{env.npm_package_homepage}}\"\\n\\\n        {{/if env.npm_package_homepage}}\\n\\\n        target=\"_blank\"\\n\\\n    >\\n\\\nutility2-comment -->\\n\\\n        {{env.npm_package_name}} (v{{env.npm_package_version}})\\n\\\n<!-- utility2-comment\\n\\\n    </a>\\n\\\nutility2-comment -->\\n\\\n</h1>\\n\\\n<h3>{{env.npm_package_description}}</h3>\\n\\\n<!-- utility2-comment\\n\\\n<h4><a download href=\"assets.app.js\">download standalone app</a></h4>\\n\\\n<button class=\"onclick onreset\" id=\"testRunButton1\">run internal test</button><br>\\n\\\n<div id=\"testReportDiv1\" style=\"display: none;\"></div>\\n\\\nutility2-comment -->\\n\\\n\\n\\\n\\n\\\n\\n\\\n<label>stderr and stdout</label>\\n\\\n<textarea class=\"resettable\" id=\"outputTextareaStdout1\" readonly></textarea>\\n\\\n<!-- utility2-comment\\n\\\n{{#if isRollup}}\\n\\\n<script src=\"assets.app.js\"></script>\\n\\\n{{#unless isRollup}}\\n\\\nutility2-comment -->\\n\\\n<script src=\"assets.utility2.rollup.js\"></script>\\n\\\n<script src=\"jsonp.utility2._stateInit?callback=window.utility2._stateInit\"></script>\\n\\\n<script src=\"assets.npmtest_newrelic.rollup.js\"></script>\\n\\\n<script src=\"assets.example.js\"></script>\\n\\\n<script src=\"assets.test.js\"></script>\\n\\\n<!-- utility2-comment\\n\\\n{{/if isRollup}}\\n\\\nutility2-comment -->\\n\\\n<div class=\"utility2FooterDiv\">\\n\\\n    [ this app was created with\\n\\\n    <a href=\"https://github.com/kaizhu256/node-utility2\" target=\"_blank\">utility2</a>\\n\\\n    ]\\n\\\n</div>\\n\\\n</body>\\n\\\n</html>\\n\\\n';\n        /* jslint-ignore-end */\n        if (local.templateRender) {\n            local.assetsDict['/'] = local.templateRender(\n                local.assetsDict['/assets.index.template.html'],\n                {\n                    env: local.objectSetDefault(local.env, {\n                        npm_package_description: 'the greatest app in the world!',\n                        npm_package_name: 'my-app',\n                        npm_package_nameAlias: 'my_app',\n                        npm_package_version: '0.0.1'\n                    })\n                }\n            );\n        } else {\n            local.assetsDict['/'] = local.assetsDict['/assets.index.template.html']\n                .replace((/\\{\\{env\\.(\\w+?)\\}\\}/g), function (match0, match1) {\n                    // jslint-hack\n                    String(match0);\n                    switch (match1) {\n                    case 'npm_package_description':\n                        return 'the greatest app in the world!';\n                    case 'npm_package_name':\n                        return 'my-app';\n                    case 'npm_package_nameAlias':\n                        return 'my_app';\n                    case 'npm_package_version':\n                        return '0.0.1';\n                    }\n                });\n        }\n        // run the cli\n        if (local.global.utility2_rollup || module !== require.main) {\n            break;\n        }\n        local.assetsDict['/assets.example.js'] =\n            local.assetsDict['/assets.example.js'] ||\n            local.fs.readFileSync(__filename, 'utf8');\n        local.assetsDict['/assets.npmtest_newrelic.rollup.js'] =\n            local.assetsDict['/assets.npmtest_newrelic.rollup.js'] ||\n            local.fs.readFileSync(\n                // buildCustomOrg-hack\n                local.npmtest_newrelic.__dirname +\n                    '/lib.npmtest_newrelic.js',\n                'utf8'\n            ).replace((/^#!/), '//');\n        local.assetsDict['/favicon.ico'] = local.assetsDict['/favicon.ico'] || '';\n        // if $npm_config_timeout_exit exists,\n        // then exit this process after $npm_config_timeout_exit ms\n        if (Number(process.env.npm_config_timeout_exit)) {\n            setTimeout(process.exit, Number(process.env.npm_config_timeout_exit));\n        }\n        // start server\n        if (local.global.utility2_serverHttp1) {\n            break;\n        }\n        process.env.PORT = process.env.PORT || '8081';\n        console.error('server starting on port ' + process.env.PORT);\n        local.http.createServer(function (request, response) {\n            request.urlParsed = local.url.parse(request.url);\n            if (local.assetsDict[request.urlParsed.pathname] !== undefined) {\n                response.end(local.assetsDict[request.urlParsed.pathname]);\n                return;\n            }\n            response.statusCode = 404;\n            response.end();\n        }).listen(process.env.PORT);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/index.js":"'use strict'\n\nvar logger = require('./lib/logger.js')\nvar semver = require('semver')\n\nvar message\nvar agent\n\nvar agentVersion = require('./package.json').version\nlogger.info(\n  \"Using New Relic for Node.js. Agent version: %s; Node version: %s.\",\n  agentVersion, process.version\n)\n\nif (require.cache.__NR_cache) {\n  logger.warn(\n    'Attempting to load a second copy of newrelic from %s, using cache instead',\n    __dirname\n  )\n  module.exports = require.cache.__NR_cache\n} else {\n  initialize()\n}\n\nfunction initialize() {\n  logger.debug(\n    'Loading agent from %s',\n    __dirname\n  )\n\n  try {\n    logger.debug(\"Process was running %s seconds before agent was loaded.\",\n                 process.uptime())\n    // Technically we run on 0.6, until we verify there are 0 users on 0.6, we\n    // should leave this code doing a check against 0.6, but then advise that\n    // people upgrade to one of our officially supported version (0.8 and higher)\n    if (semver.satisfies(process.version, '<0.6.0')) {\n      message = \"New Relic for Node.js requires a version of Node equal to or\\n\" +\n                \"greater than 0.8.0. Not starting!\"\n\n      logger.error(message)\n      throw new Error(message)\n    }\n\n    logger.debug(\"Current working directory at module load is %s.\", process.cwd())\n    logger.debug(\"Process title is %s.\", process.title)\n    logger.debug(\"Application was invoked as %s.\", process.argv.join(' '))\n\n    var config = require('./lib/config.js').getOrCreateInstance()\n\n    // Get the initialized logger as we likely have a bootstrap logger which\n    // just pipes to stdout.\n    logger = require('./lib/logger.js')\n\n    if (!config || !config.agent_enabled) {\n      logger.info(\"Module not enabled in configuration; not starting.\")\n    } else {\n      /* Only load the rest of the module if configuration is available and the\n       * configurator didn't throw.\n       *\n       * The agent must be a singleton, or else module loading will be patched\n       * multiple times, with undefined results. New Relic's instrumentation\n       * can't be enabled or disabled without an application restart.\n       */\n      var Agent = require('./lib/agent.js')\n      agent = new Agent(config)\n      var appNames = agent.config.applications()\n\n      if (config.logging.diagnostics) {\n        logger.warn(\n          'Diagnostics logging is enabled, this may cause significant overhead.'\n        )\n      }\n\n      if (appNames.length < 1) {\n        message = \"New Relic requires that you name this application!\\n\" +\n                  \"Set app_name in your newrelic.js file or set environment variable\\n\" +\n                  \"NEW_RELIC_APP_NAME. Not starting!\"\n        logger.error(message)\n        throw new Error(message)\n      }\n\n      var shimmer = require('./lib/shimmer.js')\n      shimmer.patchModule(agent)\n      shimmer.bootstrapInstrumentation(agent)\n\n      agent.start(function cb_start(error) {\n        if (!error) {\n          return logger.debug(\"New Relic for Node.js is connected to New Relic.\")\n        }\n\n        var errorMessage = \"New Relic for Node.js halted startup due to an error:\"\n        logger.error(error, errorMessage)\n\n        console.error(errorMessage)\n        console.error(error.stack)\n      })\n    }\n  } catch (error) {\n    message = \"New Relic for Node.js was unable to bootstrap itself due to an error:\"\n    logger.error(error, message)\n\n    console.error(message)\n    console.error(error.stack)\n  }\n\n  var API\n  if (agent) {\n    API = require('./api.js')\n  } else {\n    API = require('./stub_api.js')\n  }\n\n  require.cache.__NR_cache = module.exports = new API(agent)\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/logger.js":"'use strict'\n\nvar Logger = require('./util/logger')\nvar fs = require('fs')\n\n// create bootstrapping logger\nmodule.exports = new Logger({\n  name: 'newrelic_bootstrap',\n  stream: process.stdout,\n  level: 'info'\n})\n\n/**\n * Don't load config.js until this point, because it requires this\n * module, and if it gets loaded too early, module.exports will have no\n * value.\n */\nvar config = require('./config.js').getOrCreateInstance()\nif (config) {\n  var options = {\n    name: 'newrelic',\n    level: config.logging.level,\n    enabled: config.logging.enabled\n  }\n\n  // create the \"real\" logger\n  module.exports = new Logger(options)\n\n  if (config.logging.enabled) {\n    var stream\n    switch (config.logging.filepath) {\n      case 'stdout':\n        stream = process.stdout\n        break\n\n      case 'stderr':\n        stream = process.stderr\n        break\n\n      default:\n        stream = fs.createWriteStream(config.logging.filepath, {flags: 'a+'})\n        stream.on('error', function logStreamOnError(err) {\n          /* eslint-disable no-console */\n          // Since our normal logging didn't work, dump this to stderr.\n          console.error('New Relic failed to open log file ' + config.logging.filepath)\n          console.error(err)\n          /* eslint-enable no-console */\n        })\n    }\n    module.exports.pipe(stream)\n  }\n\n  // now tell the config module to switch to the real logger\n  config.setLogger(module.exports)\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/util/logger.js":"'use strict'\n\nvar stringifySync = require('./safe-json').stringifySync\nvar util = require('util')\nvar Readable = require('readable-stream')\nvar os = require('os')\n\nmodule.exports = Logger\n\nvar LEVELS = {\n  'trace': 10,\n  'debug': 20,\n  'info': 30,\n  'warn': 40,\n  'error': 50,\n  'fatal': 60\n}\n\nutil.inherits(Logger, Readable)\n\nfunction Logger(options, extra) {\n  if (!(this instanceof Logger)) {\n    return new Logger(options, extra)\n  }\n\n  Readable.call(this)\n  var passedInLevel = this.coerce(options.level)\n  this.options = {\n    _level: passedInLevel,\n    enabled: options.enabled === undefined ? true : options.enabled\n  }\n  this.name = options.name\n  this.hostname = options.hostname || os.hostname()\n  this.extra = extra || {}\n  this.buffer = ''\n  this.reading = false\n  if (options.stream) {\n    this.pipe(options.stream)\n  }\n}\n\nvar loggingFunctions = {}\n\nObject.keys(LEVELS).forEach(function buildLevel(_level) {\n  function log(extra) {\n    var level = Logger.prototype.coerce(LEVELS[_level])\n    if (!this.options.enabled) return false\n    if (level < this.options._level) return false\n\n    var has_extra = typeof extra === 'object'\n    var args = Array.prototype.slice.call(arguments, has_extra ? 1 : 0)\n    return this.write(level, args, has_extra ? extra : null)\n  }\n\n  loggingFunctions[_level] = function checkLevel() {\n    log.apply(this, arguments)\n  }\n\n  var seenMessages = {}\n  loggingFunctions[_level + 'Once'] = function logOnce(key) {\n    if (typeof key !== 'string') {\n      this.debug('Attempted to key on a non-string in ' + _level + 'Once: ' + key)\n      return\n    }\n\n    var level = Logger.prototype.coerce(LEVELS[_level])\n    if (!this.options.enabled) return false\n    if (level < this.options._level) return false\n\n    if (seenMessages[key] !== true) {\n      var args = Array.prototype.slice.call(arguments, 1)\n      var writeSuccessful = log.apply(this, args)\n\n      if (writeSuccessful) {\n        seenMessages[key] = true\n      }\n    }\n  }\n\n  var seenPerInterval = {}\n  loggingFunctions[_level + 'OncePer'] = function logOncePer(key, interval) {\n    if (typeof key !== 'string') {\n      this.debug('Attempted to key on a non-string in ' + _level + 'Once: ' + key)\n      return\n    }\n\n    var level = Logger.prototype.coerce(LEVELS[_level])\n    if (!this.options.enabled) return false\n    if (level < this.options._level) return false\n\n    if (seenPerInterval[key] !== true) {\n      var args = Array.prototype.slice.call(arguments, 2)\n      var writeSuccessful = log.apply(this, args)\n\n      if (writeSuccessful) {\n        seenPerInterval[key] = true\n\n        var clearSeen = setTimeout(function clearKey() {\n          delete seenPerInterval[key]\n        }, interval)\n\n        if (clearSeen.unref !== undefined) {\n          clearSeen.unref()\n        }\n      }\n    }\n  }\n})\n\nutil._extend(Logger.prototype, loggingFunctions)\n\nLogger.prototype.coerce = function coerce(value) {\n  if (!isNaN(parseInt(value, 10)) && isFinite(value)) {\n    // value is numeric\n    if (value < 10) value = 10\n    if (value > 60) value = 60\n\n    return value\n  }\n  return LEVELS[value] || 50\n}\n\nLogger.prototype.child = function child(extra) {\n  var childLogger = Object.create(loggingFunctions)\n\n  childLogger.extra = util._extend({}, this.extra)\n  util._extend(childLogger.extra, extra)\n\n  var parent = this\n  childLogger.options = parent.options\n\n  childLogger.write = function write(level, args, extra) {\n    extra = getPropertiesToLog(extra)\n    var selfExtra = util._extend({}, this.extra)\n\n    extra = util._extend(selfExtra, extra)\n    return parent.write(level, args, extra)\n  }\n\n  childLogger.setEnabled = Logger.prototype.setEnabled\n  childLogger.child = Logger.prototype.child\n\n  return childLogger\n}\n\nLogger.prototype.level = function level(lvl) {\n  this.options._level = this.coerce(lvl)\n}\n\nLogger.prototype.setEnabled = function setEnabled(enabled) {\n  if (typeof enabled === 'boolean') {\n    this.options.enabled = enabled\n  }\n}\n\nLogger.prototype._read = function _read() {\n  if (this.buffer.length !== 0) {\n    this.reading = this.push(this.buffer)\n    this.buffer = ''\n  } else {\n    this.reading = true\n  }\n}\n\n/**\n * For performance reasons we do not support %j because we will have\n * already converted the objects to strings.\n * Returns a boolean representing the status of the write\n * (success/failure)\n */\nLogger.prototype.write = function write(level, args, extra) {\n  for (var i = 0, l = args.length; i < l; ++i) {\n    if (typeof args[i] === 'function') {\n      args[i] = args[i].valueOf()\n    } else if (typeof args[i] === 'object') {\n      args[i] = stringifySync(args[i])\n    }\n  }\n\n  var entry = new Entry(this, level, util.format.apply(util, args))\n\n  util._extend(entry, this.extra)\n  util._extend(entry, getPropertiesToLog(extra))\n\n  if (this.reading) {\n    this.reading = this.push(stringifySync(entry) + '\\n')\n  } else {\n    this.buffer += stringifySync(entry) + '\\n'\n  }\n  return true\n}\n\nfunction Entry(logger, level, msg) {\n  this.v = 0\n  this.level = level\n  this.name = logger.name\n  this.hostname = logger.hostname\n  this.pid = process.pid\n  this.time = new Date().toISOString()\n  this.msg = msg\n}\n\nfunction getPropertiesToLog(extra) {\n  var obj = util._extend({}, extra)\n  // Error properties (message, stack) are not enumerable, so getting them directly\n  if (extra instanceof Error) {\n    var names = Object.getOwnPropertyNames(extra)\n    if (names) {\n      for (var i = 0; i < names.length; i++) {\n        obj[names[i]] = extra[names[i]]\n      }\n    }\n  }\n  return obj\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/util/safe-json.js":"'use strict'\n\nvar stringifySafe = require('json-stringify-safe')\n\nmodule.exports = {\n  parse: function parseAsync(str, cb) {\n    try {\n      cb(null, JSON.parse(str))\n    } catch (err) {\n      cb(err, null)\n    }\n  },\n\n  stringify: function stringifyAsync(obj, cb) {\n    try {\n      cb(null, stringifySafe(obj))\n    } catch (err) {\n      cb(err, '[UNPARSABLE OBJECT]')\n    }\n  },\n\n  stringifySync: function stringifySync(obj, returnVal) {\n    try {\n      return stringifySafe(obj)\n    } catch (err) {\n      return returnVal || '[UNPARSABLE OBJECT]'\n    }\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/json-stringify-safe/stringify.js":"exports = module.exports = stringify\nexports.getSerialize = serializer\n\nfunction stringify(obj, replacer, spaces, cycleReplacer) {\n  return JSON.stringify(obj, serializer(replacer, cycleReplacer), spaces)\n}\n\nfunction serializer(replacer, cycleReplacer) {\n  var stack = [], keys = []\n\n  if (cycleReplacer == null) cycleReplacer = function(key, value) {\n    if (stack[0] === value) return \"[Circular ~]\"\n    return \"[Circular ~.\" + keys.slice(0, stack.indexOf(value)).join(\".\") + \"]\"\n  }\n\n  return function(key, value) {\n    if (stack.length > 0) {\n      var thisPos = stack.indexOf(this)\n      ~thisPos ? stack.splice(thisPos + 1) : stack.push(this)\n      ~thisPos ? keys.splice(thisPos, Infinity, key) : keys.push(key)\n      if (~stack.indexOf(value)) value = cycleReplacer.call(this, key, value)\n    }\n    else stack.push(value)\n\n    return replacer == null ? value : replacer.call(this, key, value)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/readable-stream/readable.js":"exports = module.exports = require('./lib/_stream_readable.js');\nexports.Stream = require('stream');\nexports.Readable = exports;\nexports.Writable = require('./lib/_stream_writable.js');\nexports.Duplex = require('./lib/_stream_duplex.js');\nexports.Transform = require('./lib/_stream_transform.js');\nexports.PassThrough = require('./lib/_stream_passthrough.js');\nif (!process.browser && process.env.READABLE_STREAM === 'disable') {\n  module.exports = require('stream');\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/readable-stream/lib/_stream_readable.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n\n/*<replacement>*/\nvar Buffer = require('buffer').Buffer;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\nvar EE = require('events').EventEmitter;\n\n/*<replacement>*/\nif (!EE.listenerCount) EE.listenerCount = function(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\nvar Stream = require('stream');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar StringDecoder;\n\n\n/*<replacement>*/\nvar debug = require('util');\nif (debug && debug.debuglog) {\n  debug = debug.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\n\nutil.inherits(Readable, Stream);\n\nfunction ReadableState(options, stream) {\n  var Duplex = require('./_stream_duplex');\n\n  options = options || {};\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var defaultHwm = options.objectMode ? 16 : 16 * 1024;\n  this.highWaterMark = (hwm || hwm === 0) ? hwm : defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = ~~this.highWaterMark;\n\n  this.buffer = [];\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (stream instanceof Duplex)\n    this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // when piping, we only care about 'readable' events that happen\n  // after read()ing all the bytes and not getting any pushback.\n  this.ranOut = false;\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder)\n      StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  var Duplex = require('./_stream_duplex');\n\n  if (!(this instanceof Readable))\n    return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  Stream.call(this);\n}\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function(chunk, encoding) {\n  var state = this._readableState;\n\n  if (util.isString(chunk) && !state.objectMode) {\n    encoding = encoding || state.defaultEncoding;\n    if (encoding !== state.encoding) {\n      chunk = new Buffer(chunk, encoding);\n      encoding = '';\n    }\n  }\n\n  return readableAddChunk(this, state, chunk, encoding, false);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function(chunk) {\n  var state = this._readableState;\n  return readableAddChunk(this, state, chunk, '', true);\n};\n\nfunction readableAddChunk(stream, state, chunk, encoding, addToFront) {\n  var er = chunkInvalid(state, chunk);\n  if (er) {\n    stream.emit('error', er);\n  } else if (util.isNullOrUndefined(chunk)) {\n    state.reading = false;\n    if (!state.ended)\n      onEofChunk(stream, state);\n  } else if (state.objectMode || chunk && chunk.length > 0) {\n    if (state.ended && !addToFront) {\n      var e = new Error('stream.push() after EOF');\n      stream.emit('error', e);\n    } else if (state.endEmitted && addToFront) {\n      var e = new Error('stream.unshift() after end event');\n      stream.emit('error', e);\n    } else {\n      if (state.decoder && !addToFront && !encoding)\n        chunk = state.decoder.write(chunk);\n\n      if (!addToFront)\n        state.reading = false;\n\n      // if we want the data now, just emit it.\n      if (state.flowing && state.length === 0 && !state.sync) {\n        stream.emit('data', chunk);\n        stream.read(0);\n      } else {\n        // update the buffer info.\n        state.length += state.objectMode ? 1 : chunk.length;\n        if (addToFront)\n          state.buffer.unshift(chunk);\n        else\n          state.buffer.push(chunk);\n\n        if (state.needReadable)\n          emitReadable(stream);\n      }\n\n      maybeReadMore(stream, state);\n    }\n  } else if (!addToFront) {\n    state.reading = false;\n  }\n\n  return needMoreData(state);\n}\n\n\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended &&\n         (state.needReadable ||\n          state.length < state.highWaterMark ||\n          state.length === 0);\n}\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function(enc) {\n  if (!StringDecoder)\n    StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 128MB\nvar MAX_HWM = 0x800000;\nfunction roundUpToNextPowerOf2(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2\n    n--;\n    for (var p = 1; p < 32; p <<= 1) n |= n >> p;\n    n++;\n  }\n  return n;\n}\n\nfunction howMuchToRead(n, state) {\n  if (state.length === 0 && state.ended)\n    return 0;\n\n  if (state.objectMode)\n    return n === 0 ? 0 : 1;\n\n  if (isNaN(n) || util.isNull(n)) {\n    // only flow one buffer at a time\n    if (state.flowing && state.buffer.length)\n      return state.buffer[0].length;\n    else\n      return state.length;\n  }\n\n  if (n <= 0)\n    return 0;\n\n  // If we're asking for more than the target buffer level,\n  // then raise the water mark.  Bump up to the next highest\n  // power of 2, to prevent increasing it excessively in tiny\n  // amounts.\n  if (n > state.highWaterMark)\n    state.highWaterMark = roundUpToNextPowerOf2(n);\n\n  // don't have that much.  return null, unless we've ended.\n  if (n > state.length) {\n    if (!state.ended) {\n      state.needReadable = true;\n      return 0;\n    } else\n      return state.length;\n  }\n\n  return n;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function(n) {\n  debug('read', n);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (!util.isNumber(n) || n > 0)\n    state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 &&\n      state.needReadable &&\n      (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended)\n      endReadable(this);\n    else\n      emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0)\n      endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  }\n\n  if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0)\n      state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n  }\n\n  // If _read pushed data synchronously, then `reading` will be false,\n  // and we need to re-evaluate how much data we can return to the user.\n  if (doRead && !state.reading)\n    n = howMuchToRead(nOrig, state);\n\n  var ret;\n  if (n > 0)\n    ret = fromList(n, state);\n  else\n    ret = null;\n\n  if (util.isNull(ret)) {\n    state.needReadable = true;\n    n = 0;\n  }\n\n  state.length -= n;\n\n  // If we have nothing in the buffer, then we want to know\n  // as soon as we *do* get something into the buffer.\n  if (state.length === 0 && !state.ended)\n    state.needReadable = true;\n\n  // If we tried to read() past the EOF, then emit end on the next tick.\n  if (nOrig !== n && state.ended && state.length === 0)\n    endReadable(this);\n\n  if (!util.isNull(ret))\n    this.emit('data', ret);\n\n  return ret;\n};\n\nfunction chunkInvalid(state, chunk) {\n  var er = null;\n  if (!util.isBuffer(chunk) &&\n      !util.isString(chunk) &&\n      !util.isNullOrUndefined(chunk) &&\n      !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n\nfunction onEofChunk(stream, state) {\n  if (state.decoder && !state.ended) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync)\n      process.nextTick(function() {\n        emitReadable_(stream);\n      });\n    else\n      emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(function() {\n      maybeReadMore_(stream, state);\n    });\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended &&\n         state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;\n    else\n      len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function(n) {\n  this.emit('error', new Error('not implemented'));\n};\n\nReadable.prototype.pipe = function(dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) &&\n              dest !== process.stdout &&\n              dest !== process.stderr;\n\n  var endFn = doEnd ? onend : cleanup;\n  if (state.endEmitted)\n    process.nextTick(endFn);\n  else\n    src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable) {\n    debug('onunpipe');\n    if (readable === src) {\n      cleanup();\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', cleanup);\n    src.removeListener('data', ondata);\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain &&\n        (!dest._writableState || dest._writableState.needDrain))\n      ondrain();\n  }\n\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    var ret = dest.write(chunk);\n    if (false === ret) {\n      debug('false write response, pause',\n            src._readableState.awaitDrain);\n      src._readableState.awaitDrain++;\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EE.listenerCount(dest, 'error') === 0)\n      dest.emit('error', er);\n  }\n  // This is a brutally ugly hack to make sure that our error handler\n  // is attached before any userland ones.  NEVER DO THIS.\n  if (!dest._events || !dest._events.error)\n    dest.on('error', onerror);\n  else if (isArray(dest._events.error))\n    dest._events.error.unshift(onerror);\n  else\n    dest._events.error = [onerror, dest._events.error];\n\n\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function() {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain)\n      state.awaitDrain--;\n    if (state.awaitDrain === 0 && EE.listenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\n\nReadable.prototype.unpipe = function(dest) {\n  var state = this._readableState;\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0)\n    return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes)\n      return this;\n\n    if (!dest)\n      dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest)\n      dest.emit('unpipe', this);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++)\n      dests[i].emit('unpipe', this);\n    return this;\n  }\n\n  // try to find the right one.\n  var i = indexOf(state.pipes, dest);\n  if (i === -1)\n    return this;\n\n  state.pipes.splice(i, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1)\n    state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function(ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  // If listening to data, and it has not explicitly been paused,\n  // then call resume to start the flow of data on the next tick.\n  if (ev === 'data' && false !== this._readableState.flowing) {\n    this.resume();\n  }\n\n  if (ev === 'readable' && this.readable) {\n    var state = this._readableState;\n    if (!state.readableListening) {\n      state.readableListening = true;\n      state.emittedReadable = false;\n      state.needReadable = true;\n      if (!state.reading) {\n        var self = this;\n        process.nextTick(function() {\n          debug('readable nexttick read 0');\n          self.read(0);\n        });\n      } else if (state.length) {\n        emitReadable(this, state);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function() {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    if (!state.reading) {\n      debug('resume read 0');\n      this.read(0);\n    }\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    process.nextTick(function() {\n      resume_(stream, state);\n    });\n  }\n}\n\nfunction resume_(stream, state) {\n  state.resumeScheduled = false;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading)\n    stream.read(0);\n}\n\nReadable.prototype.pause = function() {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  if (state.flowing) {\n    do {\n      var chunk = stream.read();\n    } while (null !== chunk && state.flowing);\n  }\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function(stream) {\n  var state = this._readableState;\n  var paused = false;\n\n  var self = this;\n  stream.on('end', function() {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length)\n        self.push(chunk);\n    }\n\n    self.push(null);\n  });\n\n  stream.on('data', function(chunk) {\n    debug('wrapped data');\n    if (state.decoder)\n      chunk = state.decoder.write(chunk);\n    if (!chunk || !state.objectMode && !chunk.length)\n      return;\n\n    var ret = self.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (util.isFunction(stream[i]) && util.isUndefined(this[i])) {\n      this[i] = function(method) { return function() {\n        return stream[method].apply(stream, arguments);\n      }}(i);\n    }\n  }\n\n  // proxy certain important events.\n  var events = ['error', 'close', 'destroy', 'pause', 'resume'];\n  forEach(events, function(ev) {\n    stream.on(ev, self.emit.bind(self, ev));\n  });\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  self._read = function(n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return self;\n};\n\n\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\nfunction fromList(n, state) {\n  var list = state.buffer;\n  var length = state.length;\n  var stringMode = !!state.decoder;\n  var objectMode = !!state.objectMode;\n  var ret;\n\n  // nothing in the list, definitely empty.\n  if (list.length === 0)\n    return null;\n\n  if (length === 0)\n    ret = null;\n  else if (objectMode)\n    ret = list.shift();\n  else if (!n || n >= length) {\n    // read it all, truncate the array.\n    if (stringMode)\n      ret = list.join('');\n    else\n      ret = Buffer.concat(list, length);\n    list.length = 0;\n  } else {\n    // read just some of it.\n    if (n < list[0].length) {\n      // just take a part of the first list item.\n      // slice is the same for buffers and strings.\n      var buf = list[0];\n      ret = buf.slice(0, n);\n      list[0] = buf.slice(n);\n    } else if (n === list[0].length) {\n      // first list is a perfect match\n      ret = list.shift();\n    } else {\n      // complex case.\n      // we have enough to cover it, but it spans past the first buffer.\n      if (stringMode)\n        ret = '';\n      else\n        ret = new Buffer(n);\n\n      var c = 0;\n      for (var i = 0, l = list.length; i < l && c < n; i++) {\n        var buf = list[0];\n        var cpy = Math.min(n - c, buf.length);\n\n        if (stringMode)\n          ret += buf.slice(0, cpy);\n        else\n          buf.copy(ret, c, 0, cpy);\n\n        if (cpy < buf.length)\n          list[0] = buf.slice(cpy);\n        else\n          list.shift();\n\n        c += cpy;\n      }\n    }\n  }\n\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0)\n    throw new Error('endReadable called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    process.nextTick(function() {\n      // Check that we didn't get one last unshift.\n      if (!state.endEmitted && state.length === 0) {\n        state.endEmitted = true;\n        stream.readable = false;\n        stream.emit('end');\n      }\n    });\n  }\n}\n\nfunction forEach (xs, f) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    f(xs[i], i);\n  }\n}\n\nfunction indexOf (xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/readable-stream/lib/_stream_writable.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, cb), and it'll handle all\n// the drain event emission and buffering.\n\nmodule.exports = Writable;\n\n/*<replacement>*/\nvar Buffer = require('buffer').Buffer;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Stream = require('stream');\n\nutil.inherits(Writable, Stream);\n\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n}\n\nfunction WritableState(options, stream) {\n  var Duplex = require('./_stream_duplex');\n\n  options = options || {};\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var defaultHwm = options.objectMode ? 16 : 16 * 1024;\n  this.highWaterMark = (hwm || hwm === 0) ? hwm : defaultHwm;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (stream instanceof Duplex)\n    this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // cast to ints.\n  this.highWaterMark = ~~this.highWaterMark;\n\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function(er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.buffer = [];\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n}\n\nfunction Writable(options) {\n  var Duplex = require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, though they're not\n  // instanceof Writable, they're instanceof Readable.\n  if (!(this instanceof Writable) && !(this instanceof Duplex))\n    return new Writable(options);\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function() {\n  this.emit('error', new Error('Cannot pipe. Not readable.'));\n};\n\n\nfunction writeAfterEnd(stream, state, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  process.nextTick(function() {\n    cb(er);\n  });\n}\n\n// If we get something that is not a buffer, string, null, or undefined,\n// and we're not in objectMode, then that's an error.\n// Otherwise stream chunks are all considered to be of length=1, and the\n// watermarks determine how many objects to keep in the buffer, rather than\n// how many bytes or characters.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  if (!util.isBuffer(chunk) &&\n      !util.isString(chunk) &&\n      !util.isNullOrUndefined(chunk) &&\n      !state.objectMode) {\n    var er = new TypeError('Invalid non-string/buffer chunk');\n    stream.emit('error', er);\n    process.nextTick(function() {\n      cb(er);\n    });\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function(chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n\n  if (util.isFunction(encoding)) {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (util.isBuffer(chunk))\n    encoding = 'buffer';\n  else if (!encoding)\n    encoding = state.defaultEncoding;\n\n  if (!util.isFunction(cb))\n    cb = function() {};\n\n  if (state.ended)\n    writeAfterEnd(this, state, cb);\n  else if (validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function() {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function() {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing &&\n        !state.corked &&\n        !state.finished &&\n        !state.bufferProcessing &&\n        state.buffer.length)\n      clearBuffer(this, state);\n  }\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode &&\n      state.decodeStrings !== false &&\n      util.isString(chunk)) {\n    chunk = new Buffer(chunk, encoding);\n  }\n  return chunk;\n}\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, chunk, encoding, cb) {\n  chunk = decodeChunk(state, chunk, encoding);\n  if (util.isBuffer(chunk))\n    encoding = 'buffer';\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret)\n    state.needDrain = true;\n\n  if (state.writing || state.corked)\n    state.buffer.push(new WriteReq(chunk, encoding, cb));\n  else\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev)\n    stream._writev(chunk, state.onwrite);\n  else\n    stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  if (sync)\n    process.nextTick(function() {\n      state.pendingcb--;\n      cb(er);\n    });\n  else {\n    state.pendingcb--;\n    cb(er);\n  }\n\n  stream._writableState.errorEmitted = true;\n  stream.emit('error', er);\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er)\n    onwriteError(stream, state, sync, er, cb);\n  else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(stream, state);\n\n    if (!finished &&\n        !state.corked &&\n        !state.bufferProcessing &&\n        state.buffer.length) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      process.nextTick(function() {\n        afterWrite(stream, state, finished, cb);\n      });\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished)\n    onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n\n  if (stream._writev && state.buffer.length > 1) {\n    // Fast case, write everything using _writev()\n    var cbs = [];\n    for (var c = 0; c < state.buffer.length; c++)\n      cbs.push(state.buffer[c].callback);\n\n    // count the one we are adding, as well.\n    // TODO(isaacs) clean this up\n    state.pendingcb++;\n    doWrite(stream, state, true, state.length, state.buffer, '', function(err) {\n      for (var i = 0; i < cbs.length; i++) {\n        state.pendingcb--;\n        cbs[i](err);\n      }\n    });\n\n    // Clear buffer\n    state.buffer = [];\n  } else {\n    // Slow case, write chunks one-by-one\n    for (var c = 0; c < state.buffer.length; c++) {\n      var entry = state.buffer[c];\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        c++;\n        break;\n      }\n    }\n\n    if (c < state.buffer.length)\n      state.buffer = state.buffer.slice(c);\n    else\n      state.buffer.length = 0;\n  }\n\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function(chunk, encoding, cb) {\n  cb(new Error('not implemented'));\n\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function(chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (util.isFunction(chunk)) {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (util.isFunction(encoding)) {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (!util.isNullOrUndefined(chunk))\n    this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished)\n    endWritable(this, state, cb);\n};\n\n\nfunction needFinish(stream, state) {\n  return (state.ending &&\n          state.length === 0 &&\n          !state.finished &&\n          !state.writing);\n}\n\nfunction prefinish(stream, state) {\n  if (!state.prefinished) {\n    state.prefinished = true;\n    stream.emit('prefinish');\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(stream, state);\n  if (need) {\n    if (state.pendingcb === 0) {\n      prefinish(stream, state);\n      state.finished = true;\n      stream.emit('finish');\n    } else\n      prefinish(stream, state);\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished)\n      process.nextTick(cb);\n    else\n      stream.once('finish', cb);\n  }\n  state.ended = true;\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/readable-stream/lib/_stream_duplex.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) keys.push(key);\n  return keys;\n}\n/*</replacement>*/\n\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\nforEach(objectKeys(Writable.prototype), function(method) {\n  if (!Duplex.prototype[method])\n    Duplex.prototype[method] = Writable.prototype[method];\n});\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex))\n    return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false)\n    this.readable = false;\n\n  if (options && options.writable === false)\n    this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false)\n    this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended)\n    return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  process.nextTick(this.end.bind(this));\n}\n\nfunction forEach (xs, f) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    f(xs[i], i);\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/readable-stream/lib/_stream_transform.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\n\nfunction TransformState(options, stream) {\n  this.afterTransform = function(er, data) {\n    return afterTransform(stream, er, data);\n  };\n\n  this.needTransform = false;\n  this.transforming = false;\n  this.writecb = null;\n  this.writechunk = null;\n}\n\nfunction afterTransform(stream, er, data) {\n  var ts = stream._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb)\n    return stream.emit('error', new Error('no writecb in Transform class'));\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (!util.isNullOrUndefined(data))\n    stream.push(data);\n\n  if (cb)\n    cb(er);\n\n  var rs = stream._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    stream._read(rs.highWaterMark);\n  }\n}\n\n\nfunction Transform(options) {\n  if (!(this instanceof Transform))\n    return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = new TransformState(options, this);\n\n  // when the writable side finishes, then flush out anything remaining.\n  var stream = this;\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  this.once('prefinish', function() {\n    if (util.isFunction(this._flush))\n      this._flush(function(er) {\n        done(stream, er);\n      });\n    else\n      done(stream);\n  });\n}\n\nTransform.prototype.push = function(chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function(chunk, encoding, cb) {\n  throw new Error('not implemented');\n};\n\nTransform.prototype._write = function(chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform ||\n        rs.needReadable ||\n        rs.length < rs.highWaterMark)\n      this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function(n) {\n  var ts = this._transformState;\n\n  if (!util.isNull(ts.writechunk) && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\n\nfunction done(stream, er) {\n  if (er)\n    return stream.emit('error', er);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  var ws = stream._writableState;\n  var ts = stream._transformState;\n\n  if (ws.length)\n    throw new Error('calling transform done when ws.length != 0');\n\n  if (ts.transforming)\n    throw new Error('calling transform done when still transforming');\n\n  return stream.push(null);\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/readable-stream/lib/_stream_passthrough.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough))\n    return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function(chunk, encoding, cb) {\n  cb(null, chunk);\n};\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/config.js":"'use strict'\n\nvar util = require('util')\nvar path = require('path')\nvar fs = require('fs')\nvar EventEmitter = require('events').EventEmitter\nvar NAMES = require('./metrics/names.js')\nvar feature_flag = require('./feature_flags.js')\nvar flatten = require('./util/flatten')\nvar hashes = require('./util/hashes')\nvar exists = fs.existsSync || path.existsSync\nvar safeJSON = require('./util/safe-json')\nvar stringifySync = safeJSON.stringifySync\nvar parse = safeJSON.parse\nvar os = require('os')\nvar logger\n\n/**\n * CONSTANTS -- we gotta lotta 'em\n */\nvar DEFAULT_CONFIG_PATH = path.join(__dirname, 'config.default.js')\nvar DEFAULT_CONFIG = require(DEFAULT_CONFIG_PATH).config\nvar DEFAULT_FILENAME = 'newrelic.js'\nvar AZURE_APP_NAME = 'APP_POOL_ID'\nvar CONFIG_FILE_LOCATIONS = [\n  process.env.NEW_RELIC_HOME,\n  process.cwd(),\n  process.env.HOME,\n  path.join(__dirname, '../../..') // above node_modules\n]\n\n// the REPL has no main module\nif (process.mainModule && process.mainModule.filename) {\n  CONFIG_FILE_LOCATIONS.splice(2, 0, path.dirname(process.mainModule.filename))\n}\n\n/*\n * ENV_MAPPING, LIST_VARS, and BOOLEAN_VARS could probably be unified and\n * objectified, but this is simple and works.\n */\nvar ENV_MAPPING = {\n  newrelic_home: \"NEW_RELIC_HOME\",\n  app_name: \"NEW_RELIC_APP_NAME\",\n  license_key: \"NEW_RELIC_LICENSE_KEY\",\n  ssl: \"NEW_RELIC_USE_SSL\",\n  host: \"NEW_RELIC_HOST\",\n  port: \"NEW_RELIC_PORT\",\n  proxy: \"NEW_RELIC_PROXY_URL\",\n  proxy_host: \"NEW_RELIC_PROXY_HOST\",\n  proxy_port: \"NEW_RELIC_PROXY_PORT\",\n  proxy_user: \"NEW_RELIC_PROXY_USER\",\n  proxy_pass: \"NEW_RELIC_PROXY_PASS\",\n  ignore_server_configuration: \"NEW_RELIC_IGNORE_SERVER_CONFIGURATION\",\n  agent_enabled: \"NEW_RELIC_ENABLED\",\n  apdex_t: \"NEW_RELIC_APDEX\",\n  capture_params: \"NEW_RELIC_CAPTURE_PARAMS\",\n  ignored_params: \"NEW_RELIC_IGNORED_PARAMS\",\n  logging: {\n    level: \"NEW_RELIC_LOG_LEVEL\",\n    filepath: \"NEW_RELIC_LOG\",\n    enabled: \"NEW_RELIC_LOG_ENABLED\"\n  },\n  audit_log: {\n    enabled: \"NEW_RELIC_AUDIT_LOG_ENABLED\",\n    endpoints: \"NEW_RELIC_AUDIT_LOG_ENDPOINTS\"\n  },\n  error_collector: {\n    enabled: \"NEW_RELIC_ERROR_COLLECTOR_ENABLED\",\n    ignore_status_codes: \"NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERROR_CODES\"\n  },\n  transaction_tracer: {\n    enabled: \"NEW_RELIC_TRACER_ENABLED\",\n    transaction_threshold: \"NEW_RELIC_TRACER_THRESHOLD\",\n    top_n: \"NEW_RELIC_TRACER_TOP_N\",\n    record_sql: \"NEW_RELIC_RECORD_SQL\",\n    explain_threshold: \"NEW_RELIC_EXPLAIN_THRESHOLD\"\n  },\n  utilization: {\n    detect_aws: \"NEW_RELIC_UTILIZATION_DETECT_AWS\",\n    detect_docker: \"NEW_RELIC_UTILIZATION_DETECT_DOCKER\",\n    logical_processors: \"NEW_RELIC_UTILIZATION_LOGICAL_PROCESSORS\",\n    total_ram_mib: \"NEW_RELIC_UTILIZATION_TOTAL_RAM_MIB\",\n    billing_hostname: \"NEW_RELIC_UTILIZATION_BILLING_HOSTNAME\"\n  },\n  debug: {\n    internal_metrics: \"NEW_RELIC_DEBUG_METRICS\",\n    tracer_tracing: \"NEW_RELIC_DEBUG_TRACER\"\n  },\n  rules: {\n    name: \"NEW_RELIC_NAMING_RULES\",\n    ignore: \"NEW_RELIC_IGNORING_RULES\"\n  },\n  enforce_backstop: \"NEW_RELIC_ENFORCE_BACKSTOP\",\n  browser_monitoring: {\n    enable: \"NEW_RELIC_BROWSER_MONITOR_ENABLE\",\n    debug: \"NEW_RELIC_BROWSER_MONITOR_DEBUG\"\n  },\n  high_security: \"NEW_RELIC_HIGH_SECURITY\",\n  labels: \"NEW_RELIC_LABELS\",\n  slow_sql: {\n    enabled: \"NEW_RELIC_SLOW_SQL_ENABLED\",\n    max_samples: \"NEW_RELIC_MAX_SQL_SAMPLES\"\n  },\n  process_host: {\n    display_name: \"NEW_RELIC_PROCESS_HOST_DISPLAY_NAME\",\n    ipv_preference: \"NEW_RELIC_IPV_PREFERENCE\"\n  },\n  datastore_tracer: {\n    instance_reporting: {\n      enabled: \"NEW_RELIC_DATASTORE_INSTANCE_REPORTING_ENABLED\"\n    },\n    database_name_reporting:{\n      enabled: \"NEW_RELIC_DATASTORE_DATABASE_NAME_REPORTING_ENABLED\"\n    }\n  }\n}\n\n// values in list variables are comma-delimited lists\nvar LIST_VARS = [\n  \"NEW_RELIC_APP_NAME\",\n  \"NEW_RELIC_IGNORED_PARAMS\",\n  \"NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERROR_CODES\",\n  \"NEW_RELIC_IGNORING_RULES\",\n  \"NEW_RELIC_AUDIT_LOG_ENDPOINTS\"\n]\n\n// values in object lists are comma-delimited object literals\nvar OBJECT_LIST_VARS = [\n  \"NEW_RELIC_NAMING_RULES\"\n]\n\nvar HAS_ARBITRARY_KEYS = [\n  'labels'\n]\n\n/*\n * Values in boolean variables. Is pretty tolerant about values, but\n * don't get fancy and just use 'true' and 'false', everybody.\n */\nvar BOOLEAN_VARS = [\n  \"NEW_RELIC_IGNORE_SERVER_CONFIGURATION\",\n  \"NEW_RELIC_ENABLED\",\n  \"NEW_RELIC_CAPTURE_PARAMS\",\n  \"NEW_RELIC_ERROR_COLLECTOR_ENABLED\",\n  \"NEW_RELIC_TRACER_ENABLED\",\n  \"NEW_RELIC_DEBUG_METRICS\",\n  \"NEW_RELIC_DEBUG_TRACER\",\n  \"NEW_RELIC_ENFORCE_BACKSTOP\",\n  \"NEW_RELIC_USE_SSL\",\n  \"NEW_RELIC_BROWSER_MONITOR_ENABLE\",\n  \"NEW_RELIC_BROWSER_MONITOR_DEBUG\",\n  \"NEW_RELIC_HIGH_SECURITY\",\n  \"NEW_RELIC_SLOW_SQL_ENABLED\",\n  \"NEW_RELIC_LOG_ENABLED\",\n  \"NEW_RELIC_AUDIT_LOG_ENABLED\",\n  \"NEW_RELIC_DATASTORE_DATABASE_NAME_REPORTING_ENABLED\",\n  \"NEW_RELIC_DATASTORE_INSTANCE_REPORTING_ENABLED\"\n]\n\nvar FLOAT_VARS = [\n  'NEW_RELIC_APDEX'\n]\n\nvar INT_VARS = [\n  'NEW_RELIC_EXPLAIN_THRESHOLD',\n  'NEW_RELIC_MAX_SQL_SAMPLES'\n]\n\n// Config keys that can't be set by the server if high_security === true\nvar HIGH_SECURITY_SETTINGS = {\n  ssl: true,\n  capture_params: false,\n  transaction_tracer: {\n    record_sql: 'off'\n  },\n  slow_sql: {\n    enabled: false\n  }\n}\n\nvar HIGH_SECURITY_KEYS = Object.keys(flatten({}, '', HIGH_SECURITY_SETTINGS))\n\n// blank out these config values before sending to the collector\nvar REDACT_BEFORE_SEND = ['proxy_pass', 'proxy_user', 'proxy']\n\n// process.domain needs to be stripped befeore sending\nvar REMOVE_BEFORE_SEND = ['domain']\n\nvar _configInstance = null\n\nfunction isTruthular(setting) {\n  if (setting === undefined || setting === null) return false\n\n  var normalized = setting.toString().toLowerCase()\n  switch (normalized) {\n    case 'false':\n    case 'f':\n    case 'no':\n    case 'n':\n    case 'disabled':\n    case '0':\n      return false\n\n    default:\n      return true\n  }\n}\n\nfunction fromObjectList(setting) {\n  try {\n    return JSON.parse('[' + setting + ']')\n  } catch (error) {\n    logger.error(\"New Relic configurator could not deserialize object list:\")\n    logger.error(error.stack)\n  }\n}\n\nfunction _findConfigFile() {\n  var candidate\n  var filepath\n\n\n  for (var i = 0; i < CONFIG_FILE_LOCATIONS.length; i++) {\n    candidate = CONFIG_FILE_LOCATIONS[i]\n    if (!candidate) continue\n\n    filepath = path.join(path.resolve(candidate), DEFAULT_FILENAME)\n    if (!exists(filepath)) continue\n\n    return fs.realpathSync(filepath)\n  }\n}\n\nfunction Config(config) {\n  EventEmitter.call(this)\n\n  // 1. start by cloning the defaults\n  try {\n    var basis = JSON.parse(stringifySync(DEFAULT_CONFIG))\n    Object.keys(basis).forEach(function cb_forEach(key) {\n      this[key] = basis[key]\n    }, this)\n  } catch (err) {\n    logger.warn('Unable to clone the default config, %s: %s', DEFAULT_CONFIG_PATH, err)\n  }\n\n  if (config &&\n      (process.env[ENV_MAPPING.ssl] === 'false' || config.ssl === false) &&\n      process.env[ENV_MAPPING.port] === undefined && config.port === undefined ) {\n    config.port = 80\n  }\n\n  // 2. initialize undocumented, internal-only default values\n\n  // feature flags are mostly private settings for gating unreleased features\n  // flags are set in the feature_flags.js file\n  this.feature_flag = feature_flag.prerelease\n\n  // set by environment\n  this.newrelic_home = null\n  // set by configuration file loader\n  this.config_file_path = null\n  // set by collector on handshake\n  this.run_id = null\n  this.application_id = null\n  this.web_transactions_apdex = {}\n  this.cross_process_id = null\n  this.encoding_key = null\n  this.obfuscatedId = null\n  this.trusted_account_ids = null\n\n  // how frequently harvester runs\n  this.data_report_period = 60\n\n  // this value is arbitrary\n  this.max_trace_segments = 900\n\n  // feature level of this account\n  this.product_level = 0\n  // product-level related\n  this.collect_traces = true\n  this.collect_errors = true\n\n  // override options for utilization stats\n  this.utilization.logical_processors = null\n  this.utilization.total_ram_mib = null\n  this.utilization.billing_hostname = null\n\n  this.browser_monitoring.loader = 'rum'\n  this.browser_monitoring.loader_version = ''\n\n  // Settings to play nice with DLPs (see NODE-1044).\n  this.compressed_content_encoding = \"deflate\"  // Deflate or gzip\n  this.simple_compression = false               // Disables subcomponent compression\n  this.put_for_data_send = false                // Changes http verb for harvest\n\n\n  // 3. override defaults with values from the loaded / passed configuration\n  this._fromPassed(config)\n\n  // 3.5. special values (only Azure environment APP_POOL_ID for now)\n  this._fromSpecial()\n\n  // 4. override config with environment variables\n  this._fromEnvironment()\n\n  // 5. clean up anything that requires postprocessing\n  this._canonicalize()\n\n  // 6. put the version in the config\n  this.version = require('../package.json').version\n\n  // 7. apply high security overrides\n  if (this.high_security === true) {\n    this._applyHighSecurity()\n  }\n}\nutil.inherits(Config, EventEmitter)\n\n/**\n * Because this module and logger depend on each other, the logger needs\n * a way to inject the actual logger instance once it's constructed.\n * It's kind of a Rube Goldberg device, but it works.\n *\n * @param {Logger} bootstrapped The actual, configured logger.\n */\nConfig.prototype.setLogger = function setLogger(bootstrapped) {\n  logger = bootstrapped\n}\n\n/**\n * Accept any configuration passed back from the server. Will log all\n * recognized, unsupported, and unknown parameters. Some may not be set,\n * depending on the setting of ignore_server_configuration.\n *\n * @param {object} json The config blob sent by New Relic.\n */\nConfig.prototype.onConnect = function onConnect(json, recursion) {\n  json = json || {}\n  if (this.high_security === true && recursion !== true && json.high_security !== true) {\n    this.agent_enabled = false\n    this.emit('agent_enabled', false)\n    return\n  }\n  if (Object.keys(json).length === 0) return\n\n  Object.keys(json).forEach(function cb_forEach(key) {\n    this._fromServer(json, key)\n  }, this)\n\n  this.emit('change', this)\n}\n\n/**\n * The guts of the logic about how to deal with server-side configuration.\n *\n * @param {object} params A configuration dictionary.\n * @param {string} key    The particular configuration parameter to set.\n */\nConfig.prototype._fromServer = function _fromServer(params, key) {\n  switch (key) {\n    // handled by the connection\n    case 'messages':\n      break\n\n    // *sigh* Xzibit, etc.\n    case 'agent_config':\n      this.onConnect(params[key], true)\n      break\n\n    // if it's undefined or null, so be it\n    case 'agent_run_id':\n      this.run_id = params.agent_run_id\n      break\n\n    // handled by config.onConnect\n    case 'high_security':\n      break\n\n    // always accept these settings\n    case 'cross_process_id':\n    case 'encoding_key':\n      this._alwaysUpdateIfChanged(params, key)\n      if (this.cross_process_id && this.encoding_key) {\n        this.obfuscatedId = hashes.obfuscateNameUsingKey(this.cross_process_id,\n                                                         this.encoding_key)\n      }\n      break\n\n    // always accept these settings\n    case 'collect_traces':\n    case 'collect_errors':\n    case 'product_level':\n    case 'application_id':\n    case 'trusted_account_ids':\n      this._alwaysUpdateIfChanged(params, key)\n      break\n\n    case 'collect_error_events':\n      if (params.collect_error_events === false) {\n        this._updateNestedIfChanged(\n          params,\n          this.error_collector,\n          key,\n          'capture_events'\n        )\n      }\n      break\n\n    // also accept these settings\n    case 'url_rules':\n    case 'metric_name_rules':\n    case 'transaction_name_rules':\n    case 'transaction_segment_terms':\n      this._emitIfSet(params, key)\n      break\n\n    // setting these can be disabled by ignore_server_configuration\n    case 'ssl':\n    case 'apdex_t':\n    case 'web_transactions_apdex':\n    case 'data_report_period':\n    case 'ignored_params':\n      this._updateIfChanged(params, key)\n      break\n    case 'transaction_tracer.enabled':\n      this._updateNestedIfChanged(\n        params,\n        this.transaction_tracer,\n        'transaction_tracer.enabled',\n        'enabled'\n      )\n      break\n    case 'transaction_tracer.transaction_threshold':\n      this._updateNestedIfChanged(\n        params,\n        this.transaction_tracer,\n        'transaction_tracer.transaction_threshold',\n        'transaction_threshold'\n      )\n      break\n    case 'error_collector.enabled':\n      this._updateNestedIfChanged(\n        params,\n        this.error_collector,\n        'error_collector.enabled',\n        'enabled'\n      )\n      break\n    case 'error_collector.ignore_status_codes':\n      this._updateNestedIfChanged(\n        params,\n        this.error_collector,\n        'error_collector.ignore_status_codes',\n        'ignore_status_codes'\n      )\n      this._canonicalize()\n      break\n\n    case 'error_collector.capture_events':\n      this._updateNestedIfChanged(\n        params,\n        this.error_collector,\n        'error_collector.capture_events',\n        'capture_events'\n      )\n      break\n\n    case 'error_collector.max_event_samples_stored':\n      this._updateNestedIfChanged(\n        params,\n        this.error_collector,\n        'error_collector.max_event_samples_stored',\n        'max_event_samples_stored'\n      )\n      break\n\n    case 'collect_analytics_events':\n      // never enable from server-side\n      // but we allow the server to disable\n      if (params.collect_analytics_events === false)\n        this.transaction_events.enabled = false\n      break\n\n    case 'collect_custom_events':\n      // never enable from server-side\n      // but we allow the server to disable\n      if (params.collect_custom_events === false)\n        this.custom_insights_events.enabled = false\n      break\n\n    case 'transaction_events.max_samples_stored':\n      this._updateNestedIfChanged(\n        params,\n        this.transaction_events,\n        key,\n        'max_samples_stored'\n      )\n      break\n\n    case 'transaction_events.max_samples_per_minute':\n      this._updateNestedIfChanged(\n        params,\n        this.transaction_events,\n        key,\n        'max_samples_per_minute'\n      )\n      break\n\n    case 'transaction_events.enabled':\n      this._updateNestedIfChanged(\n        params,\n        this.transaction_events,\n        key,\n        'enabled'\n      )\n      break\n\n    // these are used by browser_monitoring\n    // and the api.getRUMHeader() method\n    case 'js_agent_file':\n    case 'js_agent_loader_file':\n    case 'beacon':\n    case 'error_beacon':\n    case 'browser_key':\n    case 'js_agent_loader':\n      this._updateNestedIfChangedRaw(\n        params,\n        this.browser_monitoring,\n        key,\n        key\n      )\n      break\n\n    case 'browser_monitoring.loader':\n      this._updateNestedIfChangedRaw(\n        params,\n        this.browser_monitoring,\n        key,\n        'loader'\n      )\n      break\n\n    // After 2015-02, the collector no longer supports the capture_params setting.\n    case 'capture_params':\n      break\n    // these settings aren't supported by the agent (yet)\n    case 'sampling_rate':\n    case 'episodes_file':\n    case 'episodes_url':\n    case 'cross_application_tracing':\n    case 'transaction_tracer.record_sql':\n    case 'slow_sql.enabled':\n    case 'rum.load_episodes_file':\n      this.logUnsupported(params, key)\n      break\n\n    default:\n      this.logUnknown(params, key)\n  }\n}\n\n/**\n * Change a value sent by the collector if and only if it's different from the\n * value we already have. Emit an event with the key name and the new value,\n * and log that the value has changed.\n *\n * @param {object} json Config blob sent by collector.\n * @param {string} key  Value we're looking to set.\n */\nConfig.prototype._alwaysUpdateIfChanged = function _alwaysUpdateIfChanged(json, key) {\n  var value = json[key]\n  if (value !== null && value !== undefined && this[key] !== value) {\n    if (Array.isArray(value) && Array.isArray(this[key])) {\n      value.forEach(function cb_forEach(element) {\n        if (this[key].indexOf(element) === -1) this[key].push(element)\n      }, this)\n    } else {\n      this[key] = value\n    }\n    this.emit(key, value)\n    logger.debug(\"Configuration of %s was changed to %s by New Relic.\", key, value)\n  }\n}\n\n/**\n * Change a value sent by the collector if and only if it's different from the\n * value we already have. Emit an event with the key name and the new value,\n * and log that the value has changed. Parameter will be ignored if\n * ignore_server_configuration is set.\n *\n * @param {object} json Config blob sent by collector.\n * @param {string} key  Value we're looking to set.\n */\nConfig.prototype._updateIfChanged = function _updateIfChanged(json, key) {\n  this._updateNestedIfChanged(json, this, key, key)\n}\n\n/**\n * Some parameter values are nested, need a simple way to change them as well.\n * Will merge local and remote if and only if both are arrays. Parameter will\n * be ignored if ignore_server_configuration is set.\n *\n * @param {object} remote    JSON sent from New Relic.\n * @param {object} local     A portion of this configuration object.\n * @param {string} remoteKey The name sent by New Relic.\n * @param {string} localKey  The local name.\n */\nConfig.prototype._updateNestedIfChanged = _updateNestedIfChanged\n\nfunction _updateNestedIfChanged(remote, local, remoteKey, localKey) {\n  if (this.ignore_server_configuration) return this.logDisabled(remote, remoteKey)\n  // if high-sec mode is enabled, we do not accept server changes to high-sec\n  if (this.high_security && HIGH_SECURITY_KEYS.indexOf(localKey) !== -1) {\n    return this.logDisabled(remote, remoteKey)\n  }\n  return this._updateNestedIfChangedRaw(remote, local, remoteKey, localKey)\n}\n\nConfig.prototype._updateNestedIfChangedRaw = function _updateNestedIfChangedRaw(\n    remote, local, remoteKey, localKey) {\n  var value = remote[remoteKey]\n  if (value !== null && value !== undefined && local[localKey] !== value) {\n    if (Array.isArray(value) && Array.isArray(local[localKey])) {\n      value.forEach(function cb_forEach(element) {\n        if (local[localKey].indexOf(element) === -1) local[localKey].push(element)\n      })\n    } else {\n      local[localKey] = value\n    }\n    this.emit(remoteKey, value)\n    logger.debug(\"Configuration of %s was changed to %s by New Relic.\", remoteKey, value)\n  }\n}\n\n/**\n * Some parameter values are just to be passed on.\n *\n * @param {object} json Config blob sent by collector.\n * @param {string} key  Value we're looking to set.\n */\nConfig.prototype._emitIfSet = function _emitIfSet(json, key) {\n  var value = json[key]\n  if (value !== null && value !== undefined) this.emit(key, value)\n}\n\n/**\n * The agent would normally do something with this parameter, but server-side\n * configuration is disabled via ignore_server_configuration.\n *\n * @param {object} json Config blob sent by collector.\n * @param {string} key  Value the agent won't set.\n */\nConfig.prototype.logDisabled = function logDisabled(json, key) {\n  var value = json[key]\n  if (value !== null && value !== undefined) {\n    logger.debug(\n      \"Server-side configuration of %s is currently disabled by local configuration. \" +\n      \"(Server sent value of %s.)\",\n      key,\n      value\n    )\n  }\n}\n\n/**\n * Help support out by putting in the logs the fact that we don't currently\n * support the provided configuration key, and including the sent value.\n *\n * @param {object} json Config blob sent by collector.\n * @param {string} key  Value the agent doesn't set.\n */\nConfig.prototype.logUnsupported = function logUnsupported(json, key) {\n  var flavor\n  if (this.ignore_server_configuration) {\n    flavor = \"ignored\"\n  } else {\n    flavor = \"not supported by the Node.js agent\"\n  }\n\n  var value = json[key]\n  if (value !== null && value !== undefined) {\n    logger.debug(\n      \"Server-side configuration of %s is currently %s. (Server sent value of %s.)\",\n      key,\n      flavor,\n      value\n    )\n    this.emit(key, value)\n  }\n}\n\n/**\n * The agent knows nothing about this parameter.\n *\n * @param {object} json Config blob sent by collector.\n * @param {string} key  Value the agent knows nothing about.\n */\nConfig.prototype.logUnknown = function logUnknown(json, key) {\n  var value = json[key]\n  logger.debug(\n    \"New Relic sent unknown configuration parameter %s with value %s.\",\n    key,\n    value\n  )\n}\n\n/**\n * Gets the user set host display name. If not provided, it returns the default value.\n *\n * This function is written is this strange way becauase of the use of caching variables.\n * I wanted to cache the DisplayHost, but if I attached the variable to the config object,\n * it sends the extra variable to New Relic, which is not desired.\n *\n * @return {string} display host name\n */\nConfig.prototype.getDisplayHost = getDisplayHost\n\nConfig.prototype.clearDisplayHostCache = function clearDisplayHostCache() {\n  this.getDisplayHost = getDisplayHost\n}\n\nfunction getDisplayHost() {\n  var _displayHost\n  this.getDisplayHost = function getCachedDisplayHost() {\n    return _displayHost\n  }\n  if (this.process_host.display_name === '') {\n    _displayHost = this.getHostnameSafe()\n    return _displayHost\n  }\n  var stringBuffer = new Buffer(this.process_host.display_name, 'utf8')\n  var numBytes = stringBuffer.length\n\n  if (numBytes > 255) {\n    logger.warn('Custom host display name must be less than 255 bytes')\n    _displayHost = this.getHostnameSafe()\n    return _displayHost\n  }\n\n  _displayHost = this.process_host.display_name\n  return _displayHost\n}\n\n/**\n * Gets the system's host name. If that fails, it just returns ipv4/6 based on the user's\n * process_host.ipv_preferenece setting.\n *\n * This function is written is this strange way becauase of the use of caching variables.\n * I wanted to cache the Hostname, but if I attached the variable to the config object,\n * it sends the extra variable to New Relic, which is not desired.\n *\n * @return {string} host name\n */\nConfig.prototype.getHostnameSafe = getHostnameSafe\n\nConfig.prototype.clearHostnameCache = function clearHostnameCache() {\n  this.getHostnameSafe = getHostnameSafe\n}\n\nConfig.prototype.getIPAddresses = function getIPAddresses() {\n  var addresses = {}\n  var interfaces = os.networkInterfaces()\n\n  for (var interfaceKey in interfaces) {\n    if (interfaceKey.match(/^lo/)) continue\n\n    var interfaceDescriptions = interfaces[interfaceKey]\n    for (var i = 0; i < interfaceDescriptions.length; i++) {\n      var description = interfaceDescriptions[i]\n      var family = description.family.toLowerCase()\n      addresses[family] = description.address\n    }\n  }\n  return addresses\n}\n\nfunction getHostnameSafe() {\n  var _hostname\n  this.getHostnameSafe = function getCachedHostname() {\n    return _hostname\n  }\n  try {\n    _hostname = os.hostname()\n    return _hostname\n  } catch (e) {\n    var addresses = this.getIPAddresses()\n\n    if (this.process_host.ipv_preference === '6' && addresses.ipv6) {\n      _hostname = addresses.ipv6\n    } else if (addresses.ipv4) {\n      logger.info('Defaulting to ipv4 address for host name')\n      _hostname = addresses.ipv4\n    } else if (addresses.ipv6) {\n      logger.info('Defaulting to ipv6 address for host name')\n      _hostname = addresses.ipv6\n    } else {\n      logger.info('No hostname, ipv4, or ipv6 address found for machine')\n      _hostname = 'UNKNOWN_BOX'\n    }\n\n    return _hostname\n  }\n}\n\n/**\n * Ensure that the apps names are always returned as a list.\n */\nConfig.prototype.applications = function applications() {\n  var apps = this.app_name\n\n  if (Array.isArray(apps) && apps.length > 0) {\n    return apps\n  }\n\n  if (apps && typeof apps === 'string') {\n    return [apps]\n  }\n\n  return []\n}\n\n/**\n * Safely overwrite defaults with values passed to constructor.\n *\n * @param object external The configuration being loaded.\n * @param object internal Whichever chunk of the config being overridden.\n */\nConfig.prototype._fromPassed = function _fromPassed(external, internal, arbitrary) {\n  if (!external) return\n  if (!internal) internal = this\n\n  Object.keys(external).forEach(function cb_forEach(key) {\n    // if it's not in the defaults, it doesn't exist\n    if (!arbitrary && internal[key] === undefined) return\n\n    try {\n      var node = external[key]\n    } catch (err) {\n      logger.warn('Error thrown on access of user config for key: %s', key)\n      return\n    }\n\n    if (Array.isArray(node)) {\n      internal[key] = node\n    } else if (typeof node === 'object') {\n      // is top level and can have arbitrary keys\n      if (internal === this && HAS_ARBITRARY_KEYS.indexOf(key) !== -1) {\n        this._fromPassed(node, internal[key], true)\n      } else {\n        this._fromPassed(node, internal[key], false)\n      }\n    } else {\n      internal[key] = node\n    }\n  }, this)\n}\n\n/**\n * Some values should be picked up only if they're not otherwise set, like\n * the Windows / Azure application name. Don't set it if there's already\n * a non-empty value set via the configuration file, and allow these\n * values to be overwritten by environment variables. Just saves a step for\n * PaaS users who don't want to have multiple settings for a single piece\n * of configuration.\n */\nConfig.prototype._fromSpecial = function _fromSpecial() {\n  var name = this.app_name\n  if (name === null || name === undefined || name === '' ||\n      (Array.isArray(name) && name.length === 0)) {\n    var azureName = process.env[AZURE_APP_NAME]\n    if (azureName) this.app_name = azureName.split(',')\n  }\n}\n\n/**\n * Recursively visit the nodes of the constant containing the mapping between\n * environment variable names, overriding any configuration values that are\n * found in the environment. Operates purely via side effects.\n *\n * @param object metadata The current level of the mapping object. Should never\n *                        need to set this yourself.\n * @param object data     The current level of the configuration object. Should\n *                        never need to set this yourself.\n */\nConfig.prototype._fromEnvironment = function _fromEnvironment(metadata, data) {\n  if (!metadata) metadata = ENV_MAPPING\n  if (!data) data = this\n\n  Object.keys(metadata).forEach(function cb_forEach(value) {\n    // if it's not in the config, it doesn't exist\n    if (data[value] === undefined) return\n\n    var node = metadata[value]\n    if (typeof node === 'string') {\n      var setting = process.env[node]\n      if (setting) {\n        if (LIST_VARS.indexOf(node) > -1) {\n          data[value] = setting.split(',').map(function cb_map(k) {\n            return k.trim()\n          })\n        } else if (OBJECT_LIST_VARS.indexOf(node) > -1) {\n          data[value] = fromObjectList(setting)\n        } else if (BOOLEAN_VARS.indexOf(node) > -1) {\n          data[value] = isTruthular(setting)\n        } else if (FLOAT_VARS.indexOf(node) > -1) {\n          data[value] = parseFloat(setting, 10)\n        } else if (INT_VARS.indexOf(node) > -1) {\n          data[value] = parseInt(setting, 10)\n        } else {\n          data[value] = setting\n        }\n      }\n    } else {\n      // don't crash if the mapping has config keys the current config doesn't.\n      if (!data[value]) data[value] = {}\n      this._fromEnvironment(node, data[value])\n    }\n  }, this)\n}\n\n/**\n * Depending on how the status codes are set, they could be strings, which\n * makes strict equality testing / indexOf fail. To keep things cheap, parse\n * them once, after configuration has finished loading. Other one-off shims\n * based on special properties of configuration values should go here as well.\n */\nConfig.prototype._canonicalize = function _canonicalize() {\n  var codes = this.error_collector && this.error_collector.ignore_status_codes\n  if (codes) {\n    this.error_collector.ignore_status_codes = codes.map(function cb_map(code) {\n      return parseInt(code, 10)\n    })\n  }\n\n  var logAliases = {\n    'verbose': 'trace',\n    'debugging': 'debug',\n    'warning': 'warn',\n    'err': 'error'\n  }\n  var level = this.logging.level\n  this.logging.level = logAliases[level] || level\n}\n\n/**\n * This goes through the settings that high security mode needs and coerces\n * them to be correct.\n */\nConfig.prototype._applyHighSecurity = function _applyHighSecurity() {\n  var config = this\n  checkNode('', this, HIGH_SECURITY_SETTINGS)\n\n  function checkNode(base, target, settings) {\n    Object.keys(settings).forEach(checkKey.bind(null, base, target, settings))\n  }\n\n  function checkKey(base, target, settings, key) {\n    var hsValue = settings[key]\n\n\n    if (hsValue && typeof hsValue === 'object') {\n      if (typeof target[key] !== 'object') {\n        logger.warn(\n          'High Security Mode: %s should be an object, found %s',\n          key,\n          target[key]\n        )\n        target[key] = {}\n      }\n\n      return checkNode(base + key + '.', target[key], hsValue)\n    }\n\n    if (target[key] !== hsValue) {\n      logger.warn('High Security Mode: %s was set to %s, coercing to %s',\n                  key, target[key], hsValue)\n      target[key] = hsValue\n      config.emit(base + key, hsValue)\n    }\n  }\n}\n\n/**\n * The agent will use the supportability metrics object if it's\n * available.\n *\n * @param string suffix Supportability metric name.\n * @param number duration Milliseconds that the measured operation took.\n */\nConfig.prototype.measureInternal = function measureInternal(suffix, duration) {\n  if (this.debug.supportability) {\n    var internal = this.debug.supportability\n    internal.measureMilliseconds(NAMES.SUPPORTABILITY.PREFIX + suffix, null, duration)\n  }\n}\n\nConfig.prototype.validateFlags = function validateFlags() {\n  Object.keys(this.feature_flag).forEach(function cb_forEach(key) {\n    if (feature_flag.released.indexOf(key) > -1) {\n      logger.warn('Feature flag ' + key + ' has been released')\n    }\n    if (feature_flag.unreleased.indexOf(key) > -1) {\n      logger.warn('Feature flag ' + key + ' has been deprecated')\n    }\n  })\n}\n\n/**\n * Get a JSONifiable object containing all settings we want to report to the\n * collector and store in the environment_values table.\n *\n * @return Object containing simple key-value pairs of settings\n */\nConfig.prototype.publicSettings = function publicSettings() {\n  var settings = {}\n\n  for (var key in this) {\n    if (this.hasOwnProperty(key)) {\n      var item = this[key]\n\n      if (REDACT_BEFORE_SEND.indexOf(key) > -1) {\n        item = '****'\n      }\n\n      if (REMOVE_BEFORE_SEND.indexOf(key) === -1) {\n        settings[key] = item\n      }\n    }\n  }\n\n  // Agent-side setting is 'enable', but collector-side setting is\n  // 'auto_instrument'. Send both values up.\n  settings.browser_monitoring.auto_instrument = settings.browser_monitoring.enable\n\n  // Remove simple circular references\n  parse(stringifySync(settings), function cb_parse(err, settingsCopy) {\n    if (err === null) {\n      settings = flatten({}, '', settingsCopy)\n    } else {\n      logger.warn('Error while creating deep copy: %s', err)\n    }\n  })\n\n  return settings\n}\n\n/**\n * Create a configuration, either from a configuration file or the node\n * process's environment.\n *\n * For configuration via file, check these directories, in order, for a\n * file named 'newrelic.js':\n *\n *   1. The process's current working directory at startup.\n *   2. The same directory as the process's main module (i.e. the filename\n *      passed to node on the command line).\n *   3. The directory pointed to by the environment variable NEW_RELIC_HOME.\n *   4. The current process's HOME directory.\n *   5. If this module is installed as a dependency, the directory above the\n *      node_modules folder in which newrelic is installed.\n *\n * For configration via environment (useful on Joyent, Azure, Heroku, or\n * other PaaS offerings), set NEW_RELIC_NO_CONFIG_FILE to something truthy\n * and read README.md for details on what configuration variables are\n * necessary, as well as a complete enumeration of the other available\n * variables.\n *\n * @param {object} config Optional configuration to be used in place of a\n *                        config file.\n */\nfunction initialize(config) {\n  /* When the logger is required here, it bootstraps itself and then\n   * injects itself into this module's closure via setLogger on the\n   * instance of the logger it creates.\n   */\n  logger = require('./logger.js')\n\n  if (config) return new Config(config)\n\n  if (isTruthular(process.env.NEW_RELIC_NO_CONFIG_FILE)) {\n    config = new Config({})\n    if (config.newrelic_home) delete config.newrelic_home\n    return config\n  }\n\n  var filepath = _findConfigFile()\n  if (!filepath) {\n    _noConfigFile()\n    return null\n  }\n\n  try {\n    config = new Config(require(filepath).config)\n    config.config_file_path = filepath\n    logger.debug(\"Using configuration file %s.\", filepath)\n\n    config.validateFlags()\n\n    return config\n  } catch (error) {\n    logger.error(error)\n\n    throw new Error(\n      \"Unable to read configuration file \" + filepath + \". A default\\n\" +\n      \"configuration file can be copied from \" + DEFAULT_CONFIG_PATH + \"\\n\" +\n      \"and renamed to 'newrelic.js' in the directory from which you'll be starting\\n\" +\n      \"your application.\"\n    )\n  }\n}\n\nfunction _noConfigFile() {\n  var mainpath = path.resolve(path.join(process.cwd(), DEFAULT_FILENAME))\n  var altpath = path.resolve(\n    path.dirname(process.mainModule.filename),\n    DEFAULT_FILENAME\n  )\n\n  var locations\n  if (mainpath !== altpath) {\n    locations = mainpath + \" or\\n\" + altpath\n  } else {\n    locations = mainpath\n  }\n\n  /* eslint-disable no-console */\n  console.error(\n    \"Unable to find New Relic module configuration. A default\\n\" +\n    \"configuration file can be copied from \" + DEFAULT_CONFIG_PATH + \"\\n\" +\n    \"and put at \" + locations + \". If you are not using file based config\\n\" +\n    \"please set the environment variable NEW_RELIC_NO_CONFIG_FILE=true\"\n  )\n  /* eslint-enable no-console */\n}\n\n/**\n * This function honors the singleton nature of this module while allowing\n * consumers to just request an instance without having to worry if one was\n * already created.\n */\nfunction getOrCreateInstance() {\n  if (_configInstance === null) {\n    _configInstance = initialize()\n  }\n  return _configInstance\n}\n\n/**\n * Preserve the legacy initializer, but also allow consumers to manage their\n * own configuration if they choose.\n */\nConfig.initialize = initialize\nConfig.getOrCreateInstance = getOrCreateInstance\n\nmodule.exports = Config\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/metrics/names.js":"'use strict'\n\nvar NODEJS = {\n  PREFIX: 'Nodejs/'\n}\n\nvar ALL = 'all'\n\nvar ERRORS = {\n  PREFIX: 'Errors/',\n  ALL: 'Errors/' + ALL,\n  WEB: 'Errors/allWeb',\n  OTHER: 'Errors/allOther'\n}\n\nvar EVENTS = {\n  WAIT: 'Events/wait'\n}\n\nvar MEMORY = {\n  PHYSICAL: 'Memory/Physical',\n  FREE_HEAP: 'Memory/Heap/Free',\n  USED_HEAP: 'Memory/Heap/Used',\n  MAX_HEAP: 'Memory/Heap/Max',\n  USED_NONHEAP: 'Memory/NonHeap/Used'\n}\n\nvar CPU = {\n  SYSTEM_TIME: 'CPU/System Time',\n  SYSTEM_UTILIZATION: 'CPU/System/Utilization',\n  USER_TIME: 'CPU/User Time',\n  USER_UTILIZATION: 'CPU/User/Utilization'\n}\n\nvar GC = {\n  PREFIX: 'GC/',\n  PAUSE_TIME: 'GC/System/Pauses'\n}\n\nvar VIEW = {\n  PREFIX: 'View/',\n  RENDER: '/Rendering'\n}\n\nvar LOOP = {\n  PREFIX: NODEJS.PREFIX + 'EventLoop/',\n  USAGE: NODEJS.PREFIX + 'EventLoop/CPU/Usage'\n}\n\nvar DB = {\n  PREFIX: 'Datastore/',\n  STATEMENT: 'Datastore/statement',\n  OPERATION: 'Datastore/operation',\n  INSTANCE: 'Datastore/instance',\n  ALL: 'Datastore/' + ALL,\n  WEB: 'allWeb',\n  OTHER: 'allOther'\n}\n\nvar EXTERNAL = {\n  PREFIX: 'External/',\n  ALL: 'External/' + ALL,\n  WEB: 'External/allWeb',\n  OTHER: 'External/allOther',\n  APP: 'ExternalApp/',\n  TRANSACTION: 'ExternalTransaction/'\n}\n\nvar FUNCTION = {\n  PREFIX: 'Function/'\n}\n\nvar MIDDLEWARE = {\n  PREFIX: NODEJS.PREFIX + 'Middleware/'\n}\n\nvar FS = {\n  PREFIX: 'Filesystem/'\n}\n\nvar MEMCACHE = {\n  PREFIX: 'Memcache',\n  OPERATION: DB.OPERATION + '/Memcache/',\n  INSTANCE: DB.INSTANCE + '/Memcache/',\n  ALL: DB.PREFIX + 'Memcache/' + ALL\n}\n\nvar MONGODB = {\n  PREFIX: 'MongoDB',\n  STATEMENT: DB.STATEMENT + '/MongoDB/',\n  OPERATION: DB.OPERATION + '/MongoDB/',\n  INSTANCE: DB.INSTANCE + '/MongoDB/'\n}\n\nvar MYSQL = {\n  PREFIX: 'MySQL',\n  STATEMENT: DB.STATEMENT + '/MySQL/',\n  OPERATION: DB.OPERATION + '/MySQL/',\n  INSTANCE: DB.INSTANCE + '/MySQL/'\n}\n\nvar REDIS = {\n  PREFIX: 'Redis',\n  OPERATION: DB.OPERATION + '/Redis/',\n  INSTANCE: DB.INSTANCE + '/Redis/',\n  ALL: DB.PREFIX + 'Redis/' + ALL\n}\n\nvar POSTGRES = {\n  PREFIX: 'Postgres',\n  STATEMENT: DB.STATEMENT + '/Postgres/',\n  OPERATION: DB.OPERATION + '/Postgres/',\n  INSTANCE: DB.INSTANCE + '/Postgres/'\n}\n\nvar CASSANDRA = {\n  PREFIX: 'Cassandra',\n  OPERATION: DB.OPERATION + '/Cassandra/',\n  STATEMENT: DB.STATEMENT + '/Cassandra/',\n  INSTANCE: DB.INSTANCE + '/Cassandra/',\n  ALL: DB.PREFIX + 'Cassandra/' + ALL\n\n}\n\nvar ORACLE = {\n  PREFIX: 'Oracle',\n  STATEMENT: DB.STATEMENT + '/Oracle/',\n  OPERATION: DB.OPERATION + '/Oracle/',\n  INSTANCE: DB.INSTANCE + '/Oracle/'\n}\n\nvar EXPRESS = {\n  PREFIX: 'Expressjs/',\n  MIDDLEWARE: MIDDLEWARE.PREFIX + 'Expressjs/',\n  ERROR_HANDLER: MIDDLEWARE.PREFIX + 'Expressjs/'\n}\n\nvar RESTIFY = {\n  PREFIX: 'Restify/'\n}\n\nvar HAPI = {\n  PREFIX: 'Hapi/'\n}\n\nvar SUPPORTABILITY = {\n  PREFIX: 'Supportability/',\n  UNINSTRUMENTED: 'Supportability/Uninstrumented',\n  EVENTS: 'Supportability/Events',\n  API: 'Supportability/API',\n  UTILIZATION: 'Supportability/utilization',\n  DEPENDENCIES: 'Supportability/InstalledDependencies'\n}\n\nvar UTILIZATION = {\n  AWS_ERROR: SUPPORTABILITY.UTILIZATION + '/aws/error',\n  DOCKER_ERROR: SUPPORTABILITY.UTILIZATION + '/docker/error'\n}\n\n\nvar CUSTOM_EVENTS = {\n  PREFIX: SUPPORTABILITY.EVENTS + '/Customer/',\n  DROPPED: SUPPORTABILITY.EVENTS + '/Customer/Dropped',\n  SEEN: SUPPORTABILITY.EVENTS + '/Customer/Seen',\n  SENT: SUPPORTABILITY.EVENTS + '/Customer/Sent',\n  TOO_LARGE: SUPPORTABILITY.EVENTS + '/Customer/TooLarge',\n  FAILED: SUPPORTABILITY.EVENTS + '/Customer/FailedToSend'\n}\n\nvar TRANSACTION_ERROR = {\n  SEEN: SUPPORTABILITY.EVENTS + '/TransactionError/Seen',\n  SENT: SUPPORTABILITY.EVENTS + '/TransactionError/Sent'\n}\n\nvar WEB = {\n  RESPONSE_TIME: 'WebTransaction',\n  TOTAL_TIME: 'WebTransactionTotalTime'\n}\n\nvar BACKGROUND = {\n  RESPONSE_TIME: 'OtherTransaction',\n  TOTAL_TIME: 'OtherTransactionTotalTime'\n}\n\nvar TRUNCATED = {\n  PREFIX: 'Truncated/'\n}\n\nmodule.exports = {\n  ACTION_DELIMITER: '/',\n  ALL: ALL,\n  APDEX: 'Apdex',\n  BACKGROUND: BACKGROUND,\n  CASSANDRA: CASSANDRA,\n  CLIENT_APPLICATION: 'ClientApplication',\n  CONTROLLER: 'Controller',\n  CPU: CPU,\n  GC: GC,\n  CUSTOM: 'Custom',\n  CUSTOM_EVENTS: CUSTOM_EVENTS,\n  DB: DB,\n  ERRORS: ERRORS,\n  EVENTS: EVENTS,\n  EXPRESS: EXPRESS,\n  EXTERNAL: EXTERNAL,\n  FS: FS,\n  FUNCTION: FUNCTION,\n  HAPI: HAPI,\n  HTTP: 'HttpDispatcher',\n  LOOP: LOOP,\n  MEMCACHE: MEMCACHE,\n  MEMORY: MEMORY,\n  MONGODB: MONGODB,\n  MYSQL: MYSQL,\n  NORMALIZED: 'NormalizedUri',\n  NODEJS: NODEJS,\n  ORACLE: ORACLE,\n  POSTGRES: POSTGRES,\n  QUEUETIME: 'WebFrontend/QueueTime',\n  REDIS: REDIS,\n  RESTIFY: RESTIFY,\n  SUPPORTABILITY: SUPPORTABILITY,\n  TRANSACTION_ERROR: TRANSACTION_ERROR,\n  TRUNCATED: TRUNCATED,\n  URI: 'Uri',\n  UTILIZATION: UTILIZATION,\n  VIEW: VIEW,\n  WEB: WEB\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/feature_flags.js":"'use strict'\n\n// unreleased flags gating an active feature\nexports.prerelease = {\n  cat: true,\n  custom_instrumentation: true,\n  custom_metrics: true,\n  express5: false,\n  synthetics: true,\n  express_segments: true,\n  native_metrics: true,\n  promise_segments: false,\n  reverse_naming_rules: true,\n  send_request_uri_attribute: false\n}\n\n// flags that are no longer used for released features\nexports.released = [\n  'released',\n  'express4',\n  'insights',\n  'postgres',\n  'mysql_pool',\n  'proxy',\n  'custom_events'\n]\n\n// flags that are no longer used for unreleased features\nexports.unreleased = [\n  'unreleased'\n]\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/util/flatten.js":"'use strict'\n\n/**\n * Flatten nested maps of JSONifiable data.\n *\n * Ex: {a: 5, b: {c: true, d: 7}} -> {a: 5, 'b.c': true, 'b.d': 7}\n *\n * @param result Object to place key-value pairs into, normally called with {}\n * @param prefix Prefix for keys, normally called with ''\n * @param obj    Object to be flattened\n *\n * @return Object with flattened key-value pairs\n */\nmodule.exports = function flatten(result, prefix, obj, seen) {\n  seen = seen || []\n  seen.push(obj)\n\n  for (var key in obj) {\n    if (seen.indexOf(obj[key]) > -1) {\n      continue\n    }\n\n    if (obj[key] instanceof Object) flatten(result, prefix + key + '.', obj[key], seen)\n    else result[prefix + key] = obj[key]\n  }\n\n  return result\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/util/hashes.js":"'use strict'\n\nvar crypto = require('crypto')\n\nfunction encode(bytes, keyBytes) {\n  for (var i = 0; i < bytes.length; i++) {\n    // This is really dense but happens commonly so I'm in-lining some of what\n    // could be tossed into variables. It takes the current byte of bytes, then\n    // XORs it with the current byte of the key (which uses modulo to make sure\n    // to not overrun the end.)\n    bytes.writeUInt8(bytes.readUInt8(i) ^ keyBytes.readUInt8(i % keyBytes.length), i)\n  }\n  return bytes\n}\n\nfunction obfuscateNameUsingKey(name, key) {\n  var encodedBytes = new Buffer(name, 'utf-8')\n  var keyBytes = new Buffer(key)\n  return encode(encodedBytes, keyBytes).toString('base64')\n}\n\nfunction deobfuscateNameUsingKey(name, key) {\n  var bytes = new Buffer(name, 'base64')\n  var keyBytes = new Buffer(key)\n\n  return encode(bytes, keyBytes).toString(\"utf-8\")\n}\n\nfunction calculatePathHash(appName, pathName, referingPathHash) {\n  if (typeof referingPathHash === 'string') {\n    referingPathHash = parseInt(referingPathHash, 16)\n  }\n  var rotated = ((referingPathHash << 1) | (referingPathHash >>> 31)) >>> 0\n  var hash = getHash(appName, pathName)\n\n  var result = (rotated ^ hash) >>> 0\n\n  // This is a trick to pad it out to 8 chars regardless of length.\n  var retval = ('00000000' + result.toString(16)).substr(-8)\n\n  return retval\n}\n\nfunction getHash(appName, txName) {\n  var md5sum = crypto.createHash('md5')\n  md5sum.update(new Buffer(appName + ';' + txName), 'utf8')\n  var buf = new Buffer(md5sum.digest('base64'), 'base64')\n  // pull the low 4 bytes in network byte order\n  return buf.slice(buf.length - 4, buf.length).readUInt32BE(0)\n}\n\nexports.obfuscateNameUsingKey = obfuscateNameUsingKey\nexports.deobfuscateNameUsingKey = deobfuscateNameUsingKey\nexports.calculatePathHash = calculatePathHash\nexports.getHash = getHash\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/config.default.js":"'use strict'\n\n/**\n * This file includes all of the configuration variables used by the Node.js\n * module. If there's a configurable element of the module and it's not\n * described in here, there's been a terrible mistake.\n */\nexports.config = {\n  /**\n   * Array of application names.\n   *\n   * @env NEW_RELIC_APP_NAME\n   */\n  app_name: [],\n  /**\n   * The user's license key. Must be set by per-app configuration file.\n   *\n   * @env NEW_RELIC_LICENSE_KEY\n   */\n  license_key: '',\n  /**\n   * Hostname for the New Relic collector proxy.\n   *\n   * You shouldn't need to change this.\n   *\n   * @env NEW_RELIC_HOST\n   */\n  host: 'collector.newrelic.com',\n  /**\n   * The port on which the collector proxy will be listening.\n   *\n   * You shouldn't need to change this.\n   *\n   * @env NEW_RELIC_PORT\n   */\n  port: 443,\n  /**\n   * Whether or not to use SSL to connect to New Relic's servers.\n   *\n   * @env NEW_RELIC_USE_SSL\n   */\n  ssl: true,\n  /**\n   * Proxy url\n   *\n   * A proxy url can be used in place of setting\n   * proxy_host, proxy_port, proxy_user, and proxy_pass.\n   *\n   * e.g. http://user:pass@host:port/\n   *\n   * Setting proxy will override other proxy settings.\n   *\n   * @env NEW_RELIC_PROXY_URL\n   */\n  proxy: '',\n  /**\n   * Proxy host to use to connect to the internet.\n   *\n   * @env NEW_RELIC_PROXY_HOST\n   */\n  proxy_host: '',\n  /**\n   * Proxy port to use to connect to the internet.\n   *\n   * @env NEW_RELIC_PROXY_PORT\n   */\n  proxy_port: '',\n  /**\n   * Proxy user name when required.\n   *\n   * @env NEW_RELIC_PROXY_USER\n   */\n  proxy_user: '',\n  /**\n   * Proxy password when required.\n   *\n   * @env NEW_RELIC_PROXY_PASS\n   */\n  proxy_pass: '',\n  /**\n   * Custom SSL certificates\n   *\n   * If your proxy uses a custom SSL certificate, you can add the CA text to\n   * this array, one entry per certificate.\n   *\n   * The easiest way to do this is with `fs.readFileSync` e.g.\n   *\n   * certificates: [\n   *   require('fs').readFileSync('custom.crt', 'utf8') // don't forget the utf8\n   * ]\n   *\n   */\n  certificates: [],\n  /**\n   * You may want more control over how the module is configured and want to\n   * disallow the use of New Relic's server-side configuration. To do so, set\n   * this parameter to true. Some configuration information is required to make\n   * the module work properly with the rest of New Relic, but settings such as\n   * apdex_t and capture_params will not be override-able by New Relic with this\n   * setting in effect.\n   *\n   * @env NEW_RELIC_IGNORE_SERVER_CONFIGURATION\n   */\n  ignore_server_configuration: false,\n  /**\n   * Whether the module is enabled.\n   *\n   * @env NEW_RELIC_ENABLED\n   */\n  agent_enabled: true,\n  /**\n   * The default Apdex tolerating / threshold value for applications, in\n   * seconds. The default for Node is apdexT to 100 milliseconds, which is\n   * lower than New Relic standard, but Node.js applications tend to be more\n   * latency-sensitive than most.\n   *\n   * @env NEW_RELIC_APDEX\n   */\n  apdex_t: 0.100,\n  /**\n   * Whether to capture parameters in the request URL in slow transaction\n   * traces and error traces. Because this can pass sensitive data, it's\n   * disabled by default. If there are specific parameters you want ignored,\n   * use ignored_params.\n   *\n   * @env NEW_RELIC_CAPTURE_PARAMS\n   */\n  capture_params: false,\n  /**\n   * Array of parameters you don't want captured off request URLs in slow\n   * transaction traces and error traces.\n   *\n   * @env NEW_RELIC_IGNORED_PARAMS\n   */\n  ignored_params: [],\n  logging: {\n    /**\n     * Verbosity of the module's logging. This module uses bunyan\n     * (https://github.com/trentm/node-bunyan) for its logging, and as such the\n     * valid logging levels are 'fatal', 'error', 'warn', 'info', 'debug' and\n     * 'trace'. Logging at levels 'info' and higher is very terse. For support\n     * requests, attaching logs captured at 'trace' level are extremely helpful\n     * in chasing down bugs.\n     *\n     * @env NEW_RELIC_LOG_LEVEL\n     */\n    level: 'info',\n    /**\n     * Where to put the log file -- by default just uses process.cwd +\n     * 'newrelic_agent.log'. A special case is a filepath of 'stdout',\n     * in which case all logging will go to stdout, or 'stderr', in which\n     * case all logging will go to stderr.\n     *\n     * @env NEW_RELIC_LOG\n     */\n    filepath: require('path').join(process.cwd(), 'newrelic_agent.log'),\n    /**\n     * Whether to write to a log file at all\n     *\n     * @env NEW_RELIC_LOG_ENABLED\n     */\n    enabled: true,\n\n    /**\n     * Enables extra debugging at `warn` level. No need to enable except under\n     * specific debugging conditions.\n     */\n    diagnostics: false\n  },\n\n  audit_log: {\n\n    /**\n     * Enables logging of out bound traffic from the Agent to the Collector.\n     * This field is ignored if trace level logging is enabled.\n     * With trace logging, all traffic is logged.\n     *\n     * @env NEW_RELIC_AUDIT_LOG_ENABLED\n     */\n    enabled: false,\n\n    /**\n     * Specify which methods are logged. Used in conjuction with the audit_log flag\n     * If audit_log is enabled and this property is empty, all methods will be logged\n     * Otherwise, if the audit log is enabled, only the methods specified\n     * in the filter will be logged\n     * Methods include: error_data, metric_data, and analytic_event_data\n     *\n     * @env NEW_RELIC_AUDIT_LOG_ENDPOINTS\n     */\n    endpoints: []\n  },\n  /**\n   * Whether to collect & submit error traces to New Relic.\n   *\n   * @env NEW_RELIC_ERROR_COLLECTOR_ENABLED\n   */\n  error_collector: {\n    /**\n     * Disabling the error tracer just means that errors aren't collected\n     * and sent to New Relic -- it DOES NOT remove any instrumentation.\n     */\n    enabled: true,\n    /**\n     * List of HTTP error status codes the error tracer should disregard.\n     * Ignoring a status code means that the transaction is not renamed to\n     * match the code, and the request is not treated as an error by the error\n     * collector.\n     *\n     * NOTE: This configuration value has no effect on errors recorded using\n     * `noticeError()`.\n     *\n     * Defaults to 404 NOT FOUND.\n     *\n     * @env NEW_RELIC_ERROR_COLLECTOR_IGNORE_ERROR_CODES\n     */\n    ignore_status_codes: [404],\n    /**\n     * Whether error events are collected.\n     */\n    capture_events: true,\n    /**\n     * The agent will collect all error events up to this number per minute.\n     * If there are more than that, a statistical sampling will be collected.\n     * Currently this uses a reservoir sampling algorithm.\n     *\n     * By increasing this setting you are both increasing the memory\n     * requirements of the agent as well as increasing the payload to the New\n     * Relic servers. The memory concerns are something you should consider for\n     * your own server's sake. The payload of events is compressed, but if it\n     * grows too large the New Relic servers may reject it.\n     */\n    max_event_samples_stored: 100\n  },\n  /**\n   * Options regarding collecting system information. Used for system\n   * utilization based pricing scheme.\n   */\n  utilization: {\n    /**\n     * This flag dictates whether the agent attempts to reach out to AWS\n     * to get info about the vm the process is running on.\n     *\n     * @env NEW_RELIC_UTILIZATION_DETECT_AWS\n     */\n    detect_aws: true,\n    /**\n     * This flag dictates whether the agent attempts to reach out to AWS\n     * to get info about the container the process is running in.\n     *\n     * @env NEW_RELIC_UTILIZATION_DETECT_DOCKER\n     */\n    detect_docker: true\n  },\n  transaction_tracer: {\n    /**\n     * Whether to collect & submit slow transaction traces to New Relic. The\n     * instrumentation is loaded regardless of this setting, as it's necessary\n     * to gather metrics. Disable the agent to prevent the instrumentation from\n     * loading.\n     *\n     * @env NEW_RELIC_TRACER_ENABLED\n     */\n    enabled: true,\n    /**\n     * The duration at below which the slow transaction tracer should collect a\n     * transaction trace. If set to 'apdex_f', the threshold will be set to\n     * 4 * apdex_t, which with a default apdex_t value of 500 milliseconds will\n     * be 2 seconds.\n     *\n     * If a time is provided, it is set in seconds.\n     *\n     * @env NEW_RELIC_TRACER_THRESHOLD\n     */\n    transaction_threshold: 'apdex_f',\n    /**\n     * Increase this parameter to increase the diversity of the slow\n     * transaction traces recorded by your application over time. Confused?\n     * Read on.\n     *\n     * Transactions are named based on the request (see the README for the\n     * details of how requests are mapped to transactions), and top_n refers to\n     * the \"top n slowest transactions\" grouped by these names. The module will\n     * only replace a recorded trace with a new trace if the new trace is\n     * slower than the previous slowest trace of that name. The default value\n     * for this setting is 20, as the transaction trace view page also defaults\n     * to showing the 20 slowest transactions.\n     *\n     * If you want to record the absolute slowest transaction over the last\n     * minute, set top_n to 0 or 1. This used to be the default, and has a\n     * problem in that it will allow one very slow route to dominate your slow\n     * transaction traces.\n     *\n     * The module will always record at least 5 different slow transactions in\n     * the reporting periods after it starts up, and will reset its internal\n     * slow trace aggregator if no slow transactions have been recorded for the\n     * last 5 harvest cycles, restarting the aggregation process.\n     *\n     * @env NEW_RELIC_TRACER_TOP_N\n     */\n    top_n: 20,\n\n    /**\n     * This option affects both slow-queries and record_sql for transaction\n     * traces.  It can have one of 3 values: 'off', 'obfuscated' or 'raw'\n     * When it is 'off' no slow queries will be captured, and backtraces\n     * and sql will not be included in transaction traces.  If it is 'raw'\n     * or 'obfuscated' and other criteria (slow_sql.enabled etc) are met\n     * for a query. The raw or obfuscated sql will be included in the\n     * transaction trace and a slow query sample will be collected.\n     */\n    record_sql: 'off',\n\n    /**\n     * This option affects both slow-queries and record_sql for transaction\n     * traces.  This is the minimum duration a query must take (in ms) for it\n     * to be considered for for slow query and inclusion in transaction traces.\n     */\n    explain_threshold: 500\n  },\n  /**\n   * Whether to enable internal supportability metrics and diagnostics. You're\n   * welcome to turn these on, but they will probably be most useful to the\n   * New Relic node engineering team.\n   */\n  debug: {\n    /**\n     * Whether to collect and submit internal supportability metrics alongside\n     * application performance metrics.\n     *\n     * @env NEW_RELIC_DEBUG_METRICS\n     */\n    internal_metrics: false,\n    /**\n     * Traces the execution of the transaction tracer. Requires logging.level\n     * to be set to 'trace' to provide any useful output.\n     *\n     * WARNING: The tracer tracing data is likely only to be intelligible to a\n     * small number of people inside New Relic, so you should probably only\n     * enable tracer tracing if asked to by New Relic, because it will affect\n     * performance significantly.\n     *\n     * @env NEW_RELIC_DEBUG_TRACER\n     */\n    tracer_tracing: false\n  },\n  /**\n   * Rules for naming or ignoring transactions.\n   */\n  rules: {\n    /**\n     * A list of rules of the format {pattern: 'pattern', name: 'name'} for\n     * matching incoming request URLs and naming the associated New Relic\n     * transactions. Both pattern and name are required. Additional attributes\n     * are ignored. Patterns may have capture groups (following JavaScript\n     * conventions), and names will use $1-style replacement strings. See\n     * the documentation for addNamingRule for important caveats.\n     *\n     * @env NEW_RELIC_NAMING_RULES\n     */\n    name: [],\n    /**\n     * A list of patterns for matching incoming request URLs to be ignored by\n     * the agent. Patterns may be strings or regular expressions.\n     *\n     * By default, socket.io long-polling is ignored.\n     *\n     * @env NEW_RELIC_IGNORING_RULES\n     */\n    ignore: [\n      '^\\/socket\\.io\\/.*\\/xhr-polling/'\n    ]\n  },\n  /**\n   * By default, any transactions that are not affected by other bits of\n   * naming logic (the API, rules, or metric normalization rules) will\n   * have their names set to 'NormalizedUri/*'. Setting this value to\n   * false will set them instead to Uri/path/to/resource. Don't change\n   * this setting unless you understand the implications of New Relic's\n   * metric grouping issues and are confident your application isn't going\n   * to run afoul of them. Your application could end up getting black holed!\n   * Nobody wants that.\n   *\n   * @env NEW_RELIC_ENFORCE_BACKSTOP\n   */\n  enforce_backstop: true,\n  /**\n   * Browser Monitoring\n   *\n   * Browser monitoring lets you correlate transactions between the server and browser\n   * giving you accurate data on how long a page request takes, from request,\n   * through the server response, up until the actual page render completes.\n   */\n  browser_monitoring: {\n\n    /**\n     * Enable browser monitoring header generation.\n     *\n     * This does not auto-instrument, rather it enables the agent to generate headers.\n     * The newrelic module can generate the appropriate <script> header, but you must\n     * inject the header yourself, or use a module that does so.\n     *\n     * Usage:\n     *\n     *     var newrelic = require('newrelic');\n     *\n     *     router.get('/', function (req, res) {\n     *       var header = newrelic.getBrowserTimingHeader();\n     *       res.write(header)\n     *       // write the rest of the page\n     *     });\n     *\n     * This generates the <script>...</script> header necessary for Browser Monitoring\n     * This script must be manually injected into your templates, as high as possible\n     * in the header, but _after_ any X-UA-COMPATIBLE HTTP-EQUIV meta tags.\n     * Otherwise you may hurt IE!\n     *\n     * This method must be called _during_ a transaction, and must be called every\n     * time you want to generate the headers.\n     *\n     * Do *not* reuse the headers between users, or even between requests.\n     *\n     * @env NEW_RELIC_BROWSER_MONITOR_ENABLE\n     */\n    enable: true,\n\n    /**\n     * Request un-minified sources from the server.\n     *\n     * @env NEW_RELIC_BROWSER_MONITOR_DEBUG\n     */\n    debug: false\n  },\n  /**\n   * Transaction Events\n   *\n   * Transaction events are sent to New Relic Insights. This event data\n   * includes transaction timing, transaction name, and any custom parameters.\n   *\n   * Read more here: http://newrelic.com/insights\n   */\n  transaction_events: {\n    /**\n     * If this is disabled, the agent does not collect, nor try to send,\n     * analytic data.\n     */\n    enabled: true,\n\n    /**\n     * The agent will collect all events up to this number per minute. If\n     * there are more than that, a statistical sampling will be collected.\n     */\n    max_samples_per_minute: 10000,\n\n    /**\n     * This is used if the agent is unable to send events to the collector.\n     * The values from the previous harvest cycle will be merged into the next\n     * one with this option as the limit.\n     *\n     * This should be *greater* than max_samples_per_minute or you'll see odd\n     * behavior. You probably want at least double the value, but more is okay\n     * as long as you can handle the memory overhead.\n     */\n    max_samples_stored: 20000\n  },\n\n  /**\n   * Custom Insights Events\n   *\n   * Custom insights events are JSON object that are sent to New Relic\n   * Insights. You can tell the agent to send your custom events via the\n   * `newrelic.recordCustomEvent()` API. These events are sampled once the max\n   * reservoir size is reached. You can tune this setting below.\n   *\n   * Read more here: http://newrelic.com/insights\n   */\n  custom_insights_events: {\n    /**\n     * If this is disabled, the agent does not collect, nor try to send, custom\n     * event data.\n     */\n    enabled: true,\n    /**\n     * The agent will collect all events up to this number per minute. If there\n     * are more than that, a statistical sampling will be collected. Current\n     * this uses a reservoir sampling algorithm.\n     *\n     * By increasing this setting you are both increasing the memory\n     * requirements of the agent as well as increasing the payload to the New\n     * Relic servers. The memory concerns are something you should consider for\n     * your own server's sake. The payload of events is compressed, but if it\n     * grows too large the New Relic servers may reject it.\n     */\n    max_samples_stored: 1000\n  },\n  /**\n   * This is used to configure properties about the user's host name.\n   */\n  process_host: {\n     /**\n     * Configurable display name for hosts\n     *\n     * @env NEW_RELIC_PROCESS_HOST_DISPLAY_NAME\n     */\n    display_name: '',\n    /**\n     * ip address preference when creating hostnames\n     *\n     * @env NEW_RELIC_IPV_PREFERENCE\n     */\n    ipv_preference: '4'\n },\n\n\n  /**\n   * High Security\n   *\n   * High security mode (v2) is a setting which prevents any sensitive data from\n   * being sent to New Relic. The local setting must match the server setting.\n   * If there is a mismatch the agent will log a message and act as if it is\n   * disabled.\n   *\n   * Attributes of high security mode (when enabled):\n   *  * requires SSL\n   *  * does not allow capturing of http params\n   *  * does not allow custom params\n   *\n   * To read more see: https://docs.newrelic.com/docs/subscriptions/high-security\n   */\n  high_security: false,\n\n  /**\n   * Labels\n   *\n   * An object of label names and values that will be applied to the data sent\n   * from this agent. Both label names and label values have a maximum length of\n   * 255 characters. This object should contain at most 64 labels.\n   */\n  labels: {},\n\n  /**\n   * These options control behavior for slow queries, but do not affect sql\n   * nodes in transaction traces.\n   * slow_sql.enabled enables and disables slow_sql recording\n   * slow_sql.max_samples sets the maximum number of slow query samples that\n   * will be collected in a single harvest cycle.\n   */\n   slow_sql: {\n    enabled: false,\n    max_samples: 10\n  },\n\n  /**\n   * Controls behavior of datastore instance metrics.\n   *\n   * @property {bool} [instance_reporting.enabled=true]\n   *  Enables reporting the host and port/path/id of database servers. Default\n   *  is `true`.\n   *\n   * @property {bool} [database_name_reporting.enabled=true]\n   *  Enables reporting of database/schema names. Default is `true`.\n   */\n  datastore_tracer: {\n    instance_reporting: {enabled: true},\n    database_name_reporting: {enabled: true}\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/semver/semver.js":"exports = module.exports = SemVer;\n\n// The debug function is excluded entirely from the minified version.\n/* nomin */ var debug;\n/* nomin */ if (typeof process === 'object' &&\n    /* nomin */ process.env &&\n    /* nomin */ process.env.NODE_DEBUG &&\n    /* nomin */ /\\bsemver\\b/i.test(process.env.NODE_DEBUG))\n  /* nomin */ debug = function() {\n    /* nomin */ var args = Array.prototype.slice.call(arguments, 0);\n    /* nomin */ args.unshift('SEMVER');\n    /* nomin */ console.log.apply(console, args);\n    /* nomin */ };\n/* nomin */ else\n  /* nomin */ debug = function() {};\n\n// Note: this is the semver.org version of the spec that it implements\n// Not necessarily the package version of this code.\nexports.SEMVER_SPEC_VERSION = '2.0.0';\n\nvar MAX_LENGTH = 256;\nvar MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER || 9007199254740991;\n\n// The actual regexps go on exports.re\nvar re = exports.re = [];\nvar src = exports.src = [];\nvar R = 0;\n\n// The following Regular Expressions can be used for tokenizing,\n// validating, and parsing SemVer version strings.\n\n// ## Numeric Identifier\n// A single `0`, or a non-zero digit followed by zero or more digits.\n\nvar NUMERICIDENTIFIER = R++;\nsrc[NUMERICIDENTIFIER] = '0|[1-9]\\\\d*';\nvar NUMERICIDENTIFIERLOOSE = R++;\nsrc[NUMERICIDENTIFIERLOOSE] = '[0-9]+';\n\n\n// ## Non-numeric Identifier\n// Zero or more digits, followed by a letter or hyphen, and then zero or\n// more letters, digits, or hyphens.\n\nvar NONNUMERICIDENTIFIER = R++;\nsrc[NONNUMERICIDENTIFIER] = '\\\\d*[a-zA-Z-][a-zA-Z0-9-]*';\n\n\n// ## Main Version\n// Three dot-separated numeric identifiers.\n\nvar MAINVERSION = R++;\nsrc[MAINVERSION] = '(' + src[NUMERICIDENTIFIER] + ')\\\\.' +\n                   '(' + src[NUMERICIDENTIFIER] + ')\\\\.' +\n                   '(' + src[NUMERICIDENTIFIER] + ')';\n\nvar MAINVERSIONLOOSE = R++;\nsrc[MAINVERSIONLOOSE] = '(' + src[NUMERICIDENTIFIERLOOSE] + ')\\\\.' +\n                        '(' + src[NUMERICIDENTIFIERLOOSE] + ')\\\\.' +\n                        '(' + src[NUMERICIDENTIFIERLOOSE] + ')';\n\n// ## Pre-release Version Identifier\n// A numeric identifier, or a non-numeric identifier.\n\nvar PRERELEASEIDENTIFIER = R++;\nsrc[PRERELEASEIDENTIFIER] = '(?:' + src[NUMERICIDENTIFIER] +\n                            '|' + src[NONNUMERICIDENTIFIER] + ')';\n\nvar PRERELEASEIDENTIFIERLOOSE = R++;\nsrc[PRERELEASEIDENTIFIERLOOSE] = '(?:' + src[NUMERICIDENTIFIERLOOSE] +\n                                 '|' + src[NONNUMERICIDENTIFIER] + ')';\n\n\n// ## Pre-release Version\n// Hyphen, followed by one or more dot-separated pre-release version\n// identifiers.\n\nvar PRERELEASE = R++;\nsrc[PRERELEASE] = '(?:-(' + src[PRERELEASEIDENTIFIER] +\n                  '(?:\\\\.' + src[PRERELEASEIDENTIFIER] + ')*))';\n\nvar PRERELEASELOOSE = R++;\nsrc[PRERELEASELOOSE] = '(?:-?(' + src[PRERELEASEIDENTIFIERLOOSE] +\n                       '(?:\\\\.' + src[PRERELEASEIDENTIFIERLOOSE] + ')*))';\n\n// ## Build Metadata Identifier\n// Any combination of digits, letters, or hyphens.\n\nvar BUILDIDENTIFIER = R++;\nsrc[BUILDIDENTIFIER] = '[0-9A-Za-z-]+';\n\n// ## Build Metadata\n// Plus sign, followed by one or more period-separated build metadata\n// identifiers.\n\nvar BUILD = R++;\nsrc[BUILD] = '(?:\\\\+(' + src[BUILDIDENTIFIER] +\n             '(?:\\\\.' + src[BUILDIDENTIFIER] + ')*))';\n\n\n// ## Full Version String\n// A main version, followed optionally by a pre-release version and\n// build metadata.\n\n// Note that the only major, minor, patch, and pre-release sections of\n// the version string are capturing groups.  The build metadata is not a\n// capturing group, because it should not ever be used in version\n// comparison.\n\nvar FULL = R++;\nvar FULLPLAIN = 'v?' + src[MAINVERSION] +\n                src[PRERELEASE] + '?' +\n                src[BUILD] + '?';\n\nsrc[FULL] = '^' + FULLPLAIN + '$';\n\n// like full, but allows v1.2.3 and =1.2.3, which people do sometimes.\n// also, 1.0.0alpha1 (prerelease without the hyphen) which is pretty\n// common in the npm registry.\nvar LOOSEPLAIN = '[v=\\\\s]*' + src[MAINVERSIONLOOSE] +\n                 src[PRERELEASELOOSE] + '?' +\n                 src[BUILD] + '?';\n\nvar LOOSE = R++;\nsrc[LOOSE] = '^' + LOOSEPLAIN + '$';\n\nvar GTLT = R++;\nsrc[GTLT] = '((?:<|>)?=?)';\n\n// Something like \"2.*\" or \"1.2.x\".\n// Note that \"x.x\" is a valid xRange identifer, meaning \"any version\"\n// Only the first item is strictly required.\nvar XRANGEIDENTIFIERLOOSE = R++;\nsrc[XRANGEIDENTIFIERLOOSE] = src[NUMERICIDENTIFIERLOOSE] + '|x|X|\\\\*';\nvar XRANGEIDENTIFIER = R++;\nsrc[XRANGEIDENTIFIER] = src[NUMERICIDENTIFIER] + '|x|X|\\\\*';\n\nvar XRANGEPLAIN = R++;\nsrc[XRANGEPLAIN] = '[v=\\\\s]*(' + src[XRANGEIDENTIFIER] + ')' +\n                   '(?:\\\\.(' + src[XRANGEIDENTIFIER] + ')' +\n                   '(?:\\\\.(' + src[XRANGEIDENTIFIER] + ')' +\n                   '(?:' + src[PRERELEASE] + ')?' +\n                   src[BUILD] + '?' +\n                   ')?)?';\n\nvar XRANGEPLAINLOOSE = R++;\nsrc[XRANGEPLAINLOOSE] = '[v=\\\\s]*(' + src[XRANGEIDENTIFIERLOOSE] + ')' +\n                        '(?:\\\\.(' + src[XRANGEIDENTIFIERLOOSE] + ')' +\n                        '(?:\\\\.(' + src[XRANGEIDENTIFIERLOOSE] + ')' +\n                        '(?:' + src[PRERELEASELOOSE] + ')?' +\n                        src[BUILD] + '?' +\n                        ')?)?';\n\nvar XRANGE = R++;\nsrc[XRANGE] = '^' + src[GTLT] + '\\\\s*' + src[XRANGEPLAIN] + '$';\nvar XRANGELOOSE = R++;\nsrc[XRANGELOOSE] = '^' + src[GTLT] + '\\\\s*' + src[XRANGEPLAINLOOSE] + '$';\n\n// Tilde ranges.\n// Meaning is \"reasonably at or greater than\"\nvar LONETILDE = R++;\nsrc[LONETILDE] = '(?:~>?)';\n\nvar TILDETRIM = R++;\nsrc[TILDETRIM] = '(\\\\s*)' + src[LONETILDE] + '\\\\s+';\nre[TILDETRIM] = new RegExp(src[TILDETRIM], 'g');\nvar tildeTrimReplace = '$1~';\n\nvar TILDE = R++;\nsrc[TILDE] = '^' + src[LONETILDE] + src[XRANGEPLAIN] + '$';\nvar TILDELOOSE = R++;\nsrc[TILDELOOSE] = '^' + src[LONETILDE] + src[XRANGEPLAINLOOSE] + '$';\n\n// Caret ranges.\n// Meaning is \"at least and backwards compatible with\"\nvar LONECARET = R++;\nsrc[LONECARET] = '(?:\\\\^)';\n\nvar CARETTRIM = R++;\nsrc[CARETTRIM] = '(\\\\s*)' + src[LONECARET] + '\\\\s+';\nre[CARETTRIM] = new RegExp(src[CARETTRIM], 'g');\nvar caretTrimReplace = '$1^';\n\nvar CARET = R++;\nsrc[CARET] = '^' + src[LONECARET] + src[XRANGEPLAIN] + '$';\nvar CARETLOOSE = R++;\nsrc[CARETLOOSE] = '^' + src[LONECARET] + src[XRANGEPLAINLOOSE] + '$';\n\n// A simple gt/lt/eq thing, or just \"\" to indicate \"any version\"\nvar COMPARATORLOOSE = R++;\nsrc[COMPARATORLOOSE] = '^' + src[GTLT] + '\\\\s*(' + LOOSEPLAIN + ')$|^$';\nvar COMPARATOR = R++;\nsrc[COMPARATOR] = '^' + src[GTLT] + '\\\\s*(' + FULLPLAIN + ')$|^$';\n\n\n// An expression to strip any whitespace between the gtlt and the thing\n// it modifies, so that `> 1.2.3` ==> `>1.2.3`\nvar COMPARATORTRIM = R++;\nsrc[COMPARATORTRIM] = '(\\\\s*)' + src[GTLT] +\n                      '\\\\s*(' + LOOSEPLAIN + '|' + src[XRANGEPLAIN] + ')';\n\n// this one has to use the /g flag\nre[COMPARATORTRIM] = new RegExp(src[COMPARATORTRIM], 'g');\nvar comparatorTrimReplace = '$1$2$3';\n\n\n// Something like `1.2.3 - 1.2.4`\n// Note that these all use the loose form, because they'll be\n// checked against either the strict or loose comparator form\n// later.\nvar HYPHENRANGE = R++;\nsrc[HYPHENRANGE] = '^\\\\s*(' + src[XRANGEPLAIN] + ')' +\n                   '\\\\s+-\\\\s+' +\n                   '(' + src[XRANGEPLAIN] + ')' +\n                   '\\\\s*$';\n\nvar HYPHENRANGELOOSE = R++;\nsrc[HYPHENRANGELOOSE] = '^\\\\s*(' + src[XRANGEPLAINLOOSE] + ')' +\n                        '\\\\s+-\\\\s+' +\n                        '(' + src[XRANGEPLAINLOOSE] + ')' +\n                        '\\\\s*$';\n\n// Star ranges basically just allow anything at all.\nvar STAR = R++;\nsrc[STAR] = '(<|>)?=?\\\\s*\\\\*';\n\n// Compile to actual regexp objects.\n// All are flag-free, unless they were created above with a flag.\nfor (var i = 0; i < R; i++) {\n  debug(i, src[i]);\n  if (!re[i])\n    re[i] = new RegExp(src[i]);\n}\n\nexports.parse = parse;\nfunction parse(version, loose) {\n  if (version instanceof SemVer)\n    return version;\n\n  if (typeof version !== 'string')\n    return null;\n\n  if (version.length > MAX_LENGTH)\n    return null;\n\n  var r = loose ? re[LOOSE] : re[FULL];\n  if (!r.test(version))\n    return null;\n\n  try {\n    return new SemVer(version, loose);\n  } catch (er) {\n    return null;\n  }\n}\n\nexports.valid = valid;\nfunction valid(version, loose) {\n  var v = parse(version, loose);\n  return v ? v.version : null;\n}\n\n\nexports.clean = clean;\nfunction clean(version, loose) {\n  var s = parse(version.trim().replace(/^[=v]+/, ''), loose);\n  return s ? s.version : null;\n}\n\nexports.SemVer = SemVer;\n\nfunction SemVer(version, loose) {\n  if (version instanceof SemVer) {\n    if (version.loose === loose)\n      return version;\n    else\n      version = version.version;\n  } else if (typeof version !== 'string') {\n    throw new TypeError('Invalid Version: ' + version);\n  }\n\n  if (version.length > MAX_LENGTH)\n    throw new TypeError('version is longer than ' + MAX_LENGTH + ' characters')\n\n  if (!(this instanceof SemVer))\n    return new SemVer(version, loose);\n\n  debug('SemVer', version, loose);\n  this.loose = loose;\n  var m = version.trim().match(loose ? re[LOOSE] : re[FULL]);\n\n  if (!m)\n    throw new TypeError('Invalid Version: ' + version);\n\n  this.raw = version;\n\n  // these are actually numbers\n  this.major = +m[1];\n  this.minor = +m[2];\n  this.patch = +m[3];\n\n  if (this.major > MAX_SAFE_INTEGER || this.major < 0)\n    throw new TypeError('Invalid major version')\n\n  if (this.minor > MAX_SAFE_INTEGER || this.minor < 0)\n    throw new TypeError('Invalid minor version')\n\n  if (this.patch > MAX_SAFE_INTEGER || this.patch < 0)\n    throw new TypeError('Invalid patch version')\n\n  // numberify any prerelease numeric ids\n  if (!m[4])\n    this.prerelease = [];\n  else\n    this.prerelease = m[4].split('.').map(function(id) {\n      if (/^[0-9]+$/.test(id)) {\n        var num = +id;\n        if (num >= 0 && num < MAX_SAFE_INTEGER)\n          return num;\n      }\n      return id;\n    });\n\n  this.build = m[5] ? m[5].split('.') : [];\n  this.format();\n}\n\nSemVer.prototype.format = function() {\n  this.version = this.major + '.' + this.minor + '.' + this.patch;\n  if (this.prerelease.length)\n    this.version += '-' + this.prerelease.join('.');\n  return this.version;\n};\n\nSemVer.prototype.toString = function() {\n  return this.version;\n};\n\nSemVer.prototype.compare = function(other) {\n  debug('SemVer.compare', this.version, this.loose, other);\n  if (!(other instanceof SemVer))\n    other = new SemVer(other, this.loose);\n\n  return this.compareMain(other) || this.comparePre(other);\n};\n\nSemVer.prototype.compareMain = function(other) {\n  if (!(other instanceof SemVer))\n    other = new SemVer(other, this.loose);\n\n  return compareIdentifiers(this.major, other.major) ||\n         compareIdentifiers(this.minor, other.minor) ||\n         compareIdentifiers(this.patch, other.patch);\n};\n\nSemVer.prototype.comparePre = function(other) {\n  if (!(other instanceof SemVer))\n    other = new SemVer(other, this.loose);\n\n  // NOT having a prerelease is > having one\n  if (this.prerelease.length && !other.prerelease.length)\n    return -1;\n  else if (!this.prerelease.length && other.prerelease.length)\n    return 1;\n  else if (!this.prerelease.length && !other.prerelease.length)\n    return 0;\n\n  var i = 0;\n  do {\n    var a = this.prerelease[i];\n    var b = other.prerelease[i];\n    debug('prerelease compare', i, a, b);\n    if (a === undefined && b === undefined)\n      return 0;\n    else if (b === undefined)\n      return 1;\n    else if (a === undefined)\n      return -1;\n    else if (a === b)\n      continue;\n    else\n      return compareIdentifiers(a, b);\n  } while (++i);\n};\n\n// preminor will bump the version up to the next minor release, and immediately\n// down to pre-release. premajor and prepatch work the same way.\nSemVer.prototype.inc = function(release, identifier) {\n  switch (release) {\n    case 'premajor':\n      this.prerelease.length = 0;\n      this.patch = 0;\n      this.minor = 0;\n      this.major++;\n      this.inc('pre', identifier);\n      break;\n    case 'preminor':\n      this.prerelease.length = 0;\n      this.patch = 0;\n      this.minor++;\n      this.inc('pre', identifier);\n      break;\n    case 'prepatch':\n      // If this is already a prerelease, it will bump to the next version\n      // drop any prereleases that might already exist, since they are not\n      // relevant at this point.\n      this.prerelease.length = 0;\n      this.inc('patch', identifier);\n      this.inc('pre', identifier);\n      break;\n    // If the input is a non-prerelease version, this acts the same as\n    // prepatch.\n    case 'prerelease':\n      if (this.prerelease.length === 0)\n        this.inc('patch', identifier);\n      this.inc('pre', identifier);\n      break;\n\n    case 'major':\n      // If this is a pre-major version, bump up to the same major version.\n      // Otherwise increment major.\n      // 1.0.0-5 bumps to 1.0.0\n      // 1.1.0 bumps to 2.0.0\n      if (this.minor !== 0 || this.patch !== 0 || this.prerelease.length === 0)\n        this.major++;\n      this.minor = 0;\n      this.patch = 0;\n      this.prerelease = [];\n      break;\n    case 'minor':\n      // If this is a pre-minor version, bump up to the same minor version.\n      // Otherwise increment minor.\n      // 1.2.0-5 bumps to 1.2.0\n      // 1.2.1 bumps to 1.3.0\n      if (this.patch !== 0 || this.prerelease.length === 0)\n        this.minor++;\n      this.patch = 0;\n      this.prerelease = [];\n      break;\n    case 'patch':\n      // If this is not a pre-release version, it will increment the patch.\n      // If it is a pre-release it will bump up to the same patch version.\n      // 1.2.0-5 patches to 1.2.0\n      // 1.2.0 patches to 1.2.1\n      if (this.prerelease.length === 0)\n        this.patch++;\n      this.prerelease = [];\n      break;\n    // This probably shouldn't be used publicly.\n    // 1.0.0 \"pre\" would become 1.0.0-0 which is the wrong direction.\n    case 'pre':\n      if (this.prerelease.length === 0)\n        this.prerelease = [0];\n      else {\n        var i = this.prerelease.length;\n        while (--i >= 0) {\n          if (typeof this.prerelease[i] === 'number') {\n            this.prerelease[i]++;\n            i = -2;\n          }\n        }\n        if (i === -1) // didn't increment anything\n          this.prerelease.push(0);\n      }\n      if (identifier) {\n        // 1.2.0-beta.1 bumps to 1.2.0-beta.2,\n        // 1.2.0-beta.fooblz or 1.2.0-beta bumps to 1.2.0-beta.0\n        if (this.prerelease[0] === identifier) {\n          if (isNaN(this.prerelease[1]))\n            this.prerelease = [identifier, 0];\n        } else\n          this.prerelease = [identifier, 0];\n      }\n      break;\n\n    default:\n      throw new Error('invalid increment argument: ' + release);\n  }\n  this.format();\n  this.raw = this.version;\n  return this;\n};\n\nexports.inc = inc;\nfunction inc(version, release, loose, identifier) {\n  if (typeof(loose) === 'string') {\n    identifier = loose;\n    loose = undefined;\n  }\n\n  try {\n    return new SemVer(version, loose).inc(release, identifier).version;\n  } catch (er) {\n    return null;\n  }\n}\n\nexports.diff = diff;\nfunction diff(version1, version2) {\n  if (eq(version1, version2)) {\n    return null;\n  } else {\n    var v1 = parse(version1);\n    var v2 = parse(version2);\n    if (v1.prerelease.length || v2.prerelease.length) {\n      for (var key in v1) {\n        if (key === 'major' || key === 'minor' || key === 'patch') {\n          if (v1[key] !== v2[key]) {\n            return 'pre'+key;\n          }\n        }\n      }\n      return 'prerelease';\n    }\n    for (var key in v1) {\n      if (key === 'major' || key === 'minor' || key === 'patch') {\n        if (v1[key] !== v2[key]) {\n          return key;\n        }\n      }\n    }\n  }\n}\n\nexports.compareIdentifiers = compareIdentifiers;\n\nvar numeric = /^[0-9]+$/;\nfunction compareIdentifiers(a, b) {\n  var anum = numeric.test(a);\n  var bnum = numeric.test(b);\n\n  if (anum && bnum) {\n    a = +a;\n    b = +b;\n  }\n\n  return (anum && !bnum) ? -1 :\n         (bnum && !anum) ? 1 :\n         a < b ? -1 :\n         a > b ? 1 :\n         0;\n}\n\nexports.rcompareIdentifiers = rcompareIdentifiers;\nfunction rcompareIdentifiers(a, b) {\n  return compareIdentifiers(b, a);\n}\n\nexports.major = major;\nfunction major(a, loose) {\n  return new SemVer(a, loose).major;\n}\n\nexports.minor = minor;\nfunction minor(a, loose) {\n  return new SemVer(a, loose).minor;\n}\n\nexports.patch = patch;\nfunction patch(a, loose) {\n  return new SemVer(a, loose).patch;\n}\n\nexports.compare = compare;\nfunction compare(a, b, loose) {\n  return new SemVer(a, loose).compare(b);\n}\n\nexports.compareLoose = compareLoose;\nfunction compareLoose(a, b) {\n  return compare(a, b, true);\n}\n\nexports.rcompare = rcompare;\nfunction rcompare(a, b, loose) {\n  return compare(b, a, loose);\n}\n\nexports.sort = sort;\nfunction sort(list, loose) {\n  return list.sort(function(a, b) {\n    return exports.compare(a, b, loose);\n  });\n}\n\nexports.rsort = rsort;\nfunction rsort(list, loose) {\n  return list.sort(function(a, b) {\n    return exports.rcompare(a, b, loose);\n  });\n}\n\nexports.gt = gt;\nfunction gt(a, b, loose) {\n  return compare(a, b, loose) > 0;\n}\n\nexports.lt = lt;\nfunction lt(a, b, loose) {\n  return compare(a, b, loose) < 0;\n}\n\nexports.eq = eq;\nfunction eq(a, b, loose) {\n  return compare(a, b, loose) === 0;\n}\n\nexports.neq = neq;\nfunction neq(a, b, loose) {\n  return compare(a, b, loose) !== 0;\n}\n\nexports.gte = gte;\nfunction gte(a, b, loose) {\n  return compare(a, b, loose) >= 0;\n}\n\nexports.lte = lte;\nfunction lte(a, b, loose) {\n  return compare(a, b, loose) <= 0;\n}\n\nexports.cmp = cmp;\nfunction cmp(a, op, b, loose) {\n  var ret;\n  switch (op) {\n    case '===':\n      if (typeof a === 'object') a = a.version;\n      if (typeof b === 'object') b = b.version;\n      ret = a === b;\n      break;\n    case '!==':\n      if (typeof a === 'object') a = a.version;\n      if (typeof b === 'object') b = b.version;\n      ret = a !== b;\n      break;\n    case '': case '=': case '==': ret = eq(a, b, loose); break;\n    case '!=': ret = neq(a, b, loose); break;\n    case '>': ret = gt(a, b, loose); break;\n    case '>=': ret = gte(a, b, loose); break;\n    case '<': ret = lt(a, b, loose); break;\n    case '<=': ret = lte(a, b, loose); break;\n    default: throw new TypeError('Invalid operator: ' + op);\n  }\n  return ret;\n}\n\nexports.Comparator = Comparator;\nfunction Comparator(comp, loose) {\n  if (comp instanceof Comparator) {\n    if (comp.loose === loose)\n      return comp;\n    else\n      comp = comp.value;\n  }\n\n  if (!(this instanceof Comparator))\n    return new Comparator(comp, loose);\n\n  debug('comparator', comp, loose);\n  this.loose = loose;\n  this.parse(comp);\n\n  if (this.semver === ANY)\n    this.value = '';\n  else\n    this.value = this.operator + this.semver.version;\n\n  debug('comp', this);\n}\n\nvar ANY = {};\nComparator.prototype.parse = function(comp) {\n  var r = this.loose ? re[COMPARATORLOOSE] : re[COMPARATOR];\n  var m = comp.match(r);\n\n  if (!m)\n    throw new TypeError('Invalid comparator: ' + comp);\n\n  this.operator = m[1];\n  if (this.operator === '=')\n    this.operator = '';\n\n  // if it literally is just '>' or '' then allow anything.\n  if (!m[2])\n    this.semver = ANY;\n  else\n    this.semver = new SemVer(m[2], this.loose);\n};\n\nComparator.prototype.toString = function() {\n  return this.value;\n};\n\nComparator.prototype.test = function(version) {\n  debug('Comparator.test', version, this.loose);\n\n  if (this.semver === ANY)\n    return true;\n\n  if (typeof version === 'string')\n    version = new SemVer(version, this.loose);\n\n  return cmp(version, this.operator, this.semver, this.loose);\n};\n\n\nexports.Range = Range;\nfunction Range(range, loose) {\n  if ((range instanceof Range) && range.loose === loose)\n    return range;\n\n  if (!(this instanceof Range))\n    return new Range(range, loose);\n\n  this.loose = loose;\n\n  // First, split based on boolean or ||\n  this.raw = range;\n  this.set = range.split(/\\s*\\|\\|\\s*/).map(function(range) {\n    return this.parseRange(range.trim());\n  }, this).filter(function(c) {\n    // throw out any that are not relevant for whatever reason\n    return c.length;\n  });\n\n  if (!this.set.length) {\n    throw new TypeError('Invalid SemVer Range: ' + range);\n  }\n\n  this.format();\n}\n\nRange.prototype.format = function() {\n  this.range = this.set.map(function(comps) {\n    return comps.join(' ').trim();\n  }).join('||').trim();\n  return this.range;\n};\n\nRange.prototype.toString = function() {\n  return this.range;\n};\n\nRange.prototype.parseRange = function(range) {\n  var loose = this.loose;\n  range = range.trim();\n  debug('range', range, loose);\n  // `1.2.3 - 1.2.4` => `>=1.2.3 <=1.2.4`\n  var hr = loose ? re[HYPHENRANGELOOSE] : re[HYPHENRANGE];\n  range = range.replace(hr, hyphenReplace);\n  debug('hyphen replace', range);\n  // `> 1.2.3 < 1.2.5` => `>1.2.3 <1.2.5`\n  range = range.replace(re[COMPARATORTRIM], comparatorTrimReplace);\n  debug('comparator trim', range, re[COMPARATORTRIM]);\n\n  // `~ 1.2.3` => `~1.2.3`\n  range = range.replace(re[TILDETRIM], tildeTrimReplace);\n\n  // `^ 1.2.3` => `^1.2.3`\n  range = range.replace(re[CARETTRIM], caretTrimReplace);\n\n  // normalize spaces\n  range = range.split(/\\s+/).join(' ');\n\n  // At this point, the range is completely trimmed and\n  // ready to be split into comparators.\n\n  var compRe = loose ? re[COMPARATORLOOSE] : re[COMPARATOR];\n  var set = range.split(' ').map(function(comp) {\n    return parseComparator(comp, loose);\n  }).join(' ').split(/\\s+/);\n  if (this.loose) {\n    // in loose mode, throw out any that are not valid comparators\n    set = set.filter(function(comp) {\n      return !!comp.match(compRe);\n    });\n  }\n  set = set.map(function(comp) {\n    return new Comparator(comp, loose);\n  });\n\n  return set;\n};\n\n// Mostly just for testing and legacy API reasons\nexports.toComparators = toComparators;\nfunction toComparators(range, loose) {\n  return new Range(range, loose).set.map(function(comp) {\n    return comp.map(function(c) {\n      return c.value;\n    }).join(' ').trim().split(' ');\n  });\n}\n\n// comprised of xranges, tildes, stars, and gtlt's at this point.\n// already replaced the hyphen ranges\n// turn into a set of JUST comparators.\nfunction parseComparator(comp, loose) {\n  debug('comp', comp);\n  comp = replaceCarets(comp, loose);\n  debug('caret', comp);\n  comp = replaceTildes(comp, loose);\n  debug('tildes', comp);\n  comp = replaceXRanges(comp, loose);\n  debug('xrange', comp);\n  comp = replaceStars(comp, loose);\n  debug('stars', comp);\n  return comp;\n}\n\nfunction isX(id) {\n  return !id || id.toLowerCase() === 'x' || id === '*';\n}\n\n// ~, ~> --> * (any, kinda silly)\n// ~2, ~2.x, ~2.x.x, ~>2, ~>2.x ~>2.x.x --> >=2.0.0 <3.0.0\n// ~2.0, ~2.0.x, ~>2.0, ~>2.0.x --> >=2.0.0 <2.1.0\n// ~1.2, ~1.2.x, ~>1.2, ~>1.2.x --> >=1.2.0 <1.3.0\n// ~1.2.3, ~>1.2.3 --> >=1.2.3 <1.3.0\n// ~1.2.0, ~>1.2.0 --> >=1.2.0 <1.3.0\nfunction replaceTildes(comp, loose) {\n  return comp.trim().split(/\\s+/).map(function(comp) {\n    return replaceTilde(comp, loose);\n  }).join(' ');\n}\n\nfunction replaceTilde(comp, loose) {\n  var r = loose ? re[TILDELOOSE] : re[TILDE];\n  return comp.replace(r, function(_, M, m, p, pr) {\n    debug('tilde', comp, _, M, m, p, pr);\n    var ret;\n\n    if (isX(M))\n      ret = '';\n    else if (isX(m))\n      ret = '>=' + M + '.0.0 <' + (+M + 1) + '.0.0';\n    else if (isX(p))\n      // ~1.2 == >=1.2.0 <1.3.0\n      ret = '>=' + M + '.' + m + '.0 <' + M + '.' + (+m + 1) + '.0';\n    else if (pr) {\n      debug('replaceTilde pr', pr);\n      if (pr.charAt(0) !== '-')\n        pr = '-' + pr;\n      ret = '>=' + M + '.' + m + '.' + p + pr +\n            ' <' + M + '.' + (+m + 1) + '.0';\n    } else\n      // ~1.2.3 == >=1.2.3 <1.3.0\n      ret = '>=' + M + '.' + m + '.' + p +\n            ' <' + M + '.' + (+m + 1) + '.0';\n\n    debug('tilde return', ret);\n    return ret;\n  });\n}\n\n// ^ --> * (any, kinda silly)\n// ^2, ^2.x, ^2.x.x --> >=2.0.0 <3.0.0\n// ^2.0, ^2.0.x --> >=2.0.0 <3.0.0\n// ^1.2, ^1.2.x --> >=1.2.0 <2.0.0\n// ^1.2.3 --> >=1.2.3 <2.0.0\n// ^1.2.0 --> >=1.2.0 <2.0.0\nfunction replaceCarets(comp, loose) {\n  return comp.trim().split(/\\s+/).map(function(comp) {\n    return replaceCaret(comp, loose);\n  }).join(' ');\n}\n\nfunction replaceCaret(comp, loose) {\n  debug('caret', comp, loose);\n  var r = loose ? re[CARETLOOSE] : re[CARET];\n  return comp.replace(r, function(_, M, m, p, pr) {\n    debug('caret', comp, _, M, m, p, pr);\n    var ret;\n\n    if (isX(M))\n      ret = '';\n    else if (isX(m))\n      ret = '>=' + M + '.0.0 <' + (+M + 1) + '.0.0';\n    else if (isX(p)) {\n      if (M === '0')\n        ret = '>=' + M + '.' + m + '.0 <' + M + '.' + (+m + 1) + '.0';\n      else\n        ret = '>=' + M + '.' + m + '.0 <' + (+M + 1) + '.0.0';\n    } else if (pr) {\n      debug('replaceCaret pr', pr);\n      if (pr.charAt(0) !== '-')\n        pr = '-' + pr;\n      if (M === '0') {\n        if (m === '0')\n          ret = '>=' + M + '.' + m + '.' + p + pr +\n                ' <' + M + '.' + m + '.' + (+p + 1);\n        else\n          ret = '>=' + M + '.' + m + '.' + p + pr +\n                ' <' + M + '.' + (+m + 1) + '.0';\n      } else\n        ret = '>=' + M + '.' + m + '.' + p + pr +\n              ' <' + (+M + 1) + '.0.0';\n    } else {\n      debug('no pr');\n      if (M === '0') {\n        if (m === '0')\n          ret = '>=' + M + '.' + m + '.' + p +\n                ' <' + M + '.' + m + '.' + (+p + 1);\n        else\n          ret = '>=' + M + '.' + m + '.' + p +\n                ' <' + M + '.' + (+m + 1) + '.0';\n      } else\n        ret = '>=' + M + '.' + m + '.' + p +\n              ' <' + (+M + 1) + '.0.0';\n    }\n\n    debug('caret return', ret);\n    return ret;\n  });\n}\n\nfunction replaceXRanges(comp, loose) {\n  debug('replaceXRanges', comp, loose);\n  return comp.split(/\\s+/).map(function(comp) {\n    return replaceXRange(comp, loose);\n  }).join(' ');\n}\n\nfunction replaceXRange(comp, loose) {\n  comp = comp.trim();\n  var r = loose ? re[XRANGELOOSE] : re[XRANGE];\n  return comp.replace(r, function(ret, gtlt, M, m, p, pr) {\n    debug('xRange', comp, ret, gtlt, M, m, p, pr);\n    var xM = isX(M);\n    var xm = xM || isX(m);\n    var xp = xm || isX(p);\n    var anyX = xp;\n\n    if (gtlt === '=' && anyX)\n      gtlt = '';\n\n    if (xM) {\n      if (gtlt === '>' || gtlt === '<') {\n        // nothing is allowed\n        ret = '<0.0.0';\n      } else {\n        // nothing is forbidden\n        ret = '*';\n      }\n    } else if (gtlt && anyX) {\n      // replace X with 0\n      if (xm)\n        m = 0;\n      if (xp)\n        p = 0;\n\n      if (gtlt === '>') {\n        // >1 => >=2.0.0\n        // >1.2 => >=1.3.0\n        // >1.2.3 => >= 1.2.4\n        gtlt = '>=';\n        if (xm) {\n          M = +M + 1;\n          m = 0;\n          p = 0;\n        } else if (xp) {\n          m = +m + 1;\n          p = 0;\n        }\n      } else if (gtlt === '<=') {\n        // <=0.7.x is actually <0.8.0, since any 0.7.x should\n        // pass.  Similarly, <=7.x is actually <8.0.0, etc.\n        gtlt = '<';\n        if (xm)\n          M = +M + 1;\n        else\n          m = +m + 1;\n      }\n\n      ret = gtlt + M + '.' + m + '.' + p;\n    } else if (xm) {\n      ret = '>=' + M + '.0.0 <' + (+M + 1) + '.0.0';\n    } else if (xp) {\n      ret = '>=' + M + '.' + m + '.0 <' + M + '.' + (+m + 1) + '.0';\n    }\n\n    debug('xRange return', ret);\n\n    return ret;\n  });\n}\n\n// Because * is AND-ed with everything else in the comparator,\n// and '' means \"any version\", just remove the *s entirely.\nfunction replaceStars(comp, loose) {\n  debug('replaceStars', comp, loose);\n  // Looseness is ignored here.  star is always as loose as it gets!\n  return comp.trim().replace(re[STAR], '');\n}\n\n// This function is passed to string.replace(re[HYPHENRANGE])\n// M, m, patch, prerelease, build\n// 1.2 - 3.4.5 => >=1.2.0 <=3.4.5\n// 1.2.3 - 3.4 => >=1.2.0 <3.5.0 Any 3.4.x will do\n// 1.2 - 3.4 => >=1.2.0 <3.5.0\nfunction hyphenReplace($0,\n                       from, fM, fm, fp, fpr, fb,\n                       to, tM, tm, tp, tpr, tb) {\n\n  if (isX(fM))\n    from = '';\n  else if (isX(fm))\n    from = '>=' + fM + '.0.0';\n  else if (isX(fp))\n    from = '>=' + fM + '.' + fm + '.0';\n  else\n    from = '>=' + from;\n\n  if (isX(tM))\n    to = '';\n  else if (isX(tm))\n    to = '<' + (+tM + 1) + '.0.0';\n  else if (isX(tp))\n    to = '<' + tM + '.' + (+tm + 1) + '.0';\n  else if (tpr)\n    to = '<=' + tM + '.' + tm + '.' + tp + '-' + tpr;\n  else\n    to = '<=' + to;\n\n  return (from + ' ' + to).trim();\n}\n\n\n// if ANY of the sets match ALL of its comparators, then pass\nRange.prototype.test = function(version) {\n  if (!version)\n    return false;\n\n  if (typeof version === 'string')\n    version = new SemVer(version, this.loose);\n\n  for (var i = 0; i < this.set.length; i++) {\n    if (testSet(this.set[i], version))\n      return true;\n  }\n  return false;\n};\n\nfunction testSet(set, version) {\n  for (var i = 0; i < set.length; i++) {\n    if (!set[i].test(version))\n      return false;\n  }\n\n  if (version.prerelease.length) {\n    // Find the set of versions that are allowed to have prereleases\n    // For example, ^1.2.3-pr.1 desugars to >=1.2.3-pr.1 <2.0.0\n    // That should allow `1.2.3-pr.2` to pass.\n    // However, `1.2.4-alpha.notready` should NOT be allowed,\n    // even though it's within the range set by the comparators.\n    for (var i = 0; i < set.length; i++) {\n      debug(set[i].semver);\n      if (set[i].semver === ANY)\n        continue;\n\n      if (set[i].semver.prerelease.length > 0) {\n        var allowed = set[i].semver;\n        if (allowed.major === version.major &&\n            allowed.minor === version.minor &&\n            allowed.patch === version.patch)\n          return true;\n      }\n    }\n\n    // Version has a -pre, but it's not one of the ones we like.\n    return false;\n  }\n\n  return true;\n}\n\nexports.satisfies = satisfies;\nfunction satisfies(version, range, loose) {\n  try {\n    range = new Range(range, loose);\n  } catch (er) {\n    return false;\n  }\n  return range.test(version);\n}\n\nexports.maxSatisfying = maxSatisfying;\nfunction maxSatisfying(versions, range, loose) {\n  return versions.filter(function(version) {\n    return satisfies(version, range, loose);\n  }).sort(function(a, b) {\n    return rcompare(a, b, loose);\n  })[0] || null;\n}\n\nexports.minSatisfying = minSatisfying;\nfunction minSatisfying(versions, range, loose) {\n  return versions.filter(function(version) {\n    return satisfies(version, range, loose);\n  }).sort(function(a, b) {\n    return compare(a, b, loose);\n  })[0] || null;\n}\n\nexports.validRange = validRange;\nfunction validRange(range, loose) {\n  try {\n    // Return '*' instead of '' so that truthiness works.\n    // This will throw if it's invalid anyway\n    return new Range(range, loose).range || '*';\n  } catch (er) {\n    return null;\n  }\n}\n\n// Determine if version is less than all the versions possible in the range\nexports.ltr = ltr;\nfunction ltr(version, range, loose) {\n  return outside(version, range, '<', loose);\n}\n\n// Determine if version is greater than all the versions possible in the range.\nexports.gtr = gtr;\nfunction gtr(version, range, loose) {\n  return outside(version, range, '>', loose);\n}\n\nexports.outside = outside;\nfunction outside(version, range, hilo, loose) {\n  version = new SemVer(version, loose);\n  range = new Range(range, loose);\n\n  var gtfn, ltefn, ltfn, comp, ecomp;\n  switch (hilo) {\n    case '>':\n      gtfn = gt;\n      ltefn = lte;\n      ltfn = lt;\n      comp = '>';\n      ecomp = '>=';\n      break;\n    case '<':\n      gtfn = lt;\n      ltefn = gte;\n      ltfn = gt;\n      comp = '<';\n      ecomp = '<=';\n      break;\n    default:\n      throw new TypeError('Must provide a hilo val of \"<\" or \">\"');\n  }\n\n  // If it satisifes the range it is not outside\n  if (satisfies(version, range, loose)) {\n    return false;\n  }\n\n  // From now on, variable terms are as if we're in \"gtr\" mode.\n  // but note that everything is flipped for the \"ltr\" function.\n\n  for (var i = 0; i < range.set.length; ++i) {\n    var comparators = range.set[i];\n\n    var high = null;\n    var low = null;\n\n    comparators.forEach(function(comparator) {\n      if (comparator.semver === ANY) {\n        comparator = new Comparator('>=0.0.0')\n      }\n      high = high || comparator;\n      low = low || comparator;\n      if (gtfn(comparator.semver, high.semver, loose)) {\n        high = comparator;\n      } else if (ltfn(comparator.semver, low.semver, loose)) {\n        low = comparator;\n      }\n    });\n\n    // If the edge version comparator has a operator then our version\n    // isn't outside it\n    if (high.operator === comp || high.operator === ecomp) {\n      return false;\n    }\n\n    // If the lowest version comparator has an operator and our version\n    // is less than it then it isn't higher than the range\n    if ((!low.operator || low.operator === comp) &&\n        ltefn(version, low.semver)) {\n      return false;\n    } else if (low.operator === ecomp && ltfn(version, low.semver)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexports.prerelease = prerelease;\nfunction prerelease(version, loose) {\n  var parsed = parse(version, loose);\n  return (parsed && parsed.prerelease.length) ? parsed.prerelease : null;\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/stub_api.js":"'use strict'\n\nvar logger = require('./lib/logger.js')\nvar RealAPI = require('./api.js')\n\n\n/* eslint-disable no-eval */\nfunction stubFunction(name) {\n  return eval(\"(function () {return function \" + name + \"() {\" +\n              \"logger.debug('Not calling \" + name + \" because New Relic is disabled.');\" +\n              \"}}())\")\n}\n/* eslint-enable no-eval */\n\nfunction Stub() {}\n\nvar keys = Object.keys(RealAPI.prototype)\nvar length = keys.length\n\n\n/* This way the stub API doesn't have to be updated in lockstep with the regular\n * API.\n */\nfor (var i = 0; i < length; i++) {\n  var functionName = keys[i]\n  Stub.prototype[functionName] = stubFunction(functionName)\n}\n\nStub.prototype.createTracer = createTracer\nStub.prototype.createWebTransaction = createWebTransaction\nStub.prototype.createBackgroundTransaction = createBackgroundTransaction\nStub.prototype.getBrowserTimingHeader = getBrowserTimingHeader\nStub.prototype.shutdown = shutdown\n\n// This code gets injected into HTML templates\n// and we don't want it to return undefined/null.\nfunction getBrowserTimingHeader() {\n  logger.debug('Not calling getBrowserTimingHeader because New Relic is disabled.')\n  return ''\n}\n\n// Normally the following 3 calls return a wrapped callback, instead we\n// should just return the callback in its unwrapped state.\nfunction createTracer(name, callback) {\n  logger.debug('Not calling createTracer because New Relic is disabled.')\n  return callback\n}\n\nfunction createWebTransaction(url, callback) {\n  logger.debug('Not calling createWebTransaction because New Relic is disabled.')\n  return callback\n}\n\nfunction createBackgroundTransaction(name, group, callback) {\n  logger.debug('Not calling createBackgroundTransaction because New Relic is disabled.')\n  return (callback === undefined) ? group : callback\n}\n\n// Normally the following call executes callback asynchronously\nfunction shutdown(options, cb) {\n  logger.debug('Not calling shutdown because New Relic is disabled.')\n  \n  var callback = cb\n  if (!callback) {\n    if (typeof options === 'function') {\n      callback = options\n    } else {\n      callback = new Function()\n    }\n  }\n  \n  process.nextTick(callback)\n}\n\nmodule.exports = Stub\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/api.js":"'use strict'\n\nvar util = require('util')\nvar logger = require('./lib/logger').child({component: 'api'})\nvar NAMES = require('./lib/metrics/names')\nvar recordWeb = require('./lib/metrics/recorders/http.js')\nvar recordBackground = require('./lib/metrics/recorders/other.js')\nvar customRecorder = require('./lib/metrics/recorders/custom')\nvar hashes = require('./lib/util/hashes')\nvar stringify = require('json-stringify-safe')\n\n\n/*\n *\n * CONSTANTS\n *\n */\nvar RUM_STUB = \"<script type='text/javascript'>window.NREUM||(NREUM={});\" +\n                \"NREUM.info = %s; %s</script>\"\n\n// these messages are used in the _gracefail() method below in getBrowserTimingHeader\nvar RUM_ISSUES = [\n  'NREUM: no browser monitoring headers generated; disabled',\n  'NREUM: transaction missing while generating browser monitoring headers',\n  'NREUM: config.browser_monitoring missing, something is probably wrong',\n  'NREUM: browser_monitoring headers need a transaction name',\n  'NREUM: browser_monitoring requires valid application_id',\n  'NREUM: browser_monitoring requires valid browser_key',\n  'NREUM: browser_monitoring requires js_agent_loader script',\n  'NREUM: browser_monitoring disabled by browser_monitoring.loader config'\n]\n\n// can't overwrite internal parameters or all heck will break loose\nvar CUSTOM_BLACKLIST = [\n  'nr_flatten_leading'\n]\n\nvar CUSTOM_EVENT_TYPE_REGEX = /^[a-zA-Z0-9:_ ]+$/\n\n/**\n * The exported New Relic API. This contains all of the functions meant to be\n * used by New Relic customers. For now, that means transaction naming.\n */\nfunction API(agent) {\n  this.agent = agent\n}\n\n/**\n * Give the current transaction a custom name. Overrides any New Relic naming\n * rules set in configuration or from New Relic's servers.\n *\n * IMPORTANT: this function must be called when a transaction is active. New\n * Relic transactions are tied to web requests, so this method may be called\n * from within HTTP or HTTPS listener functions, Express routes, or other\n * contexts where a web request or response object are in scope.\n *\n * @param {string} name The name you want to give the web request in the New\n *                      Relic UI. Will be prefixed with 'Custom/' when sent.\n */\nAPI.prototype.setTransactionName = function setTransactionName(name) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/setTransactionName'\n  )\n  metric.incrementCallCount()\n\n  var transaction = this.agent.tracer.getTransaction()\n  if (!transaction) {\n    return logger.warn(\"No transaction found when setting name to '%s'.\", name)\n  }\n\n  if (!name) {\n    if (transaction && transaction.url) {\n      logger.error(\"Must include name in setTransactionName call for URL %s.\",\n                   transaction.url)\n    } else {\n      logger.error(\"Must include name in setTransactionName call.\")\n    }\n\n    return\n  }\n\n  transaction.forceName = NAMES.CUSTOM + '/' + name\n}\n\n/**\n * Give the current transaction a name based on your own idea of what\n * constitutes a controller in your Node application. Also allows you to\n * optionally specify the action being invoked on the controller. If the action\n * is omitted, then the API will default to using the HTTP method used in the\n * request (e.g. GET, POST, DELETE). Overrides any New Relic naming rules set\n * in configuration or from New Relic's servers.\n *\n * IMPORTANT: this function must be called when a transaction is active. New\n * Relic transactions are tied to web requests, so this method may be called\n * from within HTTP or HTTPS listener functions, Express routes, or other\n * contexts where a web request or response object are in scope.\n *\n * @param {string} name   The name you want to give the controller in the New\n *                        Relic UI. Will be prefixed with 'Controller/' when\n *                        sent.\n * @param {string} action The action being invoked on the controller. Defaults\n *                        to the HTTP method used for the request.\n */\nAPI.prototype.setControllerName = function setControllerName(name, action) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/setControllerName'\n  )\n  metric.incrementCallCount()\n\n  var transaction = this.agent.tracer.getTransaction()\n  if (!transaction) {\n    return logger.warn(\"No transaction found when setting controller to %s.\", name)\n  }\n\n  if (!name) {\n    if (transaction && transaction.url) {\n      logger.error(\"Must include name in setControllerName call for URL %s.\",\n                   transaction.url)\n    } else {\n      logger.error(\"Must include name in setControllerName call.\")\n    }\n\n    return\n  }\n\n  action = action || transaction.verb || 'GET'\n  transaction.forceName = NAMES.CONTROLLER + '/' + name + '/' + action\n}\n\n/**\n * Add a custom parameter to the current transaction. Some parameters are\n * reserved (see CUSTOM_BLACKLIST for the current, very short list), and\n * as with most API methods, this must be called in the context of an\n * active transaction. Most recently set value wins.\n *\n * @param {string} name  The name you want displayed in the RPM UI.\n * @param {string} value The value you want displayed. Must be serializable.\n */\nAPI.prototype.addCustomParameter = function addCustomParameter(name, value) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/addCustomParameter'\n  )\n  metric.incrementCallCount()\n\n  // If high security mode is on, custom params are disabled.\n  if (this.agent.config.high_security === true) {\n    logger.warnOnce(\n      \"Custom params\",\n      \"Custom parameters are disabled by high security mode.\"\n    )\n    return false\n  }\n\n  var ignored = this.agent.config.ignored_params || []\n\n  var transaction = this.agent.tracer.getTransaction()\n  if (!transaction) {\n    return logger.warn(\"No transaction found for custom parameters.\")\n  }\n\n  var trace = transaction.trace\n  if (!trace.custom) {\n    return logger.warn(\n      \"Couldn't add parameter %s to nonexistent custom parameters.\",\n      name\n    )\n  }\n\n  if (CUSTOM_BLACKLIST.indexOf(name) !== -1) {\n    return logger.warn(\"Not overwriting value of NR-only parameter %s.\", name)\n  }\n\n  if (ignored.indexOf(name) !== -1) {\n    return logger.warn(\"Not setting ignored parameter name %s.\", name)\n  }\n\n  if (name in trace.custom) {\n    logger.debug(\n      \"Changing custom parameter %s from %s to %s.\",\n      name,\n      trace.custom[name],\n      value\n    )\n  }\n\n  trace.custom[name] = value\n}\n\n/**\n * Adds all custom parameters in an object to the current transaction.\n *\n * See documentation for newrelic.addCustomParameter for more information on\n * setting custom parameters.\n *\n * An example of setting a custom parameter object:\n *\n *    newrelic.addCustomParameters({test: 'value', test2: 'value2'});\n *\n * @param {object} [params]\n * @param {string} [params.KEY] The name you want displayed in the RPM UI.\n * @param {string} [params.KEY.VALUE] The value you want displayed. Must be serializable.\n */\nAPI.prototype.addCustomParameters = function addCustomParameters(params) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/addCustomParameters'\n  )\n  metric.incrementCallCount()\n\n  for (var key in params) {\n    if (!params.hasOwnProperty(key)) {\n      continue\n    }\n\n    this.addCustomParameter(key, params[key])\n  }\n}\n\n/**\n * Tell the tracer whether to ignore the current transaction. The most common\n * use for this will be to mark a transaction as ignored (maybe it's handling\n * a websocket polling channel, or maybe it's an external call you don't care\n * is slow), but it's also useful when you want a transaction that would\n * otherwise be ignored due to URL or transaction name normalization rules\n * to *not* be ignored.\n *\n * @param {boolean} ignored Ignore, or don't ignore, the current transaction.\n */\nAPI.prototype.setIgnoreTransaction = function setIgnoreTransaction(ignored) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/setIgnoreTransaction'\n  )\n  metric.incrementCallCount()\n\n  var transaction = this.agent.tracer.getTransaction()\n  if (!transaction) {\n    return logger.warn(\"No transaction found to ignore.\")\n  }\n\n  transaction.forceIgnore = ignored\n}\n\n/**\n * Send errors to New Relic that you've already handled yourself. Should be an\n * `Error` or one of its subtypes, but the API will handle strings and objects\n * that have an attached `.message` or `.stack` property.\n *\n * NOTE: Errors that are recorded using this method do _not_ obey the\n * `ignore_status_codes` configuration.\n *\n * @param {Error} error\n *  The error to be traced.\n *\n * @param {object} [customParameters]\n *  Optional. Any custom parameters to be displayed in the New Relic UI.\n */\nAPI.prototype.noticeError = function noticeError(error, customParameters) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/noticeError'\n  )\n  metric.incrementCallCount()\n\n\n  if (typeof error === 'string') error = new Error(error)\n  var transaction = this.agent.tracer.getTransaction()\n\n  this.agent.errors.addUserError(transaction, error, customParameters)\n}\n\n/**\n * If the URL for a transaction matches the provided pattern, name the\n * transaction with the provided name. If there are capture groups in the\n * pattern (which is a standard JavaScript regular expression, and can be\n * passed as either a RegExp or a string), then the substring matches ($1, $2,\n * etc.) are replaced in the name string. BE CAREFUL WHEN USING SUBSTITUTION.\n * If the replacement substrings are highly variable (i.e. are identifiers,\n * GUIDs, or timestamps), the rule will generate too many metrics and\n * potentially get your application blacklisted by New Relic.\n *\n * An example of a good rule with replacements:\n *\n *   newrelic.addNamingRule('^/storefront/(v[1-5])/(item|category|tag)',\n *                          'CommerceAPI/$1/$2')\n *\n * An example of a bad rule with replacements:\n *\n *   newrelic.addNamingRule('^/item/([0-9a-f]+)', 'Item/$1')\n *\n * Keep in mind that the original URL and any query parameters will be sent\n * along with the request, so slow transactions will still be identifiable.\n *\n * Naming rules can not be removed once added. They can also be added via the\n * agent's configuration. See configuration documentation for details.\n *\n * @param {RegExp} pattern The pattern to rename (with capture groups).\n * @param {string} name    The name to use for the transaction.\n */\nAPI.prototype.addNamingRule = function addNamingRule(pattern, name) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/addNamingRule'\n  )\n  metric.incrementCallCount()\n\n\n  if (!name) return logger.error(\"Simple naming rules require a replacement name.\")\n\n  this.agent.userNormalizer.addSimple(pattern, '/' + name)\n}\n\n/**\n * If the URL for a transaction matches the provided pattern, ignore the\n * transaction attached to that URL. Useful for filtering socket.io connections\n * and other long-polling requests out of your agents to keep them from\n * distorting an app's apdex or mean response time. Pattern may be a (standard\n * JavaScript) RegExp or a string.\n *\n * Example:\n *\n *   newrelic.addIgnoringRule('^/socket\\\\.io/')\n *\n * @param {RegExp} pattern The pattern to ignore.\n */\nAPI.prototype.addIgnoringRule = function addIgnoringRule(pattern) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/addIgnoringRule'\n  )\n  metric.incrementCallCount()\n\n  if (!pattern) return logger.error(\"Must include a URL pattern to ignore.\")\n\n  this.agent.userNormalizer.addSimple(pattern, null)\n}\n\n/**\n * Get the <script>...</script> header necessary for Browser Monitoring\n * This script must be manually injected into your templates, as high as possible\n * in the header, but _after_ any X-UA-COMPATIBLE HTTP-EQUIV meta tags.\n * Otherwise you may hurt IE!\n *\n * This method must be called _during_ a transaction, and must be called every\n * time you want to generate the headers.\n *\n * Do *not* reuse the headers between users, or even between requests.\n *\n * @returns {string} the <script> header to be injected\n */\nAPI.prototype.getBrowserTimingHeader = function getBrowserTimingHeader() {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/getBrowserTimingHeader'\n  )\n  metric.incrementCallCount()\n\n  var config = this.agent.config\n\n  /**\n   * Gracefully fail.\n   *\n   * Output an HTML comment and log a warning the comment is meant to be\n   * innocuous to the end user.\n   *\n   * @param {number} num          - Error code from `RUM_ISSUES`.\n   * @param {bool} [quite=false]  - Be quiet about this failure.\n   *\n   * @see RUM_ISSUES\n   */\n  function _gracefail(num, quiet) {\n    if (quiet) {\n      logger.debug(RUM_ISSUES[num])\n    } else {\n      logger.warn(RUM_ISSUES[num])\n    }\n    return '<!-- NREUM: (' + num + ') -->'\n  }\n\n  var browser_monitoring = config.browser_monitoring\n\n  // config.browser_monitoring should always exist, but we don't want the agent\n  // to bail here if something goes wrong\n  if (!browser_monitoring) return _gracefail(2)\n\n  /* Can control header generation with configuration this setting is only\n   * available in the newrelic.js config file, it is not ever set by the\n   * server.\n   */\n  if (!browser_monitoring.enable) {\n    // It has been disabled by the user; no need to warn them about their own\n    // settings so fail quietly and gracefully.\n    return _gracefail(0, true)\n  }\n\n  var trans = this.agent.getTransaction()\n\n  // bail gracefully outside a transaction\n  if (!trans) return _gracefail(1)\n\n  var name = trans.getName()\n\n  /* If we're in an unnamed transaction, add a friendly warning this is to\n   * avoid people going crazy, trying to figure out why browser monitoring is\n   * not working when they're missing a transaction name.\n   */\n  if (!name) return _gracefail(3)\n\n  var time = trans.timer.getDurationInMillis()\n\n  /*\n   * Only the first 13 chars of the license should be used for hashing with\n   * the transaction name.\n   */\n  var key = config.license_key.substr(0, 13)\n  var appid = config.application_id\n\n  /* This is only going to work if the agent has successfully handshaked with\n   * the collector. If the networks is bad, or there is no license key set in\n   * newrelis.js, there will be no application_id set.  We bail instead of\n   * outputting null/undefined configuration values.\n   */\n  if (!appid) return _gracefail(4)\n\n  /* If there is no browser_key, the server has likely decided to disable\n   * browser monitoring.\n   */\n  var licenseKey = browser_monitoring.browser_key\n  if (!licenseKey) return _gracefail(5)\n\n  /* If there is no agent_loader script, there is no point\n   * in setting the rum data\n   */\n  var js_agent_loader = browser_monitoring.js_agent_loader\n  if (!js_agent_loader) return _gracefail(6)\n\n  /* If rum is enabled, but then later disabled on the server,\n   * this is the only parameter that gets updated.\n   *\n   * This condition should only be met if rum is disabled during\n   * the lifetime of an application, and it should be picked up\n   * on the next ForceRestart by the collector.\n   */\n  var loader = browser_monitoring.loader\n  if (loader === 'none') return _gracefail(7)\n\n  // This hash gets written directly into the browser.\n  var rum_hash = {\n    agent: browser_monitoring.js_agent_file,\n    beacon: browser_monitoring.beacon,\n    errorBeacon: browser_monitoring.error_beacon,\n    licenseKey: licenseKey,\n    applicationID: appid,\n    applicationTime: time,\n    transactionName: hashes.obfuscateNameUsingKey(name, key),\n    queueTime: trans.queueTime,\n    ttGuid: trans.id,\n\n    // we don't use these parameters yet\n    agentToken: null\n  }\n\n  // if debugging, do pretty format of JSON\n  var tabs = config.browser_monitoring.debug ? 2 : 0\n  var json = JSON.stringify(rum_hash, null, tabs)\n\n\n  // the complete header to be written to the browser\n  var out = util.format(\n    RUM_STUB,\n    json,\n    js_agent_loader\n  )\n\n  logger.trace('generating RUM header', out)\n\n  return out\n}\n\n/**\n * This creates a new tracer with the passed in name. It then wraps the\n * callback and binds it to the current transaction and segment so any further\n * custom instrumentation as well as auto instrumentation will also be able to\n * find the current transaction and segment.\n */\nAPI.prototype.createTracer = function createTracer(name, callback) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/createTracer'\n  )\n  metric.incrementCallCount()\n\n  // FLAG: custom_instrumentation\n  if (!this.agent.config.feature_flag.custom_instrumentation) {\n    return callback\n  }\n\n  var fail = false\n  if (!name) {\n    logger.warn('createTracer called without a name')\n    fail = true\n  }\n\n  if (typeof callback !== 'function') {\n    logger.warn('createTracer called with a callback arg that is not a function')\n    fail = true\n  }\n\n  if (fail) {\n    // If name is undefined but callback is defined we should make a best effort\n    // to return it so things don't crash.\n    return callback\n  }\n\n  var tracer = this.agent.tracer\n  var txn = tracer.getTransaction()\n  if (!txn) {\n    logger.debug(\n      'createTracer called with %s (%s) outside of a transaction, ' +\n        'unable to create tracer.',\n      name,\n      callback && callback.name\n    )\n    return callback\n  }\n\n  logger.debug(\n    'creating tracer %s (%s) on transaction %s.',\n    name,\n    callback && callback.name,\n    txn.id\n  )\n\n  var segment = tracer.createSegment(name, customRecorder)\n  segment.start()\n  return tracer.bindFunction(callback, segment, true)\n}\n\n/**\n * Creates a function that represents a web transaction. It does not start the\n * transaction automatically - the returned function needs to be invoked to start it.\n * Inside the handler function, the transaction must be ended by calling endTransaction().\n *\n * @example\n * var newrelic = require('newrelic')\n * var transaction = newrelic.createWebTransaction('/some/url/path', function() {\n *   // do some work\n *   newrelic.endTransaction()\n * })\n *\n * @param {string}    url       The URL of the transaction.  It is used to name and group\n                                related transactions in APM, so it should be a generic\n                                name and not iclude any variable parameters.\n * @param {Function}  handle    Function that represents the transaction work.\n */\nAPI.prototype.createWebTransaction = function createWebTransaction(url, handle) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/createWebTransaction'\n  )\n  metric.incrementCallCount()\n\n  // FLAG: custom_instrumentation\n  if (!this.agent.config.feature_flag.custom_instrumentation) {\n    return handle\n  }\n\n  var fail = false\n  if (!url) {\n    logger.warn('createWebTransaction called without an url')\n    fail = true\n  }\n\n  if (typeof handle !== 'function') {\n    logger.warn('createWebTransaction called with a handle arg that is not a function')\n    fail = true\n  }\n\n  if (fail) {\n    // If name is undefined but handle is defined we should make a best effort\n    // to return it so things don't crash.\n    return handle\n  }\n\n  logger.debug(\n    'creating web transaction generator %s (%s).',\n    url,\n    handle && handle.name\n  )\n\n  var tracer = this.agent.tracer\n\n  return tracer.transactionNestProxy('web', function createWebSegment() {\n    var tx = tracer.getTransaction()\n\n    logger.debug(\n      'creating web transaction %s (%s) with transaction id: %s',\n      url,\n      handle && handle.name,\n      tx.id\n    )\n    tx.nameState.setName(NAMES.CUSTOM, null, NAMES.ACTION_DELIMITER, url)\n    tx.url = url\n    tx.applyUserNamingRules(tx.url)\n    tx.webSegment = tracer.createSegment(url, recordWeb)\n    tx.webSegment.start()\n\n    return tracer.bindFunction(handle, tx.webSegment).apply(this, arguments)\n  })\n}\n\n/**\n * Creates a function that represents a background transaction. It does not start the\n * transaction automatically - the returned function needs to be invoked to start it.\n * Inside the handler function, the transaction must be ended by calling endTransaction().\n *\n * @example\n * var newrelic = require('newrelic')\n * var transaction = newrelic.createBackgroundTransaction('myTransaction', function() {\n *   // do some work\n *   newrelic.endTransaction()\n * })\n *\n * @param {string}    name      The name of the transaction.  It is used to name and group\n                                related transactions in APM, so it should be a generic\n                                name and not iclude any variable parameters.\n * @param {string}    [group]   Optional, used for grouping background transactions in\n *                              APM.  For more information see:\n *                              https://docs.newrelic.com/docs/apm/applications-menu/monitoring/transactions-page#txn-type-dropdown\n * @param {Function}  handle    Function that represents the background work.\n */\nAPI.prototype.createBackgroundTransaction = createBackgroundTransaction\n\nfunction createBackgroundTransaction(name, group, handle) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/createBackgroundTransaction'\n  )\n  metric.incrementCallCount()\n\n  if (handle === undefined && typeof group === 'function') {\n    handle = group\n    group = 'Nodejs'\n  }\n  // FLAG: custom_instrumentation\n  if (!this.agent.config.feature_flag.custom_instrumentation) {\n    return handle\n  }\n\n  var fail = false\n  if (!name) {\n    logger.warn('createBackgroundTransaction called without an url')\n    fail = true\n  }\n\n  if (typeof handle !== 'function') {\n    logger.warn(\n      'createBackgroundTransaction called with a handle arg that is not a function'\n    )\n    fail = true\n  }\n\n  if (fail) {\n    // If name is undefined but handle is defined we should make a best effort\n    // to return it so things don't crash.\n    return handle\n  }\n\n  logger.debug(\n    'creating background transaction generator %s:%s (%s)',\n    name,\n    group,\n    handle && handle.name\n  )\n\n  var tracer = this.agent.tracer\n\n  return tracer.transactionNestProxy('bg', function createBackgroundSegment() {\n    var tx = tracer.getTransaction()\n\n    logger.debug(\n      'creating background transaction %s:%s (%s) with transaction id: %s',\n      name,\n      group,\n      handle && handle.name,\n      tx.id\n    )\n\n    tx.setBackgroundName(name, group)\n    tx.bgSegment = tracer.createSegment(name, recordBackground)\n    tx.bgSegment.partialName = group\n    tx.bgSegment.start()\n\n    return tracer.bindFunction(handle, tx.bgSegment).apply(this, arguments)\n  })\n}\n\nAPI.prototype.endTransaction = function endTransaction() {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/endTransaction'\n  )\n  metric.incrementCallCount()\n\n  // FLAG: custom_instrumentation\n  if (!this.agent.config.feature_flag.custom_instrumentation) {\n    return\n  }\n\n  var tracer = this.agent.tracer\n  var tx = tracer.getTransaction()\n\n  if (tx) {\n    if (tx.webSegment) {\n      tx.setName(tx.url, 0)\n      tx.webSegment.markAsWeb(tx.url)\n      tx.webSegment.end()\n    } else if (tx.bgSegment) {\n      tx.bgSegment.end()\n    }\n    logger.debug('ending transaction with id: %s and name: %s', tx.id, tx.name)\n    tx.end()\n  } else {\n    logger.debug('endTransaction() called while not in a transaction.')\n  }\n}\n\nAPI.prototype.recordMetric = function recordMetric(name, value) {\n  var supportMetric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/recordMetric'\n  )\n  supportMetric.incrementCallCount()\n\n  // FLAG: custom_metrics\n  if (!this.agent.config.feature_flag.custom_metrics) {\n    return\n  }\n\n  if (typeof name !== 'string') {\n    logger.warn('Metric name must be a string')\n    return\n  }\n\n  var metric = this.agent.metrics.getOrCreateMetric(name)\n\n  if (typeof value === 'number') {\n    metric.recordValue(value)\n    return\n  }\n\n  if (typeof value !== 'object') {\n    logger.warn('Metric value must be either a number, or a metric object')\n    return\n  }\n\n  var stats = {}\n  var required = ['count', 'total', 'min', 'max', 'sumOfSquares']\n  var keyMap = {count: 'callCount'}\n\n  for (var i = 0, l = required.length; i < l; ++i) {\n    if (typeof value[required[i]] !== 'number') {\n      logger.warn('Metric object must include ' + required[i] + ' as a number')\n      return\n    }\n\n    var key = keyMap[required[i]] || required[i]\n    stats[key] = value[required[i]]\n  }\n\n  if (typeof value.totalExclusive === 'number') {\n    stats.totalExclusive = value.totalExclusive\n  } else {\n    stats.totalExclusive = value.total\n  }\n\n  metric.merge(stats)\n}\n\nAPI.prototype.incrementMetric = function incrementMetric(name, value) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/incrementMetric'\n  )\n  metric.incrementCallCount()\n\n  // FLAG: custom_metrics\n  if (!this.agent.config.feature_flag.custom_metrics) {\n    return\n  }\n\n  if (!value && value !== 0) {\n    value = 1\n  }\n\n  if (typeof value !== 'number' || value % 1 !== 0) {\n    logger.warn('Metric Increment value must be an integer')\n    return\n  }\n\n  this.recordMetric(name, {\n    count: value,\n    total: 0,\n    min: 0,\n    max: 0,\n    sumOfSquares: 0\n  })\n}\n\nAPI.prototype.recordCustomEvent = function recordCustomEvent(eventType, attributes) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/recordCustomEvent'\n  )\n  metric.incrementCallCount()\n\n  if (!this.agent.config.custom_insights_events.enabled) {\n    return\n  }\n  // Check all the arguments before bailing to give maximum information in a\n  // single invocation.\n  var fail = false\n\n  if (!eventType || typeof eventType !== 'string') {\n    logger.warn(\n      'recordCustomEvent requires a string for its first argument, got %s (%s)',\n      stringify(eventType),\n      typeof eventType\n    )\n    fail = true\n  } else if (!CUSTOM_EVENT_TYPE_REGEX.test(eventType)) {\n    logger.warn(\n      'recordCustomEvent eventType of %s is invalid, it must match /%s/',\n      eventType,\n      CUSTOM_EVENT_TYPE_REGEX.source\n    )\n    fail = true\n  } else if (eventType.length > 255) {\n    logger.warn(\n      'recordCustomEvent eventType must have a length less than 256, got %s (%s)',\n      eventType,\n      eventType.length\n    )\n    fail = true\n  }\n  // If they don't pass an attributes object, or the attributes argument is not\n  // an object, or if it is an object and but is actually an array, log a\n  // warning and set the fail bit.\n  if (!attributes || typeof attributes !== 'object' || Array.isArray(attributes)) {\n    logger.warn(\n      'recordCustomEvent requires an object for its second argument, got %s (%s)',\n      stringify(attributes),\n      typeof attributes\n    )\n    fail = true\n  } else if (_checkKeyLength(attributes, 255)) {\n    fail = true\n  }\n\n  if (fail) {\n    return\n  }\n\n  var instrinics = {\n    type: eventType,\n    timestamp: Date.now()\n  }\n\n  this.agent.customEvents.add([instrinics, attributes])\n}\n\n/**\n * Shuts down the agent.\n *\n * @param {object}  [options]                           object with shut down options\n * @param {boolean} [options.collectPendingData=false]  If true, the agent will send any\n *                                                      pending data to the collector\n *                                                      before shutting down.\n * @param {number}  [options.timeout]                   time in ms to wait before\n *                                                      shutting down\n * @param {function} [callback]                         callback function that runs when\n *                                                      agent stopped\n */\nAPI.prototype.shutdown = function shutdown(options, cb) {\n  var metric = this.agent.metrics.getOrCreateMetric(\n    NAMES.SUPPORTABILITY.API + '/shutdown'\n  )\n  metric.incrementCallCount()\n\n  var callback = cb\n  if (!callback) {\n    if (typeof options === 'function') {\n      callback = options\n    } else {\n      callback = function noop() {}\n    }\n  }\n\n  var agent = this.agent\n\n  function cb_harvest(error) {\n    if (error) {\n      logger.error(\n        error,\n        'An error occurred while running last harvest before shutdown.'\n      )\n    }\n    agent.stop(callback)\n  }\n\n  if (options && options.collectPendingData && agent._state !== 'started') {\n    if (typeof options.timeout === 'number') {\n      var shutdownTimeout = setTimeout(function shutdownTimeout() {\n        agent.stop(callback)\n      }, options.timeout)\n      // timer.unref only in 0.9+\n      if (shutdownTimeout.unref) {\n        shutdownTimeout.unref()\n      }\n    } else if (options.timeout) {\n      logger.warn(\n        'options.timeout should be of type \"number\". Got %s',\n        typeof options.timeout\n      )\n    }\n\n    agent.on('started', function shutdownHarvest() {\n      agent.harvest(cb_harvest)\n    })\n    agent.on('errored', function logShutdownError(error) {\n      agent.stop(callback)\n      if (error) {\n        logger.error(\n          error,\n          'The agent encountered an error after calling shutdown.'\n        )\n      }\n    })\n  } else if (options && options.collectPendingData) {\n    agent.harvest(cb_harvest)\n  } else {\n    agent.stop(callback)\n  }\n}\n\nfunction _checkKeyLength(object, maxLength) {\n  var keys = Object.keys(object)\n  var badKey = false\n  var len = keys.length\n  var key = '' // init to string because gotta go fast\n  for (var i = 0; i < len; i++) {\n    key = keys[i]\n    if (key.length > maxLength) {\n      logger.warn(\n        'recordCustomEvent requires keys to be less than 256 chars got %s (%s)',\n        key,\n        key.length\n      )\n      badKey = true\n    }\n  }\n  return badKey\n}\n\nmodule.exports = API\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/metrics/recorders/http.js":"'use strict'\n\nvar NAMES = require('../../metrics/names.js')\n\n// CONSTANTS\nvar TO_MILLIS = 1e3\n\nfunction recordWeb(segment, scope) {\n  // in web metrics, scope is required\n  if (!scope) return\n\n  var transaction = segment.transaction\n  // if there was a nested webTransaction use its recorder instead\n  if (transaction.webSegment && segment !== transaction.webSegment) return\n\n  var duration = segment.getDurationInMillis()\n  var totalTime = transaction.trace.getTotalTimeDurationInMillis()\n  var exclusive = segment.getExclusiveDurationInMillis()\n  var partial = segment.partialName\n  var config = segment.transaction.agent.config\n  // named / key transaction support requires per-name apdexT\n  var keyApdexInMillis = config.web_transactions_apdex[scope] * TO_MILLIS || 0\n\n  transaction.measure(NAMES.WEB.RESPONSE_TIME, null, duration, exclusive)\n  transaction.measure(NAMES.WEB.TOTAL_TIME, null, totalTime, exclusive)\n  transaction.measure(NAMES.HTTP, null, duration, exclusive)\n  transaction.measure(scope, null, duration, exclusive)\n  transaction.measure(NAMES.WEB.TOTAL_TIME + '/' + partial, null, totalTime, exclusive)\n\n  if (transaction.queueTime > 0) {\n    transaction.measure(NAMES.QUEUETIME, null, transaction.queueTime)\n  }\n\n  if (transaction.incomingCatId) {\n    transaction.measure(\n        NAMES.CLIENT_APPLICATION + '/' + transaction.incomingCatId + \"/all\",\n        null,\n        transaction.catResponseTime\n      )\n  }\n  transaction._setApdex(NAMES.APDEX + '/' + partial, duration, keyApdexInMillis)\n  transaction._setApdex(NAMES.APDEX, duration, keyApdexInMillis)\n}\n\nmodule.exports = recordWeb\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/metrics/recorders/other.js":"'use strict'\n\nvar NAMES = require('../../metrics/names.js')\n\nfunction recordBackground(segment, scope) {\n  // if there was a nested otherTransaction use its recorder instead\n  var transaction = segment.transaction\n  if (transaction.bgSegment && segment !== transaction.bgSegment) return\n\n  var duration = segment.getDurationInMillis()\n  var exclusive = segment.getExclusiveDurationInMillis()\n  var totalTime = segment.transaction.trace.getTotalTimeDurationInMillis()\n  var group = segment.partialName\n  var name = group + '/' + segment.name\n\n  if (scope) {\n    transaction.measure(scope, null, duration, exclusive)\n    transaction.measure(\n      NAMES.BACKGROUND.TOTAL_TIME + '/' + name,\n      null,\n      totalTime,\n      exclusive\n    )\n  }\n  // rollup for background total time doesn't have `/all` where the response\n  // time version does.\n  transaction.measure(\n    NAMES.BACKGROUND.RESPONSE_TIME + '/all',\n    null,\n    duration,\n    exclusive\n  )\n  transaction.measure(NAMES.BACKGROUND.TOTAL_TIME, null, totalTime, exclusive)\n}\n\nmodule.exports = recordBackground\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/metrics/recorders/custom.js":"'use strict'\n\nvar NAMES = require('../names')\n\nfunction record(segment, scope) {\n  var duration = segment.getDurationInMillis()\n  var exclusive = segment.getExclusiveDurationInMillis()\n  var transaction = segment.transaction\n  var name = NAMES.CUSTOM + NAMES.ACTION_DELIMITER + segment.name\n\n  if (scope) transaction.measure(name, scope, duration, exclusive)\n\n  transaction.measure(name, null, duration, exclusive)\n}\n\nmodule.exports = record\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/agent.js":"'use strict'\n\nvar util = require('util')\nvar EventEmitter = require('events').EventEmitter\nvar Reservoir = require('./reservoir.js')\nvar logger = require('./logger.js')\nvar sampler = require('./sampler.js')\nvar NAMES = require('./metrics/names.js')\nvar CollectorAPI = require('./collector/api.js')\nvar ErrorAggregator = require('./errors/aggregator')\nvar Metrics = require('./metrics')\nvar MetricNormalizer = require('./metrics/normalizer.js')\nvar TxSegmentNormalizer = require('./metrics/normalizer/tx_segment.js')\nvar MetricMapper = require('./metrics/mapper.js')\nvar TraceAggregator = require('./transaction/trace/aggregator.js')\nvar hashes = require('./util/hashes')\nvar uninstrumented = require('./uninstrumented.js')\nvar QueryTracer = require('./db/tracer')\n\n/*\n *\n * CONSTANTS\n *\n */\n\nvar STATES = [\n  'stopped',      // start state\n  'starting',     // handshaking with NR\n  'connected',    // connected to collector\n  'disconnected', // disconnected from collector\n  'started',      // up and running\n  'stopping',     // shutting down\n  'errored'       // stopped due to error\n]\n\n// just to make clear what's going on\nvar TO_MILLIS = 1e3\nvar FROM_MILLIS = 1e-3\n\n// Check for already loaded modules and warn about them. This must be executed\n// only once, at the first require of this file, or else we have problems in\n// unit tests.\nuninstrumented.check()\n\n/**\n * There's a lot of stuff in this constructor, due to Agent acting as the\n * orchestrator for New Relic within instrumented applications.\n *\n * This constructor can throw if, for some reason, the configuration isn't\n * available. Don't try to recover here, because without configuration the\n * agent can't be brought up to a useful state.\n */\nfunction Agent(config) {\n  EventEmitter.call(this)\n\n  if (!config) throw new Error(\"Agent must be created with a configuration!\")\n\n  // The agent base attributes which last throughout its lifetime.\n  this._state = 'stopped'\n  this.config = config\n  this.environment = require('./environment')\n  this.version = this.config.version\n  this.collector = new CollectorAPI(this)\n\n  // Reset the agent to add all the sub-objects it needs. These object are the\n  // ones that get re-created if the agent is told to restart from the collector.\n  this.events = null\n  this.customEvents = null\n  this.errors = null\n  this.mapper = null\n  this.metricNameNormalizer = null\n  this.metrics = null\n  this.transactionNameNormalizer = null\n  this.urlNormalizer = null\n  this.txSegmentNormalizer = null\n  this.userNormalizer = null\n  this.reset()\n\n  // Transaction tracing.\n  this.tracer = this._setupTracer()\n  this.traces = new TraceAggregator(this.config)\n\n  // Query tracing.\n  this.queries = new QueryTracer(this.config)\n\n  // Set up all the configuration events the agent needs to listen for.\n  var self = this\n  this.config.on('apdex_t', this._apdexTChange.bind(this))\n  this.config.on('data_report_period', this._harvesterIntervalChange.bind(this))\n  this.config.on('agent_enabled', this._enabledChange.bind(this))\n  this.config.on('change', this._configChange.bind(this))\n  this.config.on('metric_name_rules', function updateMetricNameNormalizer() {\n    self.metricNameNormalizer.load.apply(self.metricNameNormalizer, arguments)\n  })\n  this.config.on('transaction_name_rules', function updateTransactionNameNormalizer() {\n    self.transactionNameNormalizer.load.apply(self.transactionNameNormalizer, arguments)\n  })\n  this.config.on('url_rules', function updateUrlNormalizer() {\n    self.urlNormalizer.load.apply(self.urlNormalizer, arguments)\n  })\n  this.config.on('transaction_segment_terms', function updateSegmentNormalizer() {\n    self.txSegmentNormalizer.load.apply(self.txSegmentNormalizer, arguments)\n  })\n\n  // Entity tracking metrics.\n  this.totalActiveSegments = 0\n  this.segmentsCreatedInHarvest = 0\n  this.segmentsClearedInHarvest = 0\n  this.activeTransactions = 0\n\n  // Hidden class optimizations.\n  this.harvesterHandle = null\n\n  // Finally, add listeners for the agent's own events.\n  this.on('transactionFinished', this._transactionFinished.bind(this))\n}\nutil.inherits(Agent, EventEmitter)\n\n/**\n * The agent is meant to only exist once per application, but the singleton is\n * managed by index.js. An agent will be created even if the agent's disabled by\n * the configuration.\n *\n * @config {boolean} agent_enabled Whether to start up the agent.\n *\n * @param {Function} callback Continuation and error handler.\n */\nAgent.prototype.start = function start(callback) {\n  if (!callback) throw new TypeError(\"callback required!\")\n\n  var agent = this\n\n  this.setState('starting')\n\n  if (this.config.agent_enabled !== true) {\n    logger.warn(\"The New Relic Node.js agent is disabled by its configuration. \" +\n                \"Not starting!\")\n\n    this.setState('stopped')\n    return process.nextTick(callback)\n  }\n\n  if (!(this.config.license_key)) {\n    logger.error(\"A valid account license key cannot be found. \" +\n                 \"Has a license key been specified in the agent configuration \" +\n                 \"file or via the NEW_RELIC_LICENSE_KEY environment variable?\")\n\n    this.setState('errored')\n    return process.nextTick(function cb_nextTick() {\n      callback(new Error(\"Not starting without license key!\"))\n    })\n  }\n\n  sampler.start(agent)\n\n  logger.info(\"Starting New Relic for Node.js connection process.\")\n\n  this.collector.connect(function cb_connect(error, config) {\n    if (error) {\n      agent.setState('errored')\n      return callback(error, config)\n    }\n\n    if (agent.collector.isConnected() && !agent.config.no_immediate_harvest) {\n      // harvest immediately for quicker data display, but after at least 1\n      // second or the collector will throw away the data.\n      setTimeout(function one_sec_delayed_harvest() {\n        agent.harvest(function cb_harvest(error) {\n          agent._startHarvester(agent.config.data_report_period)\n\n          agent.setState('started')\n          callback(error, config)\n        })\n      }, 1000)\n    } else {\n      process.nextTick(function cb_nextTick() {\n        callback(null, config)\n      })\n    }\n  })\n}\n\n/**\n * Any memory claimed by the agent will be retained after stopping.\n *\n * FIXME: make it possible to dispose of the agent, as well as do a\n * \"hard\" restart. This requires working with shimmer to strip the\n * current instrumentation and patch to the module loader.\n */\nAgent.prototype.stop = function stop(callback) {\n  if (!callback) throw new TypeError(\"callback required!\")\n\n  var agent = this\n\n  this.setState('stopping')\n  this._stopHarvester()\n  sampler.stop()\n\n  if (this.collector.isConnected()) {\n    this.collector.shutdown(function cb_shutdown(error) {\n      if (error) {\n        agent.setState('errored')\n        logger.warn(error, \"Got error shutting down connection to New Relic:\")\n      } else {\n        agent.setState('stopped')\n        logger.info(\"Stopped New Relic for Node.js.\")\n      }\n\n      callback(error)\n    })\n  } else {\n    process.nextTick(callback)\n  }\n}\n\n/**\n * Builds all of the sub-properties of the agent that rely on configurations.\n */\nAgent.prototype.reset = function reset() {\n  // Insights events.\n  if (!this.events) {\n    this.events = new Reservoir()\n  }\n  this.events.setLimit(this.config.transaction_events.max_samples_per_minute)\n  if (!this.customEvents) {\n    this.customEvents = new Reservoir()\n  }\n  this.customEvents.setLimit(this.config.custom_insights_events.max_samples_stored)\n\n  // Error tracing.\n  if (!this.errors) {\n    this.errors = new ErrorAggregator(this.config)\n  }\n  this.errors.reconfigure(this.config)\n\n  // Metrics.\n  this.mapper = new MetricMapper()\n  this.metricNameNormalizer = new MetricNormalizer(this.config, 'metric name')\n  this.metrics = new Metrics(this.config.apdex_t, this.mapper, this.metricNameNormalizer)\n\n  // Transaction naming.\n  this.transactionNameNormalizer = new MetricNormalizer(this.config, 'transaction name')\n  this.urlNormalizer = new MetricNormalizer(this.config, 'URL')\n\n  // Segment term based tx renaming for MGI mitigation.\n  this.txSegmentNormalizer = new TxSegmentNormalizer()\n\n  // User naming and ignoring rules.\n  this.userNormalizer = new MetricNormalizer(this.config, 'user')\n  this.userNormalizer.loadFromConfig()\n\n  // Supportability.\n  if (this.config.debug.internal_metrics) {\n    this.config.debug.supportability = new Metrics(\n      this.config.apdex_t,\n      this.mapper,\n      this.metricNameNormalizer\n    )\n  }\n}\n\n/**\n * On agent startup, an interval timer is started that calls this method once\n * a minute, which in turn invokes the pieces of the harvest cycle. It calls\n * the various collector API methods in order, bailing out if one of them fails,\n * to ensure that the agents don't pummel the collector if it's already\n * struggling.\n */\nAgent.prototype.harvest = function harvest(callback) {\n  if (!callback) throw new TypeError(\"callback required!\")\n\n  var agent = this\n  var harvestSteps = [\n    '_sendMetrics',\n    '_sendErrors',\n    '_sendTrace',\n    '_sendEvents',\n    '_sendCustomEvents',\n    '_sendQueries',\n    '_sendErrorEvents'\n  ]\n\n  logger.trace({\n    segmentTotal: this.totalActiveSegments,\n    harvestCreated: this.segmentsCreatedInHarvest,\n    harvestCleared: this.segmentsClearedInHarvest,\n    activeTransactions: this.activeTransactions\n  }, 'Entity stats on harvest')\n\n  this.segmentsCreatedInHarvest = 0\n  this.segmentsClearedInHarvest = 0\n\n  if (!this.collector.isConnected()) {\n    return process.nextTick(function cb_nextTick() {\n      callback(new Error(\"Not connected to New Relic!\"))\n    })\n  }\n  runHarvestStep(0)\n\n  function runHarvestStep(n) {\n    agent[harvestSteps[n++]](next)\n\n    function next(error) {\n      if (error || n >= harvestSteps.length) return callback(error)\n      runHarvestStep(n)\n    }\n  }\n}\n\n/**\n * Public interface for passing configuration data from the collector\n * on to the configuration, in an effort to keep them at least somewhat\n * decoupled.\n *\n * @param {object} configuration New config JSON from the collector.\n */\nAgent.prototype.reconfigure = function reconfigure(configuration) {\n  if (!configuration) throw new TypeError(\"must pass configuration\")\n\n  this.config.onConnect(configuration)\n}\n\n/**\n * Make it easier to determine what state the agent thinks it's in (needed\n * for a few tests, but fragile).\n *\n * FIXME: remove the need for this\n *\n * @param {string} newState The new state of the agent.\n */\nAgent.prototype.setState = function setState(newState) {\n  if (STATES.indexOf(newState) === -1) {\n    throw new TypeError(\"Invalid state \" + newState)\n  }\n  logger.debug(\"Agent state changed from %s to %s.\", this._state, newState)\n  this._state = newState\n  this.emit(this._state)\n}\n\n/**\n * Server-side configuration value.\n *\n * @param {number} apdexT Apdex tolerating value, in seconds.\n */\nAgent.prototype._apdexTChange = function _apdexTChange(apdexT) {\n  logger.debug(\"Apdex tolerating value changed to %s.\", apdexT)\n  this.metrics.apdexT = apdexT\n  if (this.config.debug.supportability) {\n    this.config.debug.supportability.apdexT = apdexT\n  }\n}\n\n/**\n * Server-side configuration value. When run, forces a harvest cycle\n * so as to not cause the agent to go too long without reporting.\n *\n * @param {number} interval Time in seconds between harvest runs.\n */\nAgent.prototype._harvesterIntervalChange = _harvesterIntervalChange\n\nfunction _harvesterIntervalChange(interval, callback) {\n  var agent = this\n\n  // only change the setup if the harvester is currently running\n  if (this.harvesterHandle) {\n    // force a harvest now, to be safe\n    this.harvest(function cb_harvest(error) {\n      agent._restartHarvester(interval)\n      if (callback) callback(error)\n    })\n  } else if (callback) {\n    process.nextTick(callback)\n  }\n}\n\n/**\n * Restart the harvest cycle timer.\n *\n * @param {number} harvestSeconds How many seconds between harvests.\n */\nAgent.prototype._restartHarvester = function _restartHarvester(harvestSeconds) {\n  this._stopHarvester()\n  this._startHarvester(harvestSeconds)\n}\n\n/**\n * Safely stop the harvest cycle timer.\n */\nAgent.prototype._stopHarvester = function _stopHarvester() {\n  if (this.harvesterHandle) clearInterval(this.harvesterHandle)\n  this.harvesterHandle = undefined\n}\n\n/**\n * Safely start the harvest cycle timer, and ensure that the harvest\n * cycle won't keep an application from exiting if nothing else is\n * happening to keep it up.\n *\n * @param {number} harvestSeconds How many seconds between harvests.\n */\nAgent.prototype._startHarvester = function _startHarvester(harvestSeconds) {\n  var agent = this\n\n  function onError(error) {\n    if (error) {\n      logger.info(error, \"Error on submission to New Relic (data held for redelivery):\")\n    }\n  }\n\n  function harvester() {\n    agent.harvest(onError)\n  }\n\n  this.harvesterHandle = setInterval(harvester, harvestSeconds * TO_MILLIS)\n  // timer.unref is 0.9+\n  if (this.harvesterHandle.unref) this.harvesterHandle.unref()\n}\n\n/**\n * `agent_enabled` changed. This will generally only happen because of a high\n * security mode mismatch between the agent and the collector. This only\n * expects to have to stop the agent. No provisions have been made, nor\n * testing have been done to make sure it is safe to start the agent back up.\n */\nAgent.prototype._enabledChange = function _enabledChange() {\n  if (this.config.agent_enabled === false) {\n    logger.warn('agent_enabled has been changed to false, stopping the agent.')\n    this.stop(function nop() {})\n  }\n}\n\n/**\n * Report new settings to collector after a configuration has changed. This\n * always occurs after handling a response from a connect call.\n */\nAgent.prototype._configChange = function _configChange() {\n  this.collector.reportSettings()\n}\n\n/**\n * To develop the current transaction tracer, I created a tracing tracer that\n * tracks when transactions, segments and function calls are proxied. This is\n * used by the tests, but can also be dumped and logged, and is useful for\n * figuring out where in the execution chain tracing is breaking down.\n *\n * @param object config Agent configuration.\n *\n * @returns Tracer Either a debugging or production transaction tracer.\n */\nAgent.prototype._setupTracer = function _setupTracer() {\n  var Tracer = require('./transaction/tracer')\n  return new Tracer(this)\n}\n\n/**\n * The pieces of supportability metrics are scattered all over the place -- only\n * send supportability metrics if they're explicitly enabled in the\n * configuration.\n *\n * @param {Function} callback Gets any delivery errors.\n */\nAgent.prototype._sendMetrics = function _sendMetrics(callback) {\n  var agent = this\n\n  if (this.collector.isConnected()) {\n    if (this.errors.getTotalErrorCount() > 0) {\n      var count = this.errors.getTotalErrorCount()\n      this.metrics.getOrCreateMetric(NAMES.ERRORS.ALL).incrementCallCount(count)\n\n      count = this.errors.getWebTransactionsErrorCount()\n      this.metrics.getOrCreateMetric(NAMES.ERRORS.WEB).incrementCallCount(count)\n\n      count = this.errors.getBackgroundTransactionsErrorCount()\n      this.metrics.getOrCreateMetric(NAMES.ERRORS.OTHER).incrementCallCount(count)\n    }\n\n    if (this.config.debug.supportability) {\n      this.metrics.merge(this.config.debug.supportability)\n    }\n\n    // Send uninstrumented supportability metrics every harvest cycle\n    uninstrumented.createMetrics(this.metrics)\n\n    this._processCustomEvents()\n    this._processErrorEvents()\n\n    // wait to check until all the standard stuff has been added\n    if (this.metrics.toJSON().length < 1) {\n      logger.debug(\"No metrics to send.\")\n      return process.nextTick(callback)\n    }\n\n    var metrics = this.metrics\n    var beginSeconds = metrics.started * FROM_MILLIS\n    var endSeconds = Date.now() * FROM_MILLIS\n    var payload = [this.config.run_id, beginSeconds, endSeconds, metrics]\n\n\n    // reset now to avoid losing metrics that come in after delivery starts\n    this.metrics = new Metrics(\n      this.config.apdex_t,\n      this.mapper,\n      this.metricNameNormalizer\n    )\n\n    this.collector.metricData(payload, function cb_metricData(error, rules) {\n      if (error) agent.metrics.merge(metrics)\n      if (rules) agent.mapper.load(rules)\n\n      callback(error)\n    })\n  } else {\n    process.nextTick(function cb_nextTick() {\n      callback(new Error(\"not connected to New Relic (metrics will be held)\"))\n    })\n  }\n}\n\n/**\n * This function takes the custom events reservoir, gets stats on it for\n * metric purposes, then instantiates a new custom events reservoir. This is\n * so the stats are consistent with what actually gets pushed by the later\n * call to _sendCustomEvents.\n */\nAgent.prototype._processCustomEvents = function _processCustomEvents() {\n  this.customEventsPool = this.customEvents.toArray()\n\n  // Create the metrics so they are at least set to 0\n  var dropped = this.metrics.getOrCreateMetric(NAMES.CUSTOM_EVENTS.DROPPED)\n  var seen = this.metrics.getOrCreateMetric(NAMES.CUSTOM_EVENTS.SEEN)\n  var sent = this.metrics.getOrCreateMetric(NAMES.CUSTOM_EVENTS.SENT)\n\n  // Bail out if there are no events\n  if (this.customEventsPool.length === 0) {\n    return\n  }\n\n  if (this.config.custom_insights_events.enabled) {\n    // Record their values\n    var diff = this.customEvents.overflow()\n    dropped.incrementCallCount(diff)\n    seen.incrementCallCount(this.customEvents.seen)\n    sent.incrementCallCount(this.customEvents.seen - diff)\n\n    // Log any warnings about dropping events\n    if (diff) {\n      logger.warn('Dropped %s custom events out of %s.', diff, this.customEvents.seen)\n    }\n\n    // Create a new reservoir now (instead of at send time) so metrics match\n    // what we actually send.\n    this.customEvents = new Reservoir(\n      this.config.custom_insights_events.max_samples_stored\n    )\n  } else if (this.customEventsPool.length > 0) {\n    // We have events and custom events are disabled. Clear everything out so we\n    // don't hold onto memory that we shouldn't. Only time this could happen is\n    // if the server sent down settings disabling custom events in the middle of\n    // a harvest cycle.\n    this.customEventsPool = []\n    this.customEvents = new Reservoir(\n      this.config.custom_insights_events.max_samples_stored\n    )\n  }\n}\n\n/**\n * This function takes the error events reservoir, gets stats on it for\n * metric purposes, then instantiates a new error events reservoir. This is\n * so the stats are consistent with what actually gets pushed by the later\n * call to _sendErrorEvents.\n */\nAgent.prototype._processErrorEvents = function _processErrorEvents() {\n  var events = this.errors.getEvents()\n\n  this._lastErrorEvents = [\n    this.errors.getEventsLimit(),\n    this.errors.getEventsSeen(),\n    events\n  ]\n\n  // Create the metrics so they are at least set to 0\n  var seen = this.metrics.getOrCreateMetric(NAMES.TRANSACTION_ERROR.SEEN)\n  var sent = this.metrics.getOrCreateMetric(NAMES.TRANSACTION_ERROR.SENT)\n\n  // Bail out if there are no events\n  if (events.length === 0) {\n    return\n  }\n\n  if (this.config.error_collector.capture_events) {\n    // Record their values\n    var diff = this.errors.events.overflow()\n    seen.incrementCallCount(this.errors.events.seen)\n    sent.incrementCallCount(this.errors.events.seen - diff)\n\n    // Log any warnings about dropping events\n    if (diff) {\n      logger.warn('Dropped %s error events out of %s.', diff, this.errors.events.seen)\n    }\n\n    // clear the reservoir now (instead of at send time) so metrics match\n    // what we actually send.\n    this.errors.clearEvents()\n  } else if (events.length > 0) {\n    // We have events and error events are disabled. Clear everything out so we\n    // don't hold onto memory that we shouldn't. Only time this could happen is\n    // if the server sent down settings disabling error events in the middle of\n    // a harvest cycle.\n    this._lastErrorEvents = []\n    this.errors.clearEvents()\n  }\n}\n\n/**\n * The error tracer doesn't know about the agent, and the connection\n * doesn't know about the error tracer. Only the agent knows about both.\n *\n * @param {Function} callback Gets any delivery errors.\n */\nAgent.prototype._sendErrors = function _sendErrors(callback) {\n  var agent = this\n\n  if (this.config.collect_errors && this.config.error_collector.enabled) {\n    if (!this.collector.isConnected()) {\n      return process.nextTick(function cb_nextTick() {\n        callback(new Error(\"not connected to New Relic (errors will be held)\"))\n      })\n    } else if (this.errors.getTotalErrorCount() < 1) {\n      logger.debug(\"No errors to send.\")\n      return process.nextTick(callback)\n    }\n\n    var errors = this.errors.getErrors()\n    var payload = [this.config.run_id, errors]\n\n    // reset now to avoid losing errors that come in after delivery starts\n    this.errors.clearErrors()\n\n    this.collector.errorData(payload, function cb_errorData(error) {\n      if (error) agent.errors.merge(errors)\n\n      callback(error)\n    })\n  } else {\n    /**\n     * Reset the errors object even if collection is disabled due to error\n     * counting. Also covers the case where the error collector gets disabled\n     * in the middle of a harvest cycle so the agent doesn't continue to hold\n     * on to the errors it had collected during the harvest cycle so far.\n     */\n    this.errors.clearErrors()\n    process.nextTick(callback)\n  }\n}\n\n/**\n * The trace aggregator has its own harvester, which is already\n * asynchronous, due to its need to compress the nested transaction\n * trace data.\n *\n * @param {Function} callback Gets any encoding or delivery errors.\n */\nAgent.prototype._sendTrace = function _sendTrace(callback) {\n  var agent = this\n  if (this.config.collect_traces && this.config.transaction_tracer.enabled) {\n    if (!this.collector.isConnected()) {\n      return process.nextTick(function cb_nextTick() {\n        callback(new Error(\"not connected to New Relic (slow trace data will be held)\"))\n      })\n    }\n\n    this.traces.harvest(function cb_harvest(error, traces, trace) {\n      if (error || !traces || traces.length === 0) return callback(error)\n\n      var payload = [agent.config.run_id, traces]\n      agent.collector.transactionSampleData(\n        payload,\n        function cb_transactionSampleData(error) {\n          if (!error) agent.traces.reset(trace)\n\n          callback(error)\n        }\n      )\n    })\n  } else {\n    process.nextTick(callback)\n  }\n}\n\nAgent.prototype._sendEvents = function _sendEvents(callback) {\n  if (this.config.transaction_events.enabled) {\n    var agent = this\n    var events = agent.events\n    var sample = events.toArray()\n    var run_id = agent.config.run_id\n\n    // bail if there are no events\n    if (sample.length < 1) {\n      return process.nextTick(callback)\n    }\n\n    var metrics = {\n      reservoir_size: events.limit,\n      events_seen: events.seen\n    }\n\n    var payload = [\n      run_id,\n      metrics,\n      sample\n    ]\n\n    // clear events\n    agent.events = new Reservoir(agent.config.transaction_events.max_samples_per_minute)\n\n    // send data to collector\n    agent.collector.analyticsEvents(payload, function cb_analyticsEvents(err) {\n      if (err && err.statusCode === 413 ) {\n        logger.warn('request too large; event data dropped')\n      } else if (err) {\n        logger.warn('analytics events failed to send; re-sampling')\n\n        // boost the limit if a connection fails\n        // and re-aggregate on failure\n        var newlimit = agent.config.transaction_events.max_samples_stored\n        agent.events.limit = newlimit\n\n        for (var k = 0; k < sample.length; k++) agent.events.add(sample[k])\n      } else {\n        // if we had to limit events and sample them, emit a warning\n        var diff = events.overflow()\n        if (diff > 0) logger.warn(\n          'analytics event overflow, dropped %d events; ' +\n           'try increasing your limit above %d',\n          diff, events.limit\n        )\n      }\n\n      callback(err)\n    })\n  } else {\n    process.nextTick(callback)\n  }\n}\n\n/**\n * This is separate from _sendEvents because of potential post size problems.\n * _processCustomEvents needs to happen before _sendCustomEvents. In the\n * normal case it will have happened in _sendMetrics but if you are testing\n * this or trying to use it directly for some reason you'll need to call\n * _processCustomEvents first.\n */\nAgent.prototype._sendCustomEvents = function _sendCustomEvents(callback) {\n  // Must be enabled and actually have events to send, otherwise bail and nextTick\n  if (this.config.custom_insights_events.enabled && this.customEventsPool.length > 0) {\n    var agent = this\n    var run_id = agent.config.run_id\n\n    var payload = [\n      run_id,\n      agent.customEventsPool\n    ]\n\n    // send data to collector\n    agent.collector.customEvents(payload, function cb_customEvents(err) {\n      if (err && err.statusCode === 413 ) {\n        var tooLarge = agent.metrics.getOrCreateMetric(NAMES.CUSTOM_EVENTS.TOO_LARGE)\n        tooLarge.incrementCallCount()\n        logger.warn('request too large; custom event data dropped')\n      } else if (err) {\n        var failed = agent.metrics.getOrCreateMetric(NAMES.CUSTOM_EVENTS.FAILED)\n        failed.incrementCallCount()\n        logger.warn('custom events failed to send; re-sampling')\n\n        for (var i = 0; i < agent.customEventsPool.length; i++) {\n          agent.customEvents.add(agent.customEventsPool[i])\n        }\n      }\n\n      callback(err)\n    })\n  } else {\n    process.nextTick(callback)\n  }\n}\n\nAgent.prototype._sendQueries = function _sendQueries(callback) {\n  var agent = this\n  var queries = this.queries\n\n  this.queries = new QueryTracer(agent.config)\n\n  if (!this.config.slow_sql.enabled) {\n    logger.debug('Slow Query is not enabled.')\n    return process.nextTick(callback)\n  }\n\n  if (Object.keys(queries.samples).length < 1) {\n    logger.debug('No queries to send.')\n    return process.nextTick(callback)\n  }\n\n  queries.prepareJSON(function gotJSON(err, data) {\n    if (err) {\n      this.queries.merge(queries)\n      logger.debug('Error while serializing query data: %s', err.message)\n      return callback(err)\n    }\n\n    agent.collector.queryData([data], function handleResponse(error) {\n      if (error) agent.queries.merge(queries)\n      callback(error)\n    })\n  })\n}\n\nAgent.prototype._sendErrorEvents = function _sendErrorEvents(callback) {\n  if (this.config.error_collector.capture_events && this._lastErrorEvents &&\n        this._lastErrorEvents[2].length > 0) {\n    var agent = this\n    var eventsLimit = this._lastErrorEvents[0]\n    var eventsSeen = this._lastErrorEvents[1]\n    var events = this._lastErrorEvents[2]\n    var run_id = agent.config.run_id\n\n    if (events.length < 1) {\n      return process.nextTick(callback)\n    }\n\n    var metrics = {\n      reservoir_size: eventsLimit,\n      events_seen: eventsSeen\n    }\n\n    var payload = [\n      run_id,\n      metrics,\n      events\n    ]\n\n    // send data to collector\n    agent.collector.errorEvents(payload, function cb_errorEvents(err) {\n      if (err && err.statusCode === 413 ) {\n        logger.warn('request too large; event data dropped')\n      } else if (err) {\n        logger.warn('error events failed to send; re-sampling')\n        agent.errors.mergeEvents(events)\n      }\n      callback(err)\n    })\n  } else {\n    process.nextTick(callback)\n  }\n}\n\nAgent.prototype._addIntrinsicAttrsFromTransaction = _addIntrinsicAttrsFromTransaction\n\nfunction _addIntrinsicAttrsFromTransaction(transaction) {\n  var intrinsicAttributes = {\n    webDuration: transaction.timer.duration / 1000,\n    timestamp: transaction.timer.start,\n    name: transaction.name,\n    duration: transaction.timer.duration / 1000,\n    type: 'Transaction',\n    error: transaction.hasErrors()\n  }\n\n  var metric = transaction.metrics.getMetric(NAMES.QUEUETIME)\n  if (metric) {\n    intrinsicAttributes.queueDuration = metric.total\n  }\n\n  metric = transaction.metrics.getMetric(NAMES.EXTERNAL.ALL)\n  if (metric) {\n    intrinsicAttributes.externalDuration = metric.total\n    intrinsicAttributes.externalCallCount = metric.callCount\n  }\n\n  metric = transaction.metrics.getMetric(NAMES.DB.ALL)\n  if (metric) {\n    intrinsicAttributes.databaseDuration = metric.total\n    intrinsicAttributes.databaseCallCount = metric.callCount\n  }\n\n  // FLAG: cat\n  if (this.config.feature_flag.cat) {\n    if (!transaction.invalidIncomingExternalTransaction &&\n         (\n           transaction.referringTransactionGuid ||\n           transaction.includesOutboundRequests()\n         )\n       ) {\n      intrinsicAttributes['nr.guid'] = transaction.id\n      intrinsicAttributes['nr.tripId'] = transaction.tripId || transaction.id\n      intrinsicAttributes['nr.pathHash'] = hashes.calculatePathHash(\n        this.config.applications()[0],\n        transaction.name || transaction.nameState.getName(),\n        transaction.referringPathHash\n      )\n      if (transaction.referringPathHash) {\n        intrinsicAttributes['nr.referringPathHash'] = transaction.referringPathHash\n      }\n      if (transaction.referringTransactionGuid) {\n        var refId = transaction.referringTransactionGuid\n        intrinsicAttributes['nr.referringTransactionGuid'] = refId\n      }\n      var alternatePathHashes = transaction.alternatePathHashes()\n      if (alternatePathHashes) {\n        intrinsicAttributes['nr.alternatePathHashes'] = alternatePathHashes\n      }\n      if (transaction.webSegment) {\n        var apdex = (this.config.web_transactions_apdex[transaction.name] ||\n                     this.config.apdex_t)\n        var duration = transaction.webSegment.getDurationInMillis() / 1000\n        intrinsicAttributes['nr.apdexPerfZone'] = calculateApdexZone(duration, apdex)\n      }\n    }\n  }\n\n  if (transaction.syntheticsData) {\n    intrinsicAttributes[\"nr.syntheticsResourceId\"] = transaction.syntheticsData.resourceId\n    intrinsicAttributes[\"nr.syntheticsJobId\"] = transaction.syntheticsData.jobId\n    intrinsicAttributes[\"nr.syntheticsMonitorId\"] = transaction.syntheticsData.monitorId\n  }\n\n  return intrinsicAttributes\n}\n\nfunction calculateApdexZone(duration, apdexT) {\n  if (duration <= apdexT) {\n    return 'S' // satisfied\n  }\n\n  if (duration <= apdexT * 4) {\n    return 'T' // tolerating\n  }\n\n  return 'F' // frustrated\n}\n\nAgent.prototype._addEventFromTransaction = _addEventFromTransaction\n\nfunction _addEventFromTransaction(transaction) {\n  if (!this.config.transaction_events.enabled) return\n\n  var intrinsicAttributes = this._addIntrinsicAttrsFromTransaction(transaction)\n  var userAttributes = transaction.trace.custom\n  var agentAttributes = transaction.trace.parameters\n\n  var event = [\n    intrinsicAttributes,\n    userAttributes,\n    agentAttributes\n  ]\n\n  this.events.add(event)\n}\n\n/**\n * Put all the logic for handing finalized transactions off to the tracers and\n * metric collections in one place.\n *\n * @param {Transaction} transaction Newly-finalized transaction.\n */\nAgent.prototype._transactionFinished = function _transactionFinished(transaction) {\n  // only available when this.config.debug.tracer_tracing is true\n  if (transaction.describer) {\n    logger.trace({trace_dump: transaction.describer.verbose}, 'Dumped transaction state.')\n  }\n\n  // Allow the API to explicitly set the ignored status on bg-tx.\n  // This is handled for web-tx when setName is called on the tx.\n  if (!transaction.isWeb() && transaction.forceIgnore !== null) {\n    transaction.ignore = transaction.forceIgnore\n  }\n\n  if (!transaction.ignore) {\n    if (transaction.forceIgnore === false) {\n      logger.debug(\"Explicitly not ignoring %s.\", transaction.name)\n    }\n    this.metrics.merge(transaction.metrics)\n    this.errors.onTransactionFinished(transaction, this.metrics)\n    this.traces.add(transaction)\n\n    var trace = transaction.trace\n    trace.intrinsics = transaction.getIntrinsicAttributes()\n\n    this._addEventFromTransaction(transaction)\n  } else if (transaction.forceIgnore === true) {\n    logger.debug(\"Explicitly ignoring %s.\", transaction.name)\n  } else {\n    logger.debug(\"Ignoring %s.\", transaction.name)\n  }\n\n  this.activeTransactions--\n  this.totalActiveSegments -= transaction.numSegments\n  this.segmentsClearedInHarvest += transaction.numSegments\n}\n\n/**\n * Get the current transaction (if there is one) from the tracer.\n *\n * @returns {Transaction} The current transaction.\n */\nAgent.prototype.getTransaction = function getTransaction() {\n  return this.tracer.getTransaction()\n}\n\nmodule.exports = Agent\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/reservoir.js":"'use strict'\n\n// from http://en.wikipedia.org/wiki/Reservoir_sampling\n\nfunction Reservoir(limit) {\n  this.limit = limit || 10\n  this.seen = 0\n  this._data = []\n}\n\nReservoir.prototype.overflow = function overflow() {\n  var diff = this.seen - this.limit\n  return diff >= 0 ? diff : 0\n}\n\nReservoir.prototype.add = function add(item) {\n  if (this.seen < this.limit) {\n    this._data.push(item)\n  } else {\n    // Take a number between 0 and n + 1, drop the element at that index\n    // from the array. If the element to drop is the (n + 1)th, the new item is\n    // not added, otherwise the new item replaces the item that was\n    // dropped.\n    // This is effectively the same as adding the new element to the\n    // end, swapping the last element (the new one) with a random element in the list,\n    // then dropping the last element (the potentially swapped one) in the list.\n    var toReplace = Math.floor(Math.random() * (this.seen + 2))\n    if (toReplace < this.limit) this._data[toReplace] = item\n  }\n  this.seen++\n}\n\nReservoir.prototype.toArray = function toArray() {\n  return this._data\n}\n\nReservoir.prototype.merge = function merge(items) {\n  if (!items || !items.length) return\n  if (items === this._data) return\n  for (var i = 0; i < items.length; i++) {\n    this.add(items[i])\n  }\n}\n\nReservoir.prototype.setLimit = function setLimit(newLimit) {\n  this.limit = newLimit\n  if (this._data.length > newLimit) {\n    this._data = this._data.slice(0, newLimit)\n  }\n}\n\nmodule.exports = Reservoir\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/sampler.js":"'use strict'\n\nvar NAMES = require('./metrics/names')\nvar logger = require('./logger').child({component: 'sampler'})\nvar Timer = require('./timer')\nvar os = require('os')\n\n/*\n *\n * CONSTANTS\n *\n */\nvar MILLIS = 1e3\nvar MICROS = 1e6\nvar NANOS = 1e9\nvar CPUS = os.cpus().length\nvar SAMPLE_INTERVAL = 15 * MILLIS\n\nvar samplers = []\n\nfunction Sampler(sampler, interval) {\n  this.id = setInterval(sampler, interval)\n  // timer.unref only in 0.9+\n  if (this.id.unref) this.id.unref()\n}\n\nSampler.prototype.stop = function stop() {\n  clearInterval(this.id)\n}\n\nfunction recordQueueTime(agent, timer) {\n  timer.end()\n  agent.metrics.measureMilliseconds(NAMES.EVENTS.WAIT, null, timer.getDurationInMillis())\n}\n\nfunction sampleMemory(agent) {\n  return function memorySampler() {\n    try {\n      var mem = process.memoryUsage()\n      agent.metrics.measureBytes(NAMES.MEMORY.PHYSICAL, mem.rss)\n      agent.metrics.measureBytes(NAMES.MEMORY.USED_HEAP, mem.heapUsed)\n      agent.metrics.measureBytes(NAMES.MEMORY.MAX_HEAP, mem.heapTotal)\n      agent.metrics.measureBytes(NAMES.MEMORY.FREE_HEAP, mem.heapTotal - mem.heapUsed)\n      agent.metrics.measureBytes(NAMES.MEMORY.USED_NONHEAP, mem.rss - mem.heapTotal)\n      logger.trace('Recorded memory:', mem)\n    } catch (e) {\n      logger.debug('Could not record memory usage', e)\n    }\n  }\n}\n\nfunction checkEvents(agent) {\n  return function eventSampler() {\n    var timer = new Timer()\n    timer.begin()\n    setTimeout(recordQueueTime.bind(null, agent, timer), 0)\n  }\n}\n\nfunction getCpuSample(lastSample) {\n  try {\n    return process.cpuUsage(lastSample)\n  } catch (e) {\n    logger.debug('Could not record cpu usage', e)\n    return null\n  }\n}\n\nfunction generateCPUMetricRecorder(agent) {\n  var lastSampleTime\n  // userTime and sysTime are in seconds\n  return function recordCPUMetrics(userTime, sysTime) {\n    var elapsedUptime\n    if (!lastSampleTime) {\n      elapsedUptime = process.uptime()\n    } else {\n      elapsedUptime = (Date.now() - lastSampleTime) / MILLIS\n    }\n\n    var totalCpuTime = CPUS * elapsedUptime\n\n    lastSampleTime = Date.now()\n\n    var userUtil = userTime / totalCpuTime\n    var sysUtil  = sysTime / totalCpuTime\n\n    recordValue(agent, NAMES.CPU.USER_TIME, userTime)\n    recordValue(agent, NAMES.CPU.SYSTEM_TIME, sysTime)\n    recordValue(agent, NAMES.CPU.USER_UTILIZATION, userUtil)\n    recordValue(agent, NAMES.CPU.SYSTEM_UTILIZATION, sysUtil)\n  }\n}\n\nfunction sampleCpu(agent) {\n  var lastSample\n  var recordCPU = generateCPUMetricRecorder(agent)\n  return function cpuSampler() {\n    var cpuSample = getCpuSample(lastSample)\n    lastSample = getCpuSample()\n\n    if (lastSample == null) {\n      return\n    }\n\n    recordCPU(cpuSample.user / MICROS, cpuSample.system / MICROS)\n  }\n}\n\nfunction sampleCpuNative(agent, nativeMetrics) {\n  var recordCPU = generateCPUMetricRecorder(agent)\n  nativeMetrics.on('usage', function collectResourceUsage(usage) {\n    recordCPU(usage.diff.ru_utime / MILLIS, usage.diff.ru_stime / MILLIS)\n  })\n\n  return function cpuSampler() {\n    // NOOP?\n  }\n}\n\nfunction sampleLoop(agent, nativeMetrics) {\n  return function loopSampler() {\n    var loopMetrics = nativeMetrics.getLoopMetrics()\n\n    // convert from microseconds to seconds\n    loopMetrics.usage.min = loopMetrics.usage.min / MICROS\n    loopMetrics.usage.max = loopMetrics.usage.max / MICROS\n    loopMetrics.usage.total = loopMetrics.usage.total / MICROS\n    loopMetrics.usage.sumOfSquares = loopMetrics.usage.sumOfSquares / (MICROS * MICROS)\n\n    recordCompleteMetric(agent, NAMES.LOOP.USAGE, loopMetrics.usage)\n  }\n}\n\nfunction sampleGc(agent, nativeMetrics) {\n  // Hook into the stats event to accumulate total pause time and record per-run\n  // pause time metric.\n  nativeMetrics.on('gc', function onGCStatsEvent(stats) {\n    var duration = stats.duration / NANOS\n    recordValue(agent, NAMES.GC.PAUSE_TIME, duration)\n\n    if (stats.type) {\n      recordValue(agent, NAMES.GC.PREFIX + stats.type, duration)\n    } else {\n      logger.debug(stats, 'Unknown GC type %j', stats.typeId)\n    }\n  })\n\n  return function gcSampler() {\n    // NOOP?\n  }\n}\n\nvar sampler = module.exports = {\n  state: 'stopped',\n  sampleMemory: sampleMemory,\n  checkEvents: checkEvents,\n  sampleCpu: sampleCpu,\n  sampleGc: sampleGc,\n  sampleLoop: sampleLoop,\n  nativeMetrics: null,\n\n  start: function start(agent) {\n    samplers.push(new Sampler(sampleMemory(agent), 5 * MILLIS))\n    samplers.push(new Sampler(checkEvents(agent), SAMPLE_INTERVAL))\n    var metricFeatureFlag = agent.config.feature_flag.native_metrics\n\n    // This requires a native module which may have failed to build.\n    if (!this.nativeMetrics) {\n      if (metricFeatureFlag) {\n        try {\n          this.nativeMetrics = require('@newrelic/native-metrics')({\n            timeout: SAMPLE_INTERVAL\n          })\n        } catch (err) {\n          logger.info(\n            {error: {message: err.message, stack: err.stack}},\n            'Not adding native metric sampler.'\n          )\n          agent.metrics.getOrCreateMetric(\n            NAMES.SUPPORTABILITY.DEPENDENCIES + '/NoNativeMetricsModule'\n          ).incrementCallCount()\n        }\n      } else {\n        logger.info('Feature flag for native metrics is false')\n      }\n    }\n\n    if (this.nativeMetrics) {\n      if (!this.nativeMetrics.bound) {\n        this.nativeMetrics.bind(SAMPLE_INTERVAL)\n      }\n\n      // Add GC events if available.\n      if (this.nativeMetrics.gcEnabled) {\n        samplers.push(new Sampler(sampleGc(agent, this.nativeMetrics), SAMPLE_INTERVAL))\n      }\n\n      // Add loop metrics if available.\n      if (this.nativeMetrics.loopEnabled) {\n        samplers.push(new Sampler(sampleLoop(agent, this.nativeMetrics), SAMPLE_INTERVAL))\n      }\n    }\n\n    // Add CPU sampling using the built-in data if available, otherwise pulling\n    // from the native module.\n    if (process.cpuUsage) { // introduced in 6.1.0\n      samplers.push(new Sampler(sampleCpu(agent), SAMPLE_INTERVAL))\n    } else if (this.nativeMetrics && this.nativeMetrics.usageEnabled) {\n      samplers.push(\n        new Sampler(sampleCpuNative(agent, this.nativeMetrics), SAMPLE_INTERVAL)\n      )\n    } else {\n      logger.debug('Not adding CPU metric sampler.')\n    }\n\n    sampler.state = 'running'\n  },\n\n  stop: function stop() {\n    samplers.forEach(function forEachSampler(s) {\n      s.stop()\n    })\n    samplers = []\n    sampler.state = 'stopped'\n    if (this.nativeMetrics) {\n      this.nativeMetrics.unbind()\n      this.nativeMetrics.removeAllListeners()\n\n      // Setting this.nativeMetrics to null allows us to config a new\n      // nativeMetrics object after the first start call.\n      this.nativeMetrics = null\n    }\n  }\n}\n\nfunction recordValue(agent, metric, value) {\n  var stats = agent.metrics.getOrCreateMetric(metric)\n  stats.recordValue(value)\n  logger.trace('Recorded metric %s: %j', metric, value)\n}\n\nfunction recordCompleteMetric(agent, metricName, metric) {\n  var stats = agent.metrics.getOrCreateMetric(metricName)\n  stats.merge(metric)\n  logger.trace('Recorded metric %s: %j', metricName, metric)\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/timer.js":"'use strict'\n\n/**\n\n * Explicit enumeration of the states a transaction can be in:\n *\n * PENDING upon instantiation (implicitly, no start time set)\n * RUNNING while timer is running (implicitly, start time is set but no stop\n *   time is set).\n * STOPPED timer has been completed (implicitly, start time and stop time\n *   are set, but the timer has not yet been harvested).\n * DEAD timer has been harvested and can only have its duration read.\n */\nvar PENDING = 1\nvar RUNNING = 2\nvar STOPPED = 3\n\n\nfunction hrToMillis(hr) {\n  // process.hrTime gives you [second, nanosecond] duration pairs\n  return (hr[0] * 1e3) + (hr[1] / 1e6)\n}\n\n/**\n * A mildly tricky timer that tracks its own state and allows its duration\n * to be set manually.\n */\nfunction Timer() {\n  this.state = PENDING\n  this.touched = false\n  this.duration = null\n  this.hrDuration = null\n  this.hrstart = null\n  this.durationInMillis = null\n}\n\n/**\n * Start measuring time elapsed.\n *\n * Uses process.hrtime if available, Date.now() otherwise.\n */\nTimer.prototype.begin = function begin() {\n  if (this.state > PENDING) return\n\n  this.start = Date.now()\n  // need to put a guard on this for compatibility with Node < 0.8\n  if (process.hrtime) this.hrstart = process.hrtime()\n  this.state = RUNNING\n}\n\n/**\n * End measurement.\n */\nTimer.prototype.end = function end() {\n  if (this.state > RUNNING) return\n  if (this.state === PENDING) this.begin()\n  if (process.hrtime) this.hrDuration = process.hrtime(this.hrstart)\n  this.touched = true\n  this.duration = Date.now() - this.start\n  this.state = STOPPED\n}\n\n/**\n * Update the duration of the timer without ending it..\n */\nTimer.prototype.touch = function touch() {\n  this.touched = true\n  if (this.state > RUNNING) return\n  if (this.state === PENDING) this.begin()\n\n  if (process.hrtime) this.hrDuration = process.hrtime(this.hrstart)\n  this.duration = Date.now() - this.start\n}\n\n/**\n * End the segment if it is still running, if touched use that time instead of\n * \"now\". Returns a boolean indicating whether the end time changed.\n */\nTimer.prototype.softEnd = function softEnd() {\n  if (this.state > RUNNING) return false\n  if (this.state === PENDING) this.begin()\n\n  this.state = STOPPED\n\n  if (this.touched) return false\n  if (process.hrtime) this.hrDuration = process.hrtime(this.hrstart)\n  this.touched = true\n  this.duration = Date.now() - this.start\n  return true\n}\n\n/**\n * @return {bool} Is this timer currently running?\n */\nTimer.prototype.isRunning = function isRunning() {\n  return this.state === RUNNING\n}\n\n/**\n * @return {bool} Is this timer still alive?\n */\nTimer.prototype.isActive = function isActive() {\n  return this.state < STOPPED\n}\n\n/**\n * @return {bool} Has the timer been touched or ended?\n */\nTimer.prototype.hasEnd = function hasEnd() {\n  return !!this.hrDuration\n}\n\n/*\n * Sets duration and stops the timer, since the passed-in duration will take precendence\n * over the measured duration.\n * @param {number} duration The duration the timer should report.\n */\nTimer.prototype.overwriteDurationInMillis = overwriteDurationInMillis\nfunction overwriteDurationInMillis(duration) {\n  this.touched = true\n  this.durationInMillis = duration\n  this.state = STOPPED\n}\n\n/**\n * When testing, it's convenient to be able to control time. Stops the timer\n * as a byproduct.\n *\n * @param {number} duration How long the timer ran.\n * @param {number} start When the timer started running (optional).\n */\nTimer.prototype.setDurationInMillis = function setDurationInMillis(duration, start) {\n  if (this.state > RUNNING) return\n  if (this.state === PENDING)\n  if (!start && start !== 0) this.begin()\n\n  this.state = STOPPED\n  this.durationInMillis = duration\n\n  // this assignment is incorrect, process.hrtime doesn't time from epoch, which\n  // is the assumption being made here.  since hrstart isn't used\n  // anywhere except to calculate duration, and we are setting duration\n  // this is fine.\n  this.hrstart = [Math.floor(start / 1e3), start % 1e3 * 1e6]\n  this.start = start\n}\n\n/**\n * Returns how long the timer has been running (if it's still running) or\n * how long it ran (if it's been ended or touched).\n */\nTimer.prototype.getDurationInMillis = function getDurationInMillis() {\n  if (this.state === PENDING) return 0\n\n  // only set by setDurationInMillis\n  if (this.durationInMillis !== null && this.durationInMillis >= 0) {\n    return this.durationInMillis\n  }\n\n  // prioritize .end() and .touch()\n  if (this.hrDuration) {\n    return hrToMillis(this.hrDuration)\n  }\n\n  if (this.duration) {\n    return this.duration\n  }\n\n  if (process.hrtime) {\n    return hrToMillis(process.hrtime(this.hrstart))\n  }\n\n  return Date.now() - this.start\n}\n\n/**\n * Get a single object containing the interval this timer was active.\n *\n * @return {Array} 2-tuple of start time in milliseconds, end time in\n *                 milliseconds.\n */\nTimer.prototype.toRange = function toRange() {\n  return [this.start, this.start + this.getDurationInMillis()]\n}\n\n/**\n * Abstract away the nonsense related to having both an\n * hrtime start time and a regular one, and always return\n * milliseconds since start.\n *\n * @param {Timer} other The point relative to which this timer started.\n * @return {number} The offset in (floating-point) milliseconds.\n */\nTimer.prototype.startedRelativeTo = function startedRelativeTo(other) {\n  if (this.hrstart && other.hrstart && process.hrtime) {\n    var s = this.hrstart[0] - other.hrstart[0]\n    var ns = this.hrstart[1] - other.hrstart[1]\n\n\n    return hrToMillis([s, ns])\n  }\n\n  return this.start - other.start\n}\n\n/**\n * Returns true if this timer ends after the other.\n */\nTimer.prototype.endsAfter = function compare(other) {\n  return (this.getDurationInMillis() + this.start) >\n    (other.getDurationInMillis() + other.start)\n}\n\n\nmodule.exports = Timer\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/collector/api.js":"'use strict'\n\nvar logger = require('../logger').child({component: 'collector_api'})\nvar facts = require('./facts.js')\nvar RemoteMethod = require('./remote-method.js')\n\n\n/*\n *\n * CONSTANTS\n *\n */\n\n// just to make clear what's going on\nvar TO_MILLIS = 1e3\n\n// taken directly from Python agent's newrelic.core.application\nvar BACKOFFS = [\n  {interval: 15, warn: false},\n  {interval: 15, warn: false},\n  {interval: 30, warn: false},\n  {interval: 60, warn: true},\n  {interval: 120, warn: false},\n  {interval: 300, warn: false}\n]\n\nvar ERRORS = {\n  INVALID_LICENSE: 'NewRelic::Agent::LicenseException',\n  LIMIT_EXCEEDED: 'NewRelic::Agent::InternalLimitExceeded',\n  RESTART: 'NewRelic::Agent::ForceRestartException',\n  DISCONNECT: 'NewRelic::Agent::ForceDisconnectException',\n  MAINTENANCE: 'NewRelic::Agent::MaintenanceError',\n  RUNTIME: 'RuntimeError'\n}\n\nvar HTTP_REQUEST_TOO_LARGE = 413\nvar HTTP_UNSUPPORTED_MEDIA_TYPE = 415\nvar HTTP_SERVER_INTERNAL = 500\nvar HTTP_LOL_COLLECTOR = 503\n\n\nfunction dumpErrors(errors, name) {\n  var index = 1\n\n  errors.forEach(function cb_forEach(error) {\n    logger.trace(error, \"Error %s during %s:\", index++, name)\n\n    if (error.laterErrors) {\n      error.laterErrors.forEach(function cb_forEach(laterError) {\n        logger.trace(laterError, \"Error %s during %s:\", index++, name)\n      })\n    }\n  })\n}\n\nfunction CollectorAPI(agent) {\n  this._agent = agent\n\n  /* RemoteMethods can be reused and have little per-object state, so why not\n   * save some GC time?\n   */\n  this._methods = {\n    redirect: new RemoteMethod('get_redirect_host', agent.config),\n    handshake: new RemoteMethod('connect', agent.config),\n    settings: new RemoteMethod('agent_settings', agent.config),\n    errors: new RemoteMethod('error_data', agent.config),\n    metrics: new RemoteMethod('metric_data', agent.config),\n    traces: new RemoteMethod('transaction_sample_data', agent.config),\n    shutdown: new RemoteMethod('shutdown', agent.config),\n    events: new RemoteMethod('analytic_event_data', agent.config),\n    customEvents: new RemoteMethod('custom_event_data', agent.config),\n    queryData: new RemoteMethod('sql_trace_data', agent.config),\n    errorEvents: new RemoteMethod('error_event_data', agent.config)\n  }\n}\n\nCollectorAPI.prototype.connect = function connect(callback) {\n  if (!callback) throw new TypeError(\"callback is required\")\n\n  var api = this\n  var attempts = 1\n  var max = BACKOFFS.length\n  var errors = []\n\n\n  function retry(error, response, body) {\n    if (error) errors.push(error)\n\n    if (!error || attempts >= max) {\n      dumpErrors(errors, 'connect')\n      return callback(error, response, body)\n    }\n\n    // failing high-security mode compliance will cause a disconnect\n    if (error.class === ERRORS.DISCONNECT) {\n      logger.error(\"The New Relic collector rejected this agent.\")\n      logger.error(error.message)\n    }\n\n    var backoff = BACKOFFS[attempts - 1]\n    if (backoff.warn) {\n      logger.warn(\n        \"No connection has been established to New Relic after %s attempts.\",\n        attempts\n      )\n    }\n\n    logger.debug(\n      \"Failed attempting to connect to New Relic, waiting %ss to retry.\",\n      backoff.interval\n    )\n\n    attempts++\n\n    var id = setTimeout(function again() {\n      api._login(retry)\n    }, backoff.interval * TO_MILLIS)\n    \n    if (id.unref) {\n      id.unref()\n    }\n  }\n\n  this._login(retry)\n}\n\nCollectorAPI.prototype._login = function _login(callback) {\n  var methods = this._methods\n  var agent = this._agent\n\n\n  methods.redirect.invoke(null, function cb_invoke(error, collector, body) {\n    if (error) return callback(error, collector, body)\n    if (!collector) {\n      logger.error(\n        \"Requesting this account's collector from %s failed; trying default.\",\n        agent.config.host\n      )\n    } else {\n      var parts = collector.split(':')\n      if (parts.length > 2) {\n        logger.error(\n          \"Requesting collector from %s returned bogus result '%s'; trying default.\",\n          agent.config.host,\n          collector\n        )\n      } else {\n        logger.debug(\n          \"Requesting this account's collector from %s returned %s; reconfiguring.\",\n          agent.config.host,\n          collector\n        )\n\n        agent.config.host = parts[0]\n        if (parts.length > 1) {\n          agent.config.port = parts[1]\n        }\n      }\n    }\n\n    facts(agent, function getEnvDict(environmentDict) {\n      // The collector really likes arrays.\n      // In fact, it kind of insists on them.\n      var environment = [environmentDict]\n\n      methods.handshake.invoke(environment, function cb_invoke(error, config, body) {\n        if (error) return callback(error, config, body)\n        if (!config || !config.agent_run_id) {\n          return callback(new Error(\"No agent run ID received from handshake.\"), config)\n        }\n\n        agent.setState('connected')\n        logger.info(\n          \"Connected to %s:%d with agent run ID %s.\",\n          agent.config.host,\n          agent.config.port,\n          config.agent_run_id\n        )\n\n        // pass configuration data from the API so automatic reconnect works\n        agent.reconfigure(config)\n\n        callback(null, config, body)\n      })\n    })\n  })\n}\n\n/**\n * Send current public agent settings to collector. This should always be\n * invoked after a successful connect response with server-side settings, but\n * will also be invoked on any other config changes.\n *\n * @param {Function} callback The continuation / error handler.\n */\nCollectorAPI.prototype.reportSettings = function reportSettings(callback) {\n  // The second argument to the callback is always empty data\n  this._methods.settings.invoke(\n    [this._agent.config.publicSettings()],\n    function cb_invoke(error, unused, body) {\n      if (error) dumpErrors([error], 'agent_settings')\n\n      if (callback) callback(error, body)\n    }\n  )\n}\n\n/**\n * Send already-formatted error data by calling error_data. For\n * performance reasons, the API methods do no validation, but the\n * collector expects data in an exact format. It expects a JSON array\n * containing the following 2 elements:\n *\n * 1. The agent run ID.\n * 2. An array of one or more errors. See lib/error.js for details.\n *\n * @param {Array}    errors   The encoded errors list.\n * @param {Function} callback The continuation / error handler.\n */\nCollectorAPI.prototype.errorData = function errorData(errors, callback) {\n  if (!errors) throw new TypeError(\"must pass errors to send\")\n  if (!callback) throw new TypeError(\"callback is required\")\n\n  this._runLifecycle(this._methods.errors, errors, callback)\n}\n\n/**\n * Send already-formatted metric data by calling metric_data. For\n * performance reasons, the API methods do no validation, but the collector\n * expects data in an exact format format. It expects a JSON array containing\n * the following 4 elements:\n *\n * 1. The agent run ID.\n * 2. The time the metric data started being collected, in seconds since the\n *    epoch.\n * 3. The time the metric data finished being collected, in seconds since the\n *    epoch.\n * 4. An array of 1 or more metric arrays. See lib/metrics.js for details.\n *\n * @param {Array}    metrics  The encoded metrics list.\n * @param {Function} callback The continuation / error handler.\n */\nCollectorAPI.prototype.metricData = function metricData(metrics, callback) {\n  if (!metrics) throw new TypeError(\"must pass metrics to send\")\n  if (!callback) throw new TypeError(\"callback is required\")\n\n  this._runLifecycle(this._methods.metrics, metrics, callback)\n}\n\nCollectorAPI.prototype.analyticsEvents = function analyticsEvents(events, callback) {\n  if (!events) throw new TypeError(\"must pass events to send\")\n  if (!callback) throw new TypeError(\"callback is required\")\n  this._runLifecycle(this._methods.events, events, callback)\n}\n\nCollectorAPI.prototype.customEvents = function customEvents(events, callback) {\n  if (!events) throw new TypeError(\"must pass events to send\")\n  if (!callback) throw new TypeError(\"callback is required\")\n  this._runLifecycle(this._methods.customEvents, events, callback)\n}\n\n/**\n * Send already-formatted slow SQL data by calling\n * sql_trace_data. For performance reasons, the API methods\n * do no validation, but the collector expects data in an exact format\n * format. It expects a JSON array containing the following 2 elements:\n *\n * 1. The agent run ID.\n * 2. The encoded slow SQL data.\n *\n * @param {Array}    queries  The encoded slow SQL data.\n * @param {Function} callback The continuation / error handler.\n */\nCollectorAPI.prototype.queryData = function queryData(queries, callback) {\n  if (!queries) throw new TypeError(\"must pass queries to send\")\n  if (!callback) throw new TypeError(\"callback is required\")\n  this._runLifecycle(this._methods.queryData, queries, callback)\n}\n\nCollectorAPI.prototype.errorEvents = function errorEvents(events, callback) {\n  if (!events) throw new TypeError(\"must pass queries to send\")\n  if (!callback) throw new TypeError(\"callback is required\")\n  this._runLifecycle(this._methods.errorEvents, events, callback)\n}\n\n/**\n * Send already-formatted slow trace data by calling\n * transaction_sample_data. For performance reasons, the API methods\n * do no validation, but the collector expects data in an exact format\n * format. It expects a JSON array containing the following 2 elements:\n *\n * 1. The agent run ID.\n * 2. The encoded slow trace data. This is the most complicated data\n *    format handled by the module, and documenting it is almost beyond the\n *    scope of comments. See lib/transaction/trace.js for details.\n *\n * @param {Array}    trace    The encoded trace data.\n * @param {Function} callback The continuation / error handler.\n */\nCollectorAPI.prototype.transactionSampleData =\n  function transactionSampleData(trace, callback) {\n  if (!trace) throw new TypeError(\"must pass slow trace data to send\")\n  if (!callback) throw new TypeError(\"callback is required\")\n\n  this._runLifecycle(this._methods.traces, trace, callback)\n}\n\n\n/**\n * Sends no data aside from the message itself. Clears the run ID, which\n * effectively disconnects the agent from the collector.\n *\n * @param Function callback Runs after the run ID has been cleared.\n */\nCollectorAPI.prototype.shutdown = function shutdown(callback) {\n  if (!callback) throw new TypeError(\"callback is required\")\n\n  var agent = this._agent\n  this._methods.shutdown.invoke(null, function closed(error, returned, body) {\n    if (error) {\n      dumpErrors([error], 'shutdown')\n    } else {\n      agent.setState('disconnected')\n      logger.info(\n        \"Disconnected from New Relic; clearing run ID %s.\",\n        agent.config.run_id\n      )\n      agent.config.run_id = undefined\n    }\n\n    callback(error, returned, body)\n  })\n}\n\nCollectorAPI.prototype._restart = function _restart(callback) {\n  var api = this\n  this.shutdown(function reconnect() {\n    api.connect(callback)\n  })\n}\n\nCollectorAPI.prototype._runLifecycle = function _runLifecycle(method, body, callback) {\n  if (!this.isConnected()) {\n    logger.warn(\"Not connected to New Relic. Not calling.\", method.name)\n    return callback(new Error(\"Not connected to collector.\", null, null))\n  }\n\n  var api = this\n  function standardHandler(error, returned, json) {\n    if (!error) return callback(error, returned, json)\n\n    dumpErrors([error], method.name)\n\n    if (error.statusCode === HTTP_REQUEST_TOO_LARGE) {\n      logger.error(\n        error,\n        \"This call of %s sent New Relic too much data; discarding (%s):\",\n        method.name,\n        HTTP_REQUEST_TOO_LARGE\n      )\n      return callback(null, returned, json)\n    } else if (error.statusCode === HTTP_UNSUPPORTED_MEDIA_TYPE) {\n      logger.error(\n        error,\n        \"The New Relic collector couldn't deserialize data; discarding for %s (%s):\",\n        method.name,\n        HTTP_UNSUPPORTED_MEDIA_TYPE\n      )\n      return callback(null, returned, json)\n    } else if (error.statusCode === HTTP_LOL_COLLECTOR) {\n      logger.debug(\n        error,\n        \"New Relic is experiencing a spot of bother; please hold on (%s):\",\n        HTTP_LOL_COLLECTOR\n      )\n      return callback(error, returned, json)\n    } else if (error.statusCode === HTTP_SERVER_INTERNAL) {\n      logger.error(\n        error,\n        \"New Relic's servers encountered a severe internal error on %s (%s):\",\n        method.name,\n        HTTP_SERVER_INTERNAL\n      )\n      return callback(error, returned, json)\n    } else if (error.class === ERRORS.INVALID_LICENSE) {\n      logger.error(\n        error,\n        \"Your New Relic license key appears to be invalid. Please double-check it:\"\n      )\n\n      return callback(error, returned, json)\n    } else if (error.class === ERRORS.LIMIT_EXCEEDED) {\n      logger.error(\n        error,\n        \"New Relic ran into a weird problem with %s. Let support@newrelic.com know:\",\n        method.name\n      )\n      return callback(null, returned, json)\n    } else if (error.class === ERRORS.RESTART) {\n      logger.info(\n        error,\n        \"The New Relic collector requested a connection restart on %s:\",\n        method.name\n      )\n\n      return api._restart(function cb__restart() {\n        method.invoke(body, standardHandler)\n      })\n    } else if (error.class === ERRORS.DISCONNECT) {\n      logger.error(error, \"The New Relic collector is shutting down this agent:\")\n\n      return api._agent.stop(function cb_stop() {\n        callback(error, returned, json)\n      })\n    } else if (error.class === ERRORS.MAINTENANCE) {\n      logger.info(\n        error,\n        \"The New Relic server for your account is currently undergoing maintenance. \" +\n          \"Data will be held until it can be submitted (failed on %s):\",\n        method.name\n      )\n      return callback(error, returned, json)\n    } else if (error.class === ERRORS.RUNTIME) {\n      logger.warn(\n        error,\n        \"Calling %s on New Relic failed due to a runtime error. \" +\n          \"Data will be held until it can be submitted:\",\n        method.name\n      )\n      return callback(error, returned, json)\n    }\n    logger.error(\n      error,\n      \"Calling %s on New Relic failed unexpectedly. \" +\n        \"Data will be held until it can be submitted:\",\n      method.name\n    )\n    return callback(error, returned, json)\n  }\n\n  method.invoke(body, standardHandler)\n}\n\nCollectorAPI.prototype.isConnected = function isConnected() {\n  return !!this._agent.config.run_id\n}\n\nmodule.exports = CollectorAPI\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/collector/facts.js":"'use strict'\n\nvar fetchSystemInfo = require('../system-info')\nvar parse_labels = require('../util/label-parser')\n\nmodule.exports = facts\n\nfunction facts(agent, callback) {\n  fetchSystemInfo(agent, function cb_fetchSystemInfo(systemInfo) {\n    var hostname = agent.config.getHostnameSafe()\n    var results = {\n      utilization: {\n        metadata_version: 2,\n        logical_processors: systemInfo.logicalProcessors,\n        total_ram_mib: systemInfo.memory,\n        hostname: hostname\n      },\n      pid: process.pid,\n      host: hostname,\n      display_host: agent.config.getDisplayHost() || hostname,\n      language: 'nodejs',\n      app_name: agent.config.applications(),\n      agent_version: agent.version,\n      environment: agent.environment,\n      settings: agent.config.publicSettings(),\n      high_security: agent.config.high_security,\n      labels: parse_labels(agent.config.labels)\n    }\n\n    // TODO:  After reconfiguring agent startup to wait for the server to start\n    //        or for the first transaction, add the `port` for the server too.\n    // NOTE: The concat is necessary to prevent sort from happening in-place.\n    results.identifier = [\n      'nodejs',\n      results.host,\n      results.app_name.concat([]).sort().join(',')\n    ].join(':')\n\n    if (systemInfo.aws || systemInfo.docker) {\n      results.utilization.vendors = {}\n      if (systemInfo.aws) {\n        results.utilization.vendors.aws = systemInfo.aws\n      }\n      if (systemInfo.docker) {\n        results.utilization.vendors.docker = systemInfo.docker\n      }\n    }\n    if (systemInfo.config) {\n      results.utilization.config = systemInfo.config\n    }\n    return callback(results)\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/system-info.js":"'use strict'\n\nvar exec = require('child_process').exec\nvar fetchAWSInfo = require('./aws-info')\nvar fs = require('fs')\nvar logger = require('./logger.js').child({component: 'system-info'})\nvar os = require('os')\nvar parseCpuInfo = require('./parse-proc-cpuinfo')\nvar parseDockerInfo = require('./parse-dockerinfo')\nvar parseMemInfo = require('./parse-proc-meminfo')\nvar platform = os.platform()\n\nmodule.exports = fetchSystemInfo\n\nfunction isInteger(i) {\n  return i === parseInt(i, 10)\n}\n\nfunction fetchSystemInfo(agent, callback) {\n  var config = agent.config\n  var systemInfo = {\n    processorArch: os.arch()\n  }\n\n  var utilizationConfig = {}\n  if (config.utilization) {\n    var configProcessors = config.utilization.logical_processors\n    var configRam = config.utilization.total_ram_mib\n    var configHostname = config.utilization.billing_hostname\n\n    if (configProcessors) {\n      var parsedConfigProcessors = parseFloat(configProcessors, 10)\n      if (!isNaN(parsedConfigProcessors) && isInteger(parsedConfigProcessors)) {\n        utilizationConfig.logical_processors = parsedConfigProcessors\n      } else {\n        logger.info(\n          '%s supplied in config for utilization.logical_processors, expected a number',\n          configProcessors\n        )\n      }\n    }\n\n    if (configRam) {\n      var parsedConfigRam = parseFloat(configRam, 10)\n      if (!isNaN(parsedConfigRam) && isInteger(parsedConfigRam)) {\n        utilizationConfig.total_ram_mib = parsedConfigRam\n      } else {\n        logger.info(\n          '%s supplied in config for utilization.total_ram_mib, expected a number',\n          configRam\n        )\n      }\n    }\n\n    if (configHostname) {\n      if (typeof configHostname === 'string') {\n        utilizationConfig.hostname = configHostname\n      } else {\n        logger.info(\n          '%s supplied in config for utilization.Hostname, expected a string',\n          configHostname\n        )\n      }\n    }\n\n    if (Object.keys(utilizationConfig).length > 0) {\n      systemInfo.config = utilizationConfig\n    }\n  }\n\n  var tasksDone = 0\n  var numTasks = 5\n  function finishedResponse() {\n    if (++tasksDone === numTasks) return callback(systemInfo)\n  }\n\n  module.exports._getProcessorStats(function getProcessCB(processorStats) {\n    systemInfo.packages = processorStats.packages\n    systemInfo.logicalProcessors = processorStats.logical\n    systemInfo.cores = processorStats.cores\n    finishedResponse()\n  })\n  module.exports._getMemoryStats(function getMemCB(memory) {\n    systemInfo.memory = memory\n    finishedResponse()\n  })\n  getKernelVersion(function getVersionCB(kernelVersion) {\n    systemInfo.kernelVersion = kernelVersion\n    finishedResponse()\n  })\n  module.exports._getDockerContainerId(agent, function getContainerId(containerId) {\n    if (containerId) {\n      systemInfo.docker = {\n        id: containerId\n      }\n    }\n    finishedResponse()\n  })\n  fetchAWSInfo(agent, function getAWSInfo(aws) {\n    systemInfo.aws = aws\n    finishedResponse()\n  })\n}\n\n// placed on module for mocking purposes in tests\nmodule.exports._getProcessorStats = function getProcessorStats(callback) {\n  var processorStats = {\n    logical: null,\n    cores: null,\n    packages: null\n  }\n\n  if (platform.match(/darwin/i)) {\n    getSysctlValue(['hw.packages'], function getPackages(packages) {\n      getSysctlValue(['hw.physicalcpu_max', 'hw.physicalcpu'],\n      function getCores(cores) {\n        getSysctlValue(['hw.logicalcpu_max', 'hw.logicalcpu', 'hw.ncpu'],\n        function getLogicalCpu(logical) {\n          processorStats.logical = parseFloat(logical, 10)\n          processorStats.cores = parseFloat(cores, 10)\n          processorStats.packages = parseFloat(packages, 10)\n\n          for (var key in processorStats) {\n            if (!processorStats[key] || !isInteger(processorStats[key])) {\n              processorStats[key] = null\n            }\n          }\n\n          callback(processorStats)\n        })\n      })\n    })\n  } else if (platform.match(/bsd/i)) {\n    getSysctlValue(['hw.ncpu'], function getLogicalCpu(logical) {\n      processorStats.logical = logical\n      callback(processorStats)\n    })\n  } else if (platform.match(/linux/i)) {\n    readProc('/proc/cpuinfo', function parseProc(data) {\n      callback(parseCpuInfo(data))\n    })\n  } else {\n    logger.debug('Unknown platform: ' + platform + ', could not retrieve processor info')\n    callback(processorStats)\n  }\n}\n\n// placed on module for mocking purposes in tests\nmodule.exports._getMemoryStats = function getMemoryStats(callback) {\n  if (platform.match(/darwin/i)) {\n    getSysctlValue(['hw.memsize'], function getMem(memory) {\n      callback(parseInt(memory, 10) / (1024 * 1024))\n    })\n  } else if (platform.match(/bsd/i)) {\n    getSysctlValue(['hw.realmem'], function getMem(memory) {\n      callback(parseInt(memory, 10) / (1024 * 1024))\n    })\n  } else if (platform.match(/linux/i)) {\n    readProc('/proc/meminfo', function parseProc(data) {\n      callback(parseMemInfo(data))\n    })\n  } else {\n    logger.debug('Unknown platform: ' + platform + ', could not retrieve memory info')\n    callback(null)\n  }\n}\n\nfunction getKernelVersion(callback) {\n  if (platform.match(/darwin/i)) {\n    getSysctlValue(['kern.version'], function getMem(version) {\n      callback(version)\n    })\n  } else if (platform.match(/bsd/i)) {\n    getSysctlValue(['kern.version'], function getMem(version) {\n      callback(version)\n    })\n  } else if (platform.match(/linux/i)) {\n    readProc('/proc/version', function parseProc(data) {\n      callback(data)\n    })\n  } else {\n    logger.debug('Unknown platform' + platform + ', could not read kernel version')\n    callback(null)\n  }\n}\n\nmodule.exports._getDockerContainerId = function getDockerContainerId(agent, callback) {\n  if (!platform.match(/linux/i)) {\n    logger.debug('Platform is not a flavor of linux, omitting docker info')\n    callback(null)\n  } else {\n    readProc('/proc/self/cgroup', function getCGroup(data) {\n      if (!data) callback(null)\n      else callback(parseDockerInfo(agent, data))\n    })\n  }\n}\n\nfunction getSysctlValue(names, callback) {\n  if (!names) return callback(null)\n  var returned = false\n  var ran = 0\n  names.forEach(function sysctlName(name) {\n    exec('sysctl -n ' + name, respond)\n\n    function respond(err, stdout, stderr) {\n      if (returned) return\n      if (err) {\n        logger.debug('Error when trying to run: sysctl -n ' + name + ': %s', err.message)\n        callback(null)\n        returned = true\n      } else if (!stderr) {\n        callback(stdout)\n        returned = true\n      }\n      if (++ran === names.length && !returned) {\n        logger.debug('No sysctl info found for names: ' + names.toString())\n        callback(null)\n      }\n    }\n  })\n}\n\nfunction readProc(path, callback) {\n  fs.readFile(path, function readProcFile(err, data) {\n    if (err) {\n      logger.error('Error when trying to read ' + path, err)\n      callback(null)\n    } else {\n      callback(data.toString())\n    }\n  })\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/aws-info.js":"'use strict'\n\nvar logger = require('./logger.js').child({component: 'aws-info'})\nvar http = require('http')\nvar NAMES = require('./metrics/names.js')\nvar concat = require('concat-stream')\n\nmodule.exports = fetchAWSInfo\nmodule.exports.clearCache = function clearAWSCache() {\n  resultDict = null\n}\n\nvar resultDict\n\nfunction fetchAWSInfo(agent, callback) {\n  if (!agent.config.utilization || !agent.config.utilization.detect_aws) {\n    return callback(null)\n  }\n\n  if (resultDict) {\n    return callback(resultDict)\n  }\n\n  var awsQuery = module.exports._awsQuery\n\n  awsQuery('instance-type', agent, function getInstanceType(type) {\n    if (!type) return callback(null)\n    awsQuery('instance-id', agent, function getInstanceId(id) {\n      if (!id) return callback(null)\n      awsQuery('placement/availability-zone', agent, function getZone(zone) {\n        if (!zone) return callback(null)\n        resultDict = {\n          type: type,\n          id: id,\n          zone: zone\n        }\n        return callback(resultDict)\n      })\n    })\n  })\n}\n\n\nmodule.exports._awsQuery = function awsQuery(key, agent, callback) {\n  var instanceHost = '169.254.169.254'\n  var apiVersion = '2008-02-01'\n  var url = ['http:/', instanceHost, apiVersion, 'meta-data', key].join('/')\n  var req = http.get(url, function awsRequest(res) {\n    res.pipe(concat(respond))\n    function respond(data) {\n      var valid = checkResponseString(data)\n      if (!valid) {\n        var awsError = agent.metrics.getOrCreateMetric(NAMES.UTILIZATION.AWS_ERROR)\n        awsError.incrementCallCount()\n        logger.debug('Response for attribute ' + key + ': %s'\n          , data)\n        data = null\n      } else {\n        data = data.toString('utf8')\n      }\n\n      agent.removeListener('errored', abortRequest)\n      agent.removeListener('stopped', abortRequest)\n      callback(data)\n    }\n  })\n  req.setTimeout(1000, function awsTimeout() {\n    logger.debug('Request for attribute %s timed out', key)\n    callback(null)\n  })\n  req.on('error', function awsError(err) {\n    logger.debug('Message for attribute %s: %s', key, err.message)\n    callback(null)\n  })\n\n  agent.once('errored', abortRequest)\n  agent.once('stopped', abortRequest)\n\n  function abortRequest() {\n    logger.debug('Abborting request for attribute %s', key)\n    req.abort()\n    agent.removeListener('errored', abortRequest)\n    agent.removeListener('stopped', abortRequest)\n  }\n}\n\nfunction checkResponseString(str) {\n  var validCharacters = /[0-9a-zA-Z_ ./-]/\n  var valid = str.length <= 255 && str.length > 0\n\n  var i = 0\n  var len = str.length\n\n  while (valid && i < len) {\n    valid = valid && (str[i] > 127 || String.fromCharCode(str[i]).match(validCharacters))\n    i++\n  }\n\n  return valid\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/index.js":"var Writable = require('readable-stream').Writable\nvar inherits = require('inherits')\n\nif (typeof Uint8Array === 'undefined') {\n  var U8 = require('typedarray').Uint8Array\n} else {\n  var U8 = Uint8Array\n}\n\nfunction ConcatStream(opts, cb) {\n  if (!(this instanceof ConcatStream)) return new ConcatStream(opts, cb)\n\n  if (typeof opts === 'function') {\n    cb = opts\n    opts = {}\n  }\n  if (!opts) opts = {}\n\n  var encoding = opts.encoding\n  var shouldInferEncoding = false\n\n  if (!encoding) {\n    shouldInferEncoding = true\n  } else {\n    encoding =  String(encoding).toLowerCase()\n    if (encoding === 'u8' || encoding === 'uint8') {\n      encoding = 'uint8array'\n    }\n  }\n\n  Writable.call(this, { objectMode: true })\n\n  this.encoding = encoding\n  this.shouldInferEncoding = shouldInferEncoding\n\n  if (cb) this.on('finish', function () { cb(this.getBody()) })\n  this.body = []\n}\n\nmodule.exports = ConcatStream\ninherits(ConcatStream, Writable)\n\nConcatStream.prototype._write = function(chunk, enc, next) {\n  this.body.push(chunk)\n  next()\n}\n\nConcatStream.prototype.inferEncoding = function (buff) {\n  var firstBuffer = buff === undefined ? this.body[0] : buff;\n  if (Buffer.isBuffer(firstBuffer)) return 'buffer'\n  if (typeof Uint8Array !== 'undefined' && firstBuffer instanceof Uint8Array) return 'uint8array'\n  if (Array.isArray(firstBuffer)) return 'array'\n  if (typeof firstBuffer === 'string') return 'string'\n  if (Object.prototype.toString.call(firstBuffer) === \"[object Object]\") return 'object'\n  return 'buffer'\n}\n\nConcatStream.prototype.getBody = function () {\n  if (!this.encoding && this.body.length === 0) return []\n  if (this.shouldInferEncoding) this.encoding = this.inferEncoding()\n  if (this.encoding === 'array') return arrayConcat(this.body)\n  if (this.encoding === 'string') return stringConcat(this.body)\n  if (this.encoding === 'buffer') return bufferConcat(this.body)\n  if (this.encoding === 'uint8array') return u8Concat(this.body)\n  return this.body\n}\n\nvar isArray = Array.isArray || function (arr) {\n  return Object.prototype.toString.call(arr) == '[object Array]'\n}\n\nfunction isArrayish (arr) {\n  return /Array\\]$/.test(Object.prototype.toString.call(arr))\n}\n\nfunction isBufferish (p) {\n  return typeof p === 'string' || isArrayish(p) || (p && typeof p.subarray === 'function')\n}\n\nfunction stringConcat (parts) {\n  var strings = []\n  var needsToString = false\n  for (var i = 0; i < parts.length; i++) {\n    var p = parts[i]\n    if (typeof p === 'string') {\n      strings.push(p)\n    } else if (Buffer.isBuffer(p)) {\n      strings.push(p)\n    } else if (isBufferish(p)) {\n      strings.push(new Buffer(p))\n    } else {\n      strings.push(new Buffer(String(p)))\n    }\n  }\n  if (Buffer.isBuffer(parts[0])) {\n    strings = Buffer.concat(strings)\n    strings = strings.toString('utf8')\n  } else {\n    strings = strings.join('')\n  }\n  return strings\n}\n\nfunction bufferConcat (parts) {\n  var bufs = []\n  for (var i = 0; i < parts.length; i++) {\n    var p = parts[i]\n    if (Buffer.isBuffer(p)) {\n      bufs.push(p)\n    } else if (isBufferish(p)) {\n      bufs.push(new Buffer(p))\n    } else {\n      bufs.push(new Buffer(String(p)))\n    }\n  }\n  return Buffer.concat(bufs)\n}\n\nfunction arrayConcat (parts) {\n  var res = []\n  for (var i = 0; i < parts.length; i++) {\n    res.push.apply(res, parts[i])\n  }\n  return res\n}\n\nfunction u8Concat (parts) {\n  var len = 0\n  for (var i = 0; i < parts.length; i++) {\n    if (typeof parts[i] === 'string') {\n      parts[i] = new Buffer(parts[i])\n    }\n    len += parts[i].length\n  }\n  var u8 = new U8(len)\n  for (var i = 0, offset = 0; i < parts.length; i++) {\n    var part = parts[i]\n    for (var j = 0; j < part.length; j++) {\n      u8[offset++] = part[j]\n    }\n  }\n  return u8\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/node_modules/readable-stream/readable.js":"var Stream = (function (){\n  try {\n    return require('st' + 'ream'); // hack to fix a circular dependency issue when used with browserify\n  } catch(_){}\n}());\nexports = module.exports = require('./lib/_stream_readable.js');\nexports.Stream = Stream || exports;\nexports.Readable = exports;\nexports.Writable = require('./lib/_stream_writable.js');\nexports.Duplex = require('./lib/_stream_duplex.js');\nexports.Transform = require('./lib/_stream_transform.js');\nexports.PassThrough = require('./lib/_stream_passthrough.js');\n\nif (!process.browser && process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream;\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_readable.js":"'use strict';\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar processNextTick = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream;\n(function () {\n  try {\n    Stream = require('st' + 'ream');\n  } catch (_) {} finally {\n    if (!Stream) Stream = require('events').EventEmitter;\n  }\n})();\n/*</replacement>*/\n\nvar Buffer = require('buffer').Buffer;\n/*<replacement>*/\nvar bufferShim = require('buffer-shims');\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = require('util');\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = require('./internal/streams/BufferList');\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') {\n    return emitter.prependListener(event, fn);\n  } else {\n    // This is a hack to make sure that our error handler is attached before any\n    // userland ones.  NEVER DO THIS. This is here only because this code needs\n    // to continue to work with older versions of Node.js that do not include\n    // the prependListener() method. The goal is to eventually remove this hack.\n    if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n  }\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (stream instanceof Duplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n  this.highWaterMark = hwm || hwm === 0 ? hwm : defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = ~ ~this.highWaterMark;\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // when piping, we only care about 'readable' events that happen\n  // after read()ing all the bytes and not getting any pushback.\n  this.ranOut = false;\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options && typeof options.read === 'function') this._read = options.read;\n\n  Stream.call(this);\n}\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n\n  if (!state.objectMode && typeof chunk === 'string') {\n    encoding = encoding || state.defaultEncoding;\n    if (encoding !== state.encoding) {\n      chunk = bufferShim.from(chunk, encoding);\n      encoding = '';\n    }\n  }\n\n  return readableAddChunk(this, state, chunk, encoding, false);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  var state = this._readableState;\n  return readableAddChunk(this, state, chunk, '', true);\n};\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\nfunction readableAddChunk(stream, state, chunk, encoding, addToFront) {\n  var er = chunkInvalid(state, chunk);\n  if (er) {\n    stream.emit('error', er);\n  } else if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else if (state.objectMode || chunk && chunk.length > 0) {\n    if (state.ended && !addToFront) {\n      var e = new Error('stream.push() after EOF');\n      stream.emit('error', e);\n    } else if (state.endEmitted && addToFront) {\n      var _e = new Error('stream.unshift() after end event');\n      stream.emit('error', _e);\n    } else {\n      var skipAdd;\n      if (state.decoder && !addToFront && !encoding) {\n        chunk = state.decoder.write(chunk);\n        skipAdd = !state.objectMode && chunk.length === 0;\n      }\n\n      if (!addToFront) state.reading = false;\n\n      // Don't add to the buffer if we've decoded to an empty string chunk and\n      // we're not in object mode\n      if (!skipAdd) {\n        // if we want the data now, just emit it.\n        if (state.flowing && state.length === 0 && !state.sync) {\n          stream.emit('data', chunk);\n          stream.read(0);\n        } else {\n          // update the buffer info.\n          state.length += state.objectMode ? 1 : chunk.length;\n          if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n          if (state.needReadable) emitReadable(stream);\n        }\n      }\n\n      maybeReadMore(stream, state);\n    }\n  } else if (!addToFront) {\n    state.reading = false;\n  }\n\n  return needMoreData(state);\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction chunkInvalid(state, chunk) {\n  var er = null;\n  if (!Buffer.isBuffer(chunk) && typeof chunk !== 'string' && chunk !== null && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) processNextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    processNextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : cleanup;\n  if (state.endEmitted) processNextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable) {\n    debug('onunpipe');\n    if (readable === src) {\n      cleanup();\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', cleanup);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        processNextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this, state);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    processNextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var state = this._readableState;\n  var paused = false;\n\n  var self = this;\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) self.push(chunk);\n    }\n\n    self.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = self.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  var events = ['error', 'close', 'destroy', 'pause', 'resume'];\n  forEach(events, function (ev) {\n    stream.on(ev, self.emit.bind(self, ev));\n  });\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  self._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return self;\n};\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = bufferShim.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    processNextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction forEach(xs, f) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    f(xs[i], i);\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/node_modules/readable-stream/node_modules/process-nextick-args/index.js":"'use strict';\n\nif (!process.version ||\n    process.version.indexOf('v0.') === 0 ||\n    process.version.indexOf('v1.') === 0 && process.version.indexOf('v1.8.') !== 0) {\n  module.exports = nextTick;\n} else {\n  module.exports = process.nextTick;\n}\n\nfunction nextTick(fn, arg1, arg2, arg3) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('\"callback\" argument must be a function');\n  }\n  var len = arguments.length;\n  var args, i;\n  switch (len) {\n  case 0:\n  case 1:\n    return process.nextTick(fn);\n  case 2:\n    return process.nextTick(function afterTickOne() {\n      fn.call(null, arg1);\n    });\n  case 3:\n    return process.nextTick(function afterTickTwo() {\n      fn.call(null, arg1, arg2);\n    });\n  case 4:\n    return process.nextTick(function afterTickThree() {\n      fn.call(null, arg1, arg2, arg3);\n    });\n  default:\n    args = new Array(len - 1);\n    i = 0;\n    while (i < args.length) {\n      args[i++] = arguments[i];\n    }\n    return process.nextTick(function afterTick() {\n      fn.apply(null, args);\n    });\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/node_modules/readable-stream/node_modules/isarray/index.js":"var toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/node_modules/readable-stream/node_modules/buffer-shims/index.js":"'use strict';\n\nvar buffer = require('buffer');\nvar Buffer = buffer.Buffer;\nvar SlowBuffer = buffer.SlowBuffer;\nvar MAX_LEN = buffer.kMaxLength || 2147483647;\nexports.alloc = function alloc(size, fill, encoding) {\n  if (typeof Buffer.alloc === 'function') {\n    return Buffer.alloc(size, fill, encoding);\n  }\n  if (typeof encoding === 'number') {\n    throw new TypeError('encoding must not be number');\n  }\n  if (typeof size !== 'number') {\n    throw new TypeError('size must be a number');\n  }\n  if (size > MAX_LEN) {\n    throw new RangeError('size is too large');\n  }\n  var enc = encoding;\n  var _fill = fill;\n  if (_fill === undefined) {\n    enc = undefined;\n    _fill = 0;\n  }\n  var buf = new Buffer(size);\n  if (typeof _fill === 'string') {\n    var fillBuf = new Buffer(_fill, enc);\n    var flen = fillBuf.length;\n    var i = -1;\n    while (++i < size) {\n      buf[i] = fillBuf[i % flen];\n    }\n  } else {\n    buf.fill(_fill);\n  }\n  return buf;\n}\nexports.allocUnsafe = function allocUnsafe(size) {\n  if (typeof Buffer.allocUnsafe === 'function') {\n    return Buffer.allocUnsafe(size);\n  }\n  if (typeof size !== 'number') {\n    throw new TypeError('size must be a number');\n  }\n  if (size > MAX_LEN) {\n    throw new RangeError('size is too large');\n  }\n  return new Buffer(size);\n}\nexports.from = function from(value, encodingOrOffset, length) {\n  if (typeof Buffer.from === 'function' && (!global.Uint8Array || Uint8Array.from !== Buffer.from)) {\n    return Buffer.from(value, encodingOrOffset, length);\n  }\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number');\n  }\n  if (typeof value === 'string') {\n    return new Buffer(value, encodingOrOffset);\n  }\n  if (typeof ArrayBuffer !== 'undefined' && value instanceof ArrayBuffer) {\n    var offset = encodingOrOffset;\n    if (arguments.length === 1) {\n      return new Buffer(value);\n    }\n    if (typeof offset === 'undefined') {\n      offset = 0;\n    }\n    var len = length;\n    if (typeof len === 'undefined') {\n      len = value.byteLength - offset;\n    }\n    if (offset >= value.byteLength) {\n      throw new RangeError('\\'offset\\' is out of bounds');\n    }\n    if (len > value.byteLength - offset) {\n      throw new RangeError('\\'length\\' is out of bounds');\n    }\n    return new Buffer(value.slice(offset, offset + len));\n  }\n  if (Buffer.isBuffer(value)) {\n    var out = new Buffer(value.length);\n    value.copy(out, 0, 0, value.length);\n    return out;\n  }\n  if (value) {\n    if (Array.isArray(value) || (typeof ArrayBuffer !== 'undefined' && value.buffer instanceof ArrayBuffer) || 'length' in value) {\n      return new Buffer(value);\n    }\n    if (value.type === 'Buffer' && Array.isArray(value.data)) {\n      return new Buffer(value.data);\n    }\n  }\n\n  throw new TypeError('First argument must be a string, Buffer, ' + 'ArrayBuffer, Array, or array-like object.');\n}\nexports.allocUnsafeSlow = function allocUnsafeSlow(size) {\n  if (typeof Buffer.allocUnsafeSlow === 'function') {\n    return Buffer.allocUnsafeSlow(size);\n  }\n  if (typeof size !== 'number') {\n    throw new TypeError('size must be a number');\n  }\n  if (size >= MAX_LEN) {\n    throw new RangeError('size is too large');\n  }\n  return new SlowBuffer(size);\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/node_modules/readable-stream/node_modules/core-util-is/lib/util.js":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\n\nfunction isArray(arg) {\n  if (Array.isArray) {\n    return Array.isArray(arg);\n  }\n  return objectToString(arg) === '[object Array]';\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = Buffer.isBuffer;\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/node_modules/inherits/inherits.js":"try {\n  var util = require('util');\n  if (typeof util.inherits !== 'function') throw '';\n  module.exports = util.inherits;\n} catch (e) {\n  module.exports = require('./inherits_browser.js');\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/node_modules/readable-stream/lib/internal/streams/BufferList.js":"'use strict';\n\nvar Buffer = require('buffer').Buffer;\n/*<replacement>*/\nvar bufferShim = require('buffer-shims');\n/*</replacement>*/\n\nmodule.exports = BufferList;\n\nfunction BufferList() {\n  this.head = null;\n  this.tail = null;\n  this.length = 0;\n}\n\nBufferList.prototype.push = function (v) {\n  var entry = { data: v, next: null };\n  if (this.length > 0) this.tail.next = entry;else this.head = entry;\n  this.tail = entry;\n  ++this.length;\n};\n\nBufferList.prototype.unshift = function (v) {\n  var entry = { data: v, next: this.head };\n  if (this.length === 0) this.tail = entry;\n  this.head = entry;\n  ++this.length;\n};\n\nBufferList.prototype.shift = function () {\n  if (this.length === 0) return;\n  var ret = this.head.data;\n  if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n  --this.length;\n  return ret;\n};\n\nBufferList.prototype.clear = function () {\n  this.head = this.tail = null;\n  this.length = 0;\n};\n\nBufferList.prototype.join = function (s) {\n  if (this.length === 0) return '';\n  var p = this.head;\n  var ret = '' + p.data;\n  while (p = p.next) {\n    ret += s + p.data;\n  }return ret;\n};\n\nBufferList.prototype.concat = function (n) {\n  if (this.length === 0) return bufferShim.alloc(0);\n  if (this.length === 1) return this.head.data;\n  var ret = bufferShim.allocUnsafe(n >>> 0);\n  var p = this.head;\n  var i = 0;\n  while (p) {\n    p.data.copy(ret, i);\n    i += p.data.length;\n    p = p.next;\n  }\n  return ret;\n};","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_writable.js":"// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict';\n\nmodule.exports = Writable;\n\n/*<replacement>*/\nvar processNextTick = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : processNextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream;\n(function () {\n  try {\n    Stream = require('st' + 'ream');\n  } catch (_) {} finally {\n    if (!Stream) Stream = require('events').EventEmitter;\n  }\n})();\n/*</replacement>*/\n\nvar Buffer = require('buffer').Buffer;\n/*<replacement>*/\nvar bufferShim = require('buffer-shims');\n/*</replacement>*/\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (stream instanceof Duplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n  this.highWaterMark = hwm || hwm === 0 ? hwm : defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = ~ ~this.highWaterMark;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  processNextTick(cb, er);\n}\n\n// If we get something that is not a buffer, string, null, or undefined,\n// and we're not in objectMode, then that's an error.\n// Otherwise stream chunks are all considered to be of length=1, and the\n// watermarks determine how many objects to keep in the buffer, rather than\n// how many bytes or characters.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n  // Always throw error if a null is written\n  // if we are not in object mode then throw\n  // if it is not a buffer, string, or undefined.\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (!Buffer.isBuffer(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    processNextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (Buffer.isBuffer(chunk)) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = bufferShim.from(chunk, encoding);\n  }\n  return chunk;\n}\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, chunk, encoding, cb) {\n  chunk = decodeChunk(state, chunk, encoding);\n\n  if (Buffer.isBuffer(chunk)) encoding = 'buffer';\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = new WriteReq(chunk, encoding, cb);\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n  if (sync) processNextTick(cb, er);else cb(er);\n\n  stream._writableState.errorEmitted = true;\n  stream.emit('error', er);\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n        afterWrite(stream, state, finished, cb);\n      }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    while (entry) {\n      buffer[count] = entry;\n      entry = entry.next;\n      count += 1;\n    }\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequestCount = 0;\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\n\nfunction prefinish(stream, state) {\n  if (!state.prefinished) {\n    state.prefinished = true;\n    stream.emit('prefinish');\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    if (state.pendingcb === 0) {\n      prefinish(stream, state);\n      state.finished = true;\n      stream.emit('finish');\n    } else {\n      prefinish(stream, state);\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) processNextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n\n  this.finish = function (err) {\n    var entry = _this.entry;\n    _this.entry = null;\n    while (entry) {\n      var cb = entry.callback;\n      state.pendingcb--;\n      cb(err);\n      entry = entry.next;\n    }\n    if (state.corkedRequestsFree) {\n      state.corkedRequestsFree.next = _this;\n    } else {\n      state.corkedRequestsFree = _this;\n    }\n  };\n}","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/node_modules/readable-stream/node_modules/util-deprecate/node.js":"\n/**\n * For Node.js, simply re-export the core `util.deprecate` function.\n */\n\nmodule.exports = require('util').deprecate;\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_duplex.js":"// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n'use strict';\n\n/*<replacement>*/\n\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar processNextTick = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\nvar keys = objectKeys(Writable.prototype);\nfor (var v = 0; v < keys.length; v++) {\n  var method = keys[v];\n  if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  processNextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nfunction forEach(xs, f) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    f(xs[i], i);\n  }\n}","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_transform.js":"// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict';\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction TransformState(stream) {\n  this.afterTransform = function (er, data) {\n    return afterTransform(stream, er, data);\n  };\n\n  this.needTransform = false;\n  this.transforming = false;\n  this.writecb = null;\n  this.writechunk = null;\n  this.writeencoding = null;\n}\n\nfunction afterTransform(stream, er, data) {\n  var ts = stream._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) return stream.emit('error', new Error('no writecb in Transform class'));\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data !== null && data !== undefined) stream.push(data);\n\n  cb(er);\n\n  var rs = stream._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    stream._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = new TransformState(this);\n\n  var stream = this;\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.once('prefinish', function () {\n    if (typeof this._flush === 'function') this._flush(function (er, data) {\n      done(stream, er, data);\n    });else done(stream);\n  });\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data !== null && data !== undefined) stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  var ws = stream._writableState;\n  var ts = stream._transformState;\n\n  if (ws.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (ts.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_passthrough.js":"// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/parse-proc-cpuinfo.js":"'use strict'\n\nvar logger = require('./logger.js').child({component: 'proc-cpuinfo'})\nmodule.exports = parseProcCPUInfo\n\nfunction parseProcCPUInfo(data) {\n  var relevantAttributes = [\n    'processor',\n    'physical id',\n    'cpu cores',\n    'core id'\n  ]\n\n  var processorStats = {\n    logical: null,\n    cores: null,\n    packages: null\n  }\n\n  // seperate the processors\n  var splitData = data.split('\\n')\n    .map(function formatAttribute(attr) {\n      return attr.split(':')\n        .map(function eliminateExtraWhitespace(s) {\n          return s.replace(/\\\\r|\\\\t| {2,}/g, '').trim()\n        })\n    })\n\n  var validData = splitData.filter(function checkForValidAttrs(a) {\n    return a.length === 2 && relevantAttributes.indexOf(a[0]) !== -1\n  })\n  if (validData.length === 0) {\n    logger.debug('No applicable cpu attributes found')\n    return processorStats\n  }\n\n  splitData = collapseMultilineValues(splitData)\n\n  var processors = seperateProcessors(splitData)\n\n  processorStats = countProcessorStats(processors)\n  if (!processorStats.cores) {\n    if (processorStats.logical === 1) {\n      // some older, single-core processors might not list ids,\n      // so we'll mark them 1\n      processorStats.cores = 1\n      processorStats.packages = 1\n    } else {\n      // there is no way of knowing how many packages\n      // or cores there are\n      processorStats.cores = null\n      processorStats.packages = null\n    }\n  }\n  return processorStats\n}\n\n// some values are split up over multiple lines, these won't be broken\n// by split(':'), and should be folded into the last seen valid value\nfunction collapseMultilineValues(li) {\n  var tmp = []\n  var last\n  for (var i = 0; i < li.length; ++i) {\n    if (li[i].length === 2) {\n      // store the last valid entry to append invalid entries to\n      last = li[i]\n      tmp.push(last)\n    } else {\n      last[1] += li[i][0]\n    }\n  }\n\n  return tmp\n}\n\n// walk through the processed list of key, value pairs and populate\n// objects till you find a collision\nfunction seperateProcessors(processorData) {\n  var processors = []\n  var processor = {}\n  for (var i = 0; i < processorData.length; ++i) {\n    var key = processorData[i][0]\n    var value = processorData[i][1]\n    if (processor[key] !== undefined) {\n      processors.push(processor)\n      processor = {}\n    }\n    processor[key] = value\n  }\n  processors.push(processor)\n  return processors\n}\n\nfunction countProcessorStats(processors) {\n  var phys = []\n  var cores = []\n\n  for (var i = 0; i < processors.length; i++) {\n    var processor = processors[i]\n    if (processor['physical id'] &&\n        processor['cpu cores'] &&\n        phys.indexOf(processor['physical id']) === -1) {\n      phys.push(processor['physical id'])\n      cores.push(processor['cpu cores'])\n    }\n  }\n\n  return {\n    logical: processors.length,\n    cores: cores\n      .map(function convertToInt(s) {\n        return parseInt(s, 10)\n      })\n      .reduce(function sum(a, b) {\n        return a + b\n      }, 0),\n    packages: phys.length\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/parse-dockerinfo.js":"'use strict'\n\nvar logger = require('./logger.js').child({component: 'dockerinfo'})\nvar NAMES = require('./metrics/names.js')\nmodule.exports = parseDockerInfo\n\nfunction parseDockerInfo(agent, data) {\n  if (!agent.config.utilization || !agent.config.utilization.detect_docker) return null\n  var cpuCgroup = parseCgroupIds(data).cpu\n  // if we can't parse the cgroups, or if the cpu is not in a cgroup\n  var dockerError = agent.metrics.getOrCreateMetric(NAMES.UTILIZATION.DOCKER_ERROR)\n  if (!cpuCgroup) {\n    logger.debug('Could not parse cgroup data from: ' + data)\n    dockerError.incrementCallCount()\n    return null\n  }\n\n  // if cpu isn't in a cgroup\n  if (cpuCgroup === '/') return null\n\n  var patterns = [\n    /^\\/docker\\/([0-9a-f]+)$/, // docker native driver w/out systemd\n    /^\\/system\\.slice\\/docker-([0-9a-f]+)\\.scope$/, // with systemd\n    /^\\/lxc\\/([0-9a-f]+)$/ // docker lxc driver\n  ]\n  for (var i = 0; i < patterns.length; i++) {\n    var pattern = patterns[i]\n    var matches = cpuCgroup.match(pattern)\n    if (matches) {\n      var id = matches[1]\n      if (id.length !== 64) {\n        dockerError.incrementCallCount()\n        logger.debug('Encountered a malformed docker id: ', id)\n        return null\n      }\n      return id\n    }\n  }\n\n  logger.debug('Unable to recognise cgroup format')\n\n  return null\n}\n\nfunction parseCgroupIds(cgroupInfo) {\n  var cgroupIds = {}\n  cgroupInfo.split('\\n').forEach(function parseCgroupInfo(line) {\n    var parts = line.split(':')\n    if (parts.length !== 3) return\n    var subsystems = parts[1]\n    var cgroupId = parts[2]\n    subsystems.split(',').forEach(function assignGroupIds(subsystem) {\n      cgroupIds[subsystem] = cgroupId\n    })\n  })\n  return cgroupIds\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/parse-proc-meminfo.js":"'use strict'\n\nvar logger = require('./logger.js').child({component: 'proc-meminfo'})\n\nmodule.exports = parseProcMeminfo\n\nfunction parseProcMeminfo(data) {\n  var mem_total = parseInt(data.replace(/MemTotal:\\s*(\\d*)\\skB/, '$1'), 10)\n\n  if (mem_total) return mem_total / 1024\n\n  logger.debug('Unable to parse memory string:', data)\n  return null\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/util/label-parser.js":"'use strict'\n\nmodule.exports = parse\nmodule.exports.fromString = fromString\nmodule.exports.fromMap = fromMap\n\n\n// this creates a copy of trim that can be used with map\nvar trim = Function.prototype.call.bind(String.prototype.trim)\nvar logger = require('../logger').child({component: 'label-parser'})\nvar stringifySync = require('./safe-json').stringifySync\n\nfunction parse(labels) {\n  var results\n\n  if (!labels) {\n    return []\n  } else if (typeof labels === 'string') {\n    results = fromString(labels)\n  } else if (labels) {\n    results = fromMap(labels)\n  }\n\n  results.warnings.forEach(function logWarnings(messaage) {\n    logger.warn(messaage)\n  })\n\n  return results.labels\n}\n\nfunction fromString(raw) {\n  var map = {}\n\n  if (!raw) {\n    return {labels: [], warnings: []}\n  }\n\n  var pairs = raw.split(';').map(trim)\n  var parts\n\n\n  while (!pairs[pairs.length - 1]) {\n    pairs.pop()\n  }\n\n  while (!pairs[0]) {\n    pairs.shift()\n  }\n\n  for (var i = 0, l = pairs.length; i < l; ++i) {\n    parts = pairs[i].split(':').map(trim)\n\n    if (parts.length !== 2) {\n      return warn('Could not create a Label pair from ' + parts[i])\n    } else if (!parts[0]) {\n      return warn('Label key can not be empty')\n    } else if (!parts[1]) {\n      return warn('Label value can not be empty')\n    }\n\n    map[parts[0]] = parts[1]\n  }\n\n  return fromMap(map)\n\n  function warn(message) {\n    return {labels: [], warnings: [\n      'Invalid Label String: ' + raw,\n       message\n    ]}\n  }\n}\n\nfunction fromMap(map) {\n  var warnings = []\n  var labels = []\n\n  Object.keys(map).forEach(function processKeys(key) {\n    var type = truncate(key, 255)\n\n    if (!map[key] || typeof map[key] !== 'string') {\n      return warnings.push(\n        'Label value for ' + type +\n        'should be a string with a length between 1 and 255 characters'\n      )\n    }\n\n    var value = truncate(map[key], 255)\n\n    if (type !== key) {\n      warnings.push('Label key too long: ' + type)\n    }\n\n    if (value !== map[key]) {\n      warnings.push('Label value too long: ' + value)\n    }\n\n    labels.push({label_type: type, label_value: value})\n  })\n\n  if (labels.length > 64) {\n    warnings.push('Too many Labels, list truncated to 64')\n    labels = labels.slice(0, 64)\n  }\n\n  if (warnings.length) {\n    warnings.unshift('Partially Invalid Label Setting: ' + stringifySync(map))\n  }\n\n  return {labels: labels, warnings: warnings}\n}\n\nfunction truncate(str, max) {\n  var len = 0\n  var chr\n  for (var i = 0, l = str.length; i < l; ++i) {\n    chr = str.charCodeAt(i)\n    if (chr >= 0xD800 && chr <= 0xDBFF && i !== l) {\n      i += 1\n    }\n\n    if (++len === max) {\n      break\n    }\n  }\n\n  return str.slice(0, i + 1)\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/collector/remote-method.js":"'use strict'\n\nvar util = require('util')\nvar url = require('url')\nvar http = require('http')\nvar https = require('https')\nvar zlib = require('zlib')\nvar logger = require('../logger').child({component: 'remote_method_invoke'})\nvar parse = require('./parse-response')\nvar safeJSON = require('../util/safe-json')\nvar Sink = require('../util/stream-sink')\nvar agents = require('./http-agents')\nvar certificates = require('./ssl/certificates')\n\n/*\n *\n * CONSTANTS\n *\n */\nvar PROTOCOL_VERSION = 14\nvar RUN_ID_NAME = 'run_id'\nvar RAW_METHOD_PATH = '/agent_listener/invoke_raw_method'\n  // see job/collector-master/javadoc/com/nr/servlet/AgentListener.html on NR Jenkins\nvar USER_AGENT_FORMAT = \"NewRelic-NodeAgent/%s (nodejs %s %s-%s)\"\nvar ENCODING_HEADER = 'CONTENT-ENCODING'\nvar CONTENT_TYPE_HEADER = 'Content-Type'\nvar DEFAULT_ENCODING = 'identity'\nvar DEFAULT_CONTENT_TYPE = 'application/json'\nvar COMPRESSED_CONTENT_TYPE = 'application/octet-stream'\n\n\nfunction RemoteMethod(name, config) {\n  if (!name) {\n    throw new TypeError(\"Must include name of method to invoke on collector.\")\n  }\n\n  this.name = name\n  this._config = config\n}\n\nRemoteMethod.prototype.serialize = function serialize(payload, callback) {\n  try {\n    var res = safeJSON.stringifySync(payload)\n  } catch (error) {\n    logger.error(error, \"Unable to serialize payload for method %s.\", this.name)\n    return process.nextTick(function cb_nextTick() {\n      return callback(error)\n    })\n  }\n  return callback(null, res)\n}\n\n/**\n * The primary operation on RemoteMethod objects. If you're calling anything on\n * RemoteMethod objects aside from invoke (and you're not writing test code),\n * you're doing it wrong.\n *\n * @param object   payload    Serializable payload.\n * @param Function callback   What to do next. Gets passed any error.\n */\nRemoteMethod.prototype.invoke = function call(payload, callback) {\n  if (!payload) payload = []\n\n  this.serialize(payload, function cb_serialize(err, serialized) {\n    if (err) return callback(err)\n    this._post(serialized, callback)\n  }.bind(this))\n}\n\n/**\n * Take a serialized payload and create a response wrapper for it before\n * invoking the method on the collector.\n *\n * @param string   methodName Name of method to invoke on collector.\n * @param string   data       Serialized payload.\n * @param Function callback   What to do next. Gets passed any error.\n */\nRemoteMethod.prototype._post = function _post(data, callback) {\n  var method = this\n\n  // set up standard response handling\n  function onResponse(response) {\n    response.on('end', function handle_end() {\n      logger.debug(\n        \"Finished receiving data back from the collector for %s.\",\n        method.name\n      )\n    })\n\n    response.setEncoding('utf8')\n    response.pipe(new Sink(parse(method.name, response, callback)))\n  }\n\n  var options = {\n    port: this._config.port,\n    host: this._config.host,\n    compressed: this._shouldCompress(data),\n    path: this._path(),\n    onError: callback,\n    onResponse: onResponse\n  }\n\n  if (options.compressed) {\n    logger.trace({data: data}, \"Sending %s on collector API with (COMPRESSED)\", this.name)\n\n    var useGzip = this._config.compressed_content_encoding === 'gzip'\n    var compressor = useGzip ? zlib.gzip : zlib.deflate\n    compressor(data, function cb_compressor(err, compressed) {\n      if (err) {\n        logger.warn(err, \"Error compressing JSON for delivery. Not sending.\")\n        return callback(err)\n      }\n\n      options.body = compressed\n      method._safeRequest(options)\n    })\n  } else {\n    logger.debug({data: data}, \"Calling %s on collector API\", this.name)\n\n    options.body = data\n    this._safeRequest(options)\n  }\n}\n\n/**\n * http.request does its own DNS lookup, and if it fails, will cause\n * dns.lookup to throw asynchronously instead of passing the error to\n * the callback (which is obviously awesome). To prevent New Relic from\n * crashing people's applications, verify that lookup works and bail out\n * early if not.\n *\n * Also, ensure that all the necessary parameters are set before\n * actually making the request. Useful to put here to simplify test code\n * that calls _request directly.\n *\n * @param object options A dictionary of request parameters.\n */\nRemoteMethod.prototype._safeRequest = function _safeRequest(options) {\n  if (!options) throw new Error(\"Must include options to make request!\")\n  if (!options.host) throw new Error(\"Must include collector hostname!\")\n  if (!options.port) throw new Error(\"Must include collector port!\")\n  if (!options.onError) throw new Error(\"Must include error handler!\")\n  if (!options.onResponse) throw new Error(\"Must include response handler!\")\n  if (!options.body) throw new Error(\"Must include body to send to collector!\")\n  if (!options.path) throw new Error(\"Must include URL to request!\")\n\n  var protocol = this._config.ssl ? 'https' : 'http'\n  var logconfig = this._config.logging\n  var audit_log = this._config.audit_log\n  var logevent = util.format({\n    body: Buffer.isBuffer(options.body) ? 'Buffer ' + options.body.length : options.body\n  }, \"Posting to %s://%s:%s%s\",\n    protocol,\n    options.host,\n    options.port,\n    options.path\n  )\n  // if trace level is not explicity enabled\n  // check to see if the audit log is enabled\n  if ((typeof logconfig !== 'undefined') && logconfig.level !== 'trace') {\n    if (audit_log.enabled &&\n          // if the filter property is empty, then always log the event\n          // otherwise check to see if the filter includes this method\n          (audit_log.endpoints.length > 0 ?\n           audit_log.endpoints.indexOf(this.name) > -1 : true)) {\n      logger.info(logevent)\n    }\n  } else {\n    logger.trace(logevent)\n  }\n\n\n  this._request(options)\n}\n\n/**\n * Generate the request headers and wire up the request. There are many\n * parameters used to make a request:\n *\n * @param string   options.host       Hostname (or proxy hostname) for collector.\n * @param string   options.port       Port (or proxy port) for collector.\n * @param string   options.path       URL path for method being invoked on collector.\n * @param string   options.body       Serialized payload to be sent to collector.\n * @param boolean  options.compressed Whether the payload has been compressed.\n * @param Function options.onError    Error handler for this request (probably the\n *                                    original callback given to .send).\n * @param Function options.onResponse Response handler for this request (created by\n *                                    ._post).\n */\nRemoteMethod.prototype._request = function _request(options) {\n  var requestOptions = {\n    method: this._config.put_for_data_send ? 'PUT' : 'POST',\n    setHost: false,         // See below\n    host: options.host,     // Set explicitly in the headers\n    port: options.port,\n    path: options.path,\n    headers: this._headers(options.body, options.compressed),\n    __NR__connection: true  // Who measures the metrics measurer?\n  }\n  var request\n\n  var isProxy = !!(\n    this._config.proxy ||\n    this._config.proxy_port ||\n    this._config.proxy_host\n  )\n\n  if (isProxy) {\n    // proxy\n    requestOptions.agent = agents.proxyAgent(this._config)\n    request = https.request(requestOptions)\n\n    // FIXME: The agent keeps this connection open when using the proxy.\n    // This will prevent the application from shutting down correctly.\n    // Explicitly destroy the socket when the response is completed.\n    //\n    // This goes against keep-alive, but for now letting the application die\n    // gracefully is more important.\n    request.on('response', function cb_on_response(sock) {\n      sock.on('end', function cb_on_end() {\n        sock.destroy()\n      })\n    })\n  } else if (this._config.ssl) {\n    if (this._config.certificates && this._config.certificates.length > 0) {\n      logger.debug(\n        'Adding custom certificate to the cert bundle.'\n      )\n      requestOptions.ca = this._config.certificates.concat(certificates)\n    }\n    request = https.request(requestOptions)\n  } else {\n    request = http.request(requestOptions)\n  }\n\n  request.on('error', options.onError)\n  request.on('response', options.onResponse)\n\n  request.end(options.body)\n}\n\n/**\n * See the constants list for the format string (and the URL that explains it).\n */\nRemoteMethod.prototype._userAgent = function _userAgent() {\n  return util.format(USER_AGENT_FORMAT,\n                     this._config.version,\n                     process.versions.node,\n                     process.platform,\n                     process.arch)\n}\n\n/**\n * Generate a URL the collector understands.\n *\n * @returns string The URL path to be POSTed to.\n */\nRemoteMethod.prototype._path = function _path() {\n  var query = {\n      marshal_format: 'json',\n      protocol_version: PROTOCOL_VERSION,\n      license_key: this._config.license_key,\n      method: this.name\n  }\n\n  if (this._config.run_id) query[RUN_ID_NAME] = this._config.run_id\n\n  var formatted = url.format({\n    pathname: RAW_METHOD_PATH,\n    query: query\n  })\n\n  return formatted\n}\n\n/**\n * @param {number}  length      - Length of data to be sent.\n * @param {bool}    compressed  - The compression method used, if any.\n */\nRemoteMethod.prototype._headers = function _headers(body, compressed) {\n  var agent = this._userAgent()\n\n  var headers = {\n    // select the virtual host on the server end\n    'Host': this._config.host,\n    'User-Agent': agent,\n    'Connection': 'Keep-Alive',\n    'Content-Length': byteLength(body)\n  }\n\n  if (compressed) {\n    headers[ENCODING_HEADER] = this._config.compressed_content_encoding\n    headers[CONTENT_TYPE_HEADER] = COMPRESSED_CONTENT_TYPE\n  } else {\n    headers[ENCODING_HEADER] = DEFAULT_ENCODING\n    headers[CONTENT_TYPE_HEADER] = DEFAULT_CONTENT_TYPE\n  }\n\n  return headers\n}\n\n/**\n * FLN pretty much decided on his own recognizance that 64K was a good point\n * at which to compress a server response. There's only a loose consensus that\n * the threshold should probably be much higher than this, if only to keep the\n * load on the collector down.\n *\n * FIXME: come up with a better heuristic\n */\nRemoteMethod.prototype._shouldCompress = function _shouldCompress(data) {\n  return data && byteLength(data) > 65536\n}\n\nfunction byteLength(data) {\n  if (!data) {\n    return 0\n  }\n\n  if (data instanceof Buffer) {\n    return data.length\n  }\n\n  return Buffer.byteLength(data, 'utf8')\n}\n\nmodule.exports = RemoteMethod\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/collector/parse-response.js":"'use strict'\n\nvar format = require('util').format\nvar logger = require('../logger').child({component: 'new_relic_response'})\n\n\n/*\n *\n * CONSTANTS\n *\n */\nvar RESPONSE_VALUE_NAME = 'return_value'\nvar EXCEPTION_VALUE_NAME = 'exception'\n\n\n/**\n * The collector has many ways of indicating failure, and isn't\n * necessarily consistent. Because there can either be a failure at\n * the network level, a nonstandard HTTP status code on the response,\n * or a JSON-encoded exception in the response body, there's a lot of\n * conditional logic in here that tries to grab as much information\n * about errors as possible, and to parse out the return value as often\n * as possible.\n *\n * @param string         name     Remote method name that was invoked.\n * @param ServerResponse response HTTP response stream\n * @param Function       callback Function that will be called with any\n *                                error, the value returned by the server\n *                                (if any), and the raw JSON of the\n *                                server's response.\n *\n * @returns Function Another callback that is meant to be invoked with\n *                   any errors from reading the response stream, as\n *                   well as a string containing the full response.\n */\nmodule.exports = function parse(name, response, callback) {\n  if (!name) throw new TypeError('collector method name required!')\n  if (!response) throw new TypeError('HTTP response required!')\n  if (!callback) throw new TypeError('callback required!')\n\n  return function parser(inError, body) {\n    /* jshint maxdepth:4 */\n\n    var code = response.statusCode\n    var errors = []\n    var errorClass\n    var json\n    var returned\n\n\n    if (code !== 200) logger.debug(\"Got %s as a response code from the collector.\", code)\n\n    if (inError) errors.push(inError)\n\n    if (body) {\n      try {\n        json = JSON.parse(body)\n\n        // Can be super verbose, but useful for debugging.\n        logger.trace({response: json}, \"Deserialized from collector:\")\n\n        // If we get messages back from the collector, be polite and pass them along.\n        returned = json[RESPONSE_VALUE_NAME]\n        if (returned && returned.messages) {\n          returned.messages.forEach(function cb_forEach(element) {\n            logger.info(element.message)\n          })\n        }\n\n        /* Wait to deal with errors in the response until any messages have\n         * been passed along. Otherwise, ensure that there was a return\n         * value, raising an error if not.\n         *\n         * Some errors are only interesting if the status code indicates\n         * that the request went bad already, so filter out adding more\n         * errors when statusCode is not OK (200).\n         */\n        var exception = json[EXCEPTION_VALUE_NAME]\n        if (exception) {\n          if (exception.message) {\n            errors.push(new Error(exception.message))\n          } else if (code === 200 ) {\n            errors.push(new Error('New Relic internal error'))\n          }\n\n          if (exception.error_type) errorClass = exception.error_type\n        } else if (code === 200 && returned === undefined) {\n          errors.push(new Error(format('No data found in response to %s.', name)))\n        }\n      } catch (error) {\n        logger.trace(error, 'Could not parse response from the collector: %s', body)\n        errors.push(error)\n      }\n    } else {\n      errors.push(new Error(format('No body found in response to %s.', name)))\n    }\n\n    if (code !== 200) {\n      errors.push(new Error(format('Got HTTP %s in response to %s.', code, name)))\n    }\n\n    var error\n    if (errors.length > 0) {\n      error = errors.shift()\n      error.statusCode = code\n      // Preserve a consistent hidden class (cheaper than sub-classing Error).\n      error.class = errorClass ? errorClass : undefined\n      error.laterErrors = (errors.length > 0) ? errors : undefined\n    }\n\n    // Raw json is useful for testing and logging.\n    process.nextTick(function cb_nextTick() {\n      callback(error, returned, json)\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/util/stream-sink.js":"'use strict'\n\nvar EventEmitter = require('events').EventEmitter\nvar util = require('util')\n\n\n/**\n * Pipe a readable stream into this sink that fulfills the Writable Stream\n * contract and the callback will be fired when the stream has been completely\n * read.\n */\nfunction StreamSink(callback) {\n  EventEmitter.call(this)\n\n  this.callback = callback\n  this.sink = ''\n  this.writable = true\n\n  var sink = this\n  this.on('error', function handle_error(error) {\n    sink.writable = false\n    callback(error)\n  })\n}\nutil.inherits(StreamSink, EventEmitter)\n\nStreamSink.prototype.write = function write(string) {\n  if (!this.writable) {\n    this.emit('error', new Error(\"Sink no longer writable!\"))\n    return false\n  }\n\n  // Explicitly copy buffer contents so we are sure to release references to\n  // the TLS slab buffer region.\n  this.sink += string.toString()\n\n  return true\n}\n\nStreamSink.prototype.end = function end() {\n  this.writable = false\n\n  this.callback(null, this.sink)\n}\n\nStreamSink.prototype.destroy = function destroy() {\n  this.emit('close')\n  this.writable = false\n\n  delete this.sink\n}\n\nmodule.exports = StreamSink\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/collector/http-agents.js":"'use strict'\n\nvar parse = require('url').parse\nvar ProxyAgent = require('https-proxy-agent')\nvar logger = require('../logger').child({component: 'http-agent'})\nvar certificates = require('./ssl/certificates.js')\n\nexports.proxyAgent = function proxyAgent(config) {\n  var opts = proxyOptions(config)\n  var proxy_url = opts.proxy_url\n\n  var proxy_opts = {\n    host: proxy_url.host,\n    port: proxy_url.port,\n    protocol: proxy_url.protocol,\n    secureEndpoint: config.ssl,\n    auth: proxy_url.auth,\n    ca: opts.certificates\n  }\n\n  logger.info({\n    host: proxy_opts.host,\n    port: proxy_opts.port,\n    auth: !!proxy_opts.auth,\n    protocol: proxy_url.protocol\n  }, 'using proxy')\n\n  var proxy = new ProxyAgent(proxy_opts)\n\n  return proxy\n}\n\nfunction proxyOptions(config) {\n  if (config.proxy) {\n    var parsed_url = parse(config.proxy)\n\n    var proxy_url = {\n      protocol: parsed_url.protocol || 'http:',\n      host: parsed_url.hostname,\n      port: parsed_url.port || 80,\n      auth: parsed_url.auth\n    }\n  } else {\n    var proxy_auth = config.proxy_user\n    if (config.proxy_pass !== '') {\n      proxy_auth += ':' + config.proxy_pass\n    }\n\n    // Unless a proxy config is provided, default to HTTP.\n    proxy_url = {\n      protocol: 'http:',\n      host: config.proxy_host || 'localhost',\n      port: config.proxy_port || 80,\n      auth: proxy_auth\n    }\n  }\n\n  var opts = {\n    proxy_url: proxy_url\n  }\n\n  // merge user certificates with built-in certs\n\n  if (config.certificates && config.certificates.length > 0) {\n    logger.info(\n      'Using a proxy with a special cert. This enables our cert bundle which, combined ' +\n      'with some versions of node, exacerbates a leak in node core TLS.'\n    )\n    opts.certificates = config.certificates.concat(certificates)\n  }\n\n  return opts\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/https-proxy-agent/https-proxy-agent.js":"\n/**\n * Module dependencies.\n */\n\nvar net = require('net');\nvar tls = require('tls');\nvar url = require('url');\nvar extend = require('extend');\nvar Agent = require('agent-base');\nvar inherits = require('util').inherits;\nvar debug = require('debug')('https-proxy-agent');\n\n/**\n * Module exports.\n */\n\nmodule.exports = HttpsProxyAgent;\n\n/**\n * The `HttpsProxyAgent` implements an HTTP Agent subclass that connects to the\n * specified \"HTTP(s) proxy server\" in order to proxy HTTPS requests.\n *\n * @api public\n */\n\nfunction HttpsProxyAgent (opts) {\n  if (!(this instanceof HttpsProxyAgent)) return new HttpsProxyAgent(opts);\n  if ('string' == typeof opts) opts = url.parse(opts);\n  if (!opts) throw new Error('an HTTP(S) proxy server `host` and `port` must be specified!');\n  debug('creating new HttpsProxyAgent instance: %j', opts);\n  Agent.call(this, connect);\n\n  var proxy = extend({}, opts);\n\n  // if `true`, then connect to the proxy server over TLS. defaults to `false`.\n  this.secureProxy = proxy.protocol ? /^https:?$/i.test(proxy.protocol) : false;\n\n  // if `true`, then connect to the destination endpoint over TLS, defaults to `true`\n  this.secureEndpoint = opts.secureEndpoint !== false;\n\n  // prefer `hostname` over `host`, and set the `port` if needed\n  proxy.host = proxy.hostname || proxy.host;\n  proxy.port = +proxy.port || (this.secureProxy ? 443 : 80);\n\n  if (proxy.host && proxy.path) {\n    // if both a `host` and `path` are specified then it's most likely the\n    // result of a `url.parse()` call... we need to remove the `path` portion so\n    // that `net.connect()` doesn't attempt to open that as a unix socket file.\n    delete proxy.path;\n    delete proxy.pathname;\n  }\n\n  this.proxy = proxy;\n}\ninherits(HttpsProxyAgent, Agent);\n\n/**\n * Default options for the \"connect\" opts object.\n */\n\nvar defaults = { port: 80 };\nvar secureDefaults = { port: 443 };\n\n/**\n * Called when the node-core HTTP client library is creating a new HTTP request.\n *\n * @api public\n */\n\nfunction connect (req, _opts, fn) {\n\n  var proxy = this.proxy;\n  var secureProxy = this.secureProxy;\n  var secureEndpoint = this.secureEndpoint;\n\n  // create a socket connection to the proxy server\n  var socket;\n  if (secureProxy) {\n    socket = tls.connect(proxy);\n  } else {\n    socket = net.connect(proxy);\n  }\n\n  // these `opts` are the connect options to connect to the destination endpoint\n  // XXX: we mix in the proxy options so that TLS options like\n  // `rejectUnauthorized` get passed to the destination endpoint as well\n  var proxyOpts = extend({}, proxy);\n  delete proxyOpts.host;\n  delete proxyOpts.hostname;\n  delete proxyOpts.port;\n  var opts = extend({}, proxyOpts, secureEndpoint ? secureDefaults : defaults, _opts);\n\n  // we need to buffer any HTTP traffic that happens with the proxy before we get\n  // the CONNECT response, so that if the response is anything other than an \"200\"\n  // response code, then we can re-play the \"data\" events on the socket once the\n  // HTTP parser is hooked up...\n  var buffers = [];\n  var buffersLength = 0;\n\n  function read () {\n    var b = socket.read();\n    if (b) ondata(b);\n    else socket.once('readable', read);\n  }\n\n  function cleanup () {\n    socket.removeListener('data', ondata);\n    socket.removeListener('end', onend);\n    socket.removeListener('error', onerror);\n    socket.removeListener('close', onclose);\n    socket.removeListener('readable', read);\n  }\n\n  function onclose (err) {\n    debug('onclose had error', err);\n  }\n\n  function onend () {\n    debug('onend');\n  }\n\n  function onerror (err) {\n    cleanup();\n    fn(err);\n  }\n\n  function ondata (b) {\n    buffers.push(b);\n    buffersLength += b.length;\n    var buffered = Buffer.concat(buffers, buffersLength);\n    var str = buffered.toString('ascii');\n\n    if (!~str.indexOf('\\r\\n\\r\\n')) {\n      // keep buffering\n      debug('have not received end of HTTP headers yet...');\n      if (socket.read) {\n        read();\n      } else {\n        socket.once('data', ondata);\n      }\n      return;\n    }\n\n    var firstLine = str.substring(0, str.indexOf('\\r\\n'));\n    var statusCode = +firstLine.split(' ')[1];\n    debug('got proxy server response: \"%s\"', firstLine);\n    //console.log('statusCode: %d', statusCode);\n    //console.log(b.length, b, b.toString());\n\n    if (200 == statusCode) {\n      // 200 Connected status code!\n      var sock = socket;\n\n      // nullify the buffered data since we won't be needing it\n      buffers = buffered = null;\n\n      if (secureEndpoint) {\n        // since the proxy is connecting to an SSL server, we have\n        // to upgrade this socket connection to an SSL connection\n        debug('upgrading proxy-connected socket to TLS connection: \"%s\"', opts.host);\n        opts.socket = socket;\n        opts.servername = opts.host;\n        opts.host = null;\n        opts.hostname = null;\n        opts.port = null;\n        sock = tls.connect(opts);\n      }\n\n      cleanup();\n      fn(null, sock);\n    } else {\n      // some other status code that's not 200... need to re-play the HTTP header\n      // \"data\" events onto the socket once the HTTP machinery is attached so that\n      // the user can parse and handle the error status code\n      cleanup();\n\n      // save a reference to the concat'd Buffer for the `onsocket` callback\n      buffers = buffered;\n\n      // need to wait for the \"socket\" event to re-play the \"data\" events\n      req.once('socket', onsocket);\n      fn(null, socket);\n    }\n  }\n\n  function onsocket (socket) {\n    // replay the \"buffers\" Buffer onto the `socket`, since at this point\n    // the HTTP module machinery has been hooked up for the user\n    if ('function' == typeof socket.ondata) {\n      // node <= v0.11.3, the `ondata` function is set on the socket\n      socket.ondata(buffers, 0, buffers.length);\n    } else if (socket.listeners('data').length > 0) {\n      // node > v0.11.3, the \"data\" event is listened for directly\n      socket.emit('data', buffers);\n    } else {\n      // never?\n      throw new Error('should not happen...');\n    }\n\n    // nullify the cached Buffer instance\n    buffers = null;\n  }\n\n  socket.on('error', onerror);\n  socket.on('close', onclose);\n  socket.on('end', onend);\n\n  if (socket.read) {\n    read();\n  } else {\n    socket.once('data', ondata);\n  }\n\n  var hostname = opts.host + ':' + opts.port;\n  var msg = 'CONNECT ' + hostname + ' HTTP/1.1\\r\\n';\n  var auth = proxy.auth;\n  if (auth) {\n    msg += 'Proxy-Authorization: Basic ' + new Buffer(auth).toString('base64') + '\\r\\n';\n  }\n  msg += 'Host: ' + hostname + '\\r\\n' +\n         'Connection: close\\r\\n' +\n         '\\r\\n';\n  socket.write(msg);\n};\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/https-proxy-agent/node_modules/extend/index.js":"'use strict';\n\nvar hasOwn = Object.prototype.hasOwnProperty;\nvar toStr = Object.prototype.toString;\n\nvar isArray = function isArray(arr) {\n\tif (typeof Array.isArray === 'function') {\n\t\treturn Array.isArray(arr);\n\t}\n\n\treturn toStr.call(arr) === '[object Array]';\n};\n\nvar isPlainObject = function isPlainObject(obj) {\n\tif (!obj || toStr.call(obj) !== '[object Object]') {\n\t\treturn false;\n\t}\n\n\tvar hasOwnConstructor = hasOwn.call(obj, 'constructor');\n\tvar hasIsPrototypeOf = obj.constructor && obj.constructor.prototype && hasOwn.call(obj.constructor.prototype, 'isPrototypeOf');\n\t// Not own constructor property must be Object\n\tif (obj.constructor && !hasOwnConstructor && !hasIsPrototypeOf) {\n\t\treturn false;\n\t}\n\n\t// Own properties are enumerated firstly, so to speed up,\n\t// if last one is own, then all properties are own.\n\tvar key;\n\tfor (key in obj) {/**/}\n\n\treturn typeof key === 'undefined' || hasOwn.call(obj, key);\n};\n\nmodule.exports = function extend() {\n\tvar options, name, src, copy, copyIsArray, clone,\n\t\ttarget = arguments[0],\n\t\ti = 1,\n\t\tlength = arguments.length,\n\t\tdeep = false;\n\n\t// Handle a deep copy situation\n\tif (typeof target === 'boolean') {\n\t\tdeep = target;\n\t\ttarget = arguments[1] || {};\n\t\t// skip the boolean and the target\n\t\ti = 2;\n\t} else if ((typeof target !== 'object' && typeof target !== 'function') || target == null) {\n\t\ttarget = {};\n\t}\n\n\tfor (; i < length; ++i) {\n\t\toptions = arguments[i];\n\t\t// Only deal with non-null/undefined values\n\t\tif (options != null) {\n\t\t\t// Extend the base object\n\t\t\tfor (name in options) {\n\t\t\t\tsrc = target[name];\n\t\t\t\tcopy = options[name];\n\n\t\t\t\t// Prevent never-ending loop\n\t\t\t\tif (target !== copy) {\n\t\t\t\t\t// Recurse if we're merging plain objects or arrays\n\t\t\t\t\tif (deep && copy && (isPlainObject(copy) || (copyIsArray = isArray(copy)))) {\n\t\t\t\t\t\tif (copyIsArray) {\n\t\t\t\t\t\t\tcopyIsArray = false;\n\t\t\t\t\t\t\tclone = src && isArray(src) ? src : [];\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tclone = src && isPlainObject(src) ? src : {};\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Never move original objects, clone them\n\t\t\t\t\t\ttarget[name] = extend(deep, clone, copy);\n\n\t\t\t\t\t// Don't bring in undefined values\n\t\t\t\t\t} else if (typeof copy !== 'undefined') {\n\t\t\t\t\t\ttarget[name] = copy;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Return the modified object\n\treturn target;\n};\n\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/https-proxy-agent/node_modules/agent-base/agent.js":"\n/**\n * Module dependencies.\n */\n\nvar inherits = require('util').inherits;\nvar EventEmitter = require('events').EventEmitter;\n\n/**\n * Module exports.\n */\n\nmodule.exports = Agent;\n\n/**\n *\n * @api public\n */\n\nfunction Agent (callback) {\n  if (!(this instanceof Agent)) return new Agent(callback);\n  if ('function' != typeof callback) throw new Error('Must pass a \"callback function\"');\n  EventEmitter.call(this);\n  this.callback = callback;\n}\ninherits(Agent, EventEmitter);\n\n/**\n * Called by node-core's \"_http_client.js\" module when creating\n * a new HTTP request with this Agent instance.\n *\n * @api public\n */\n\nAgent.prototype.addRequest = function (req, host, port, localAddress) {\n  var opts;\n  if ('object' == typeof host) {\n    // >= v0.11.x API\n    opts = host;\n    if (opts.host && opts.path) {\n      // if both a `host` and `path` are specified then it's most likely the\n      // result of a `url.parse()` call... we need to remove the `path` portion so\n      // that `net.connect()` doesn't attempt to open that as a unix socket file.\n      delete opts.path;\n    }\n  } else {\n    // <= v0.10.x API\n    opts = { host: host, port: port };\n    if (null != localAddress) {\n      opts.localAddress = localAddress;\n    }\n  }\n\n  // hint to use \"Connection: close\"\n  // XXX: non-documented `http` module API :(\n  req._last = true;\n  req.shouldKeepAlive = false;\n\n  // create the `net.Socket` instance\n  var sync = true;\n  this.callback(req, opts, function (err, socket) {\n    function emitErr () {\n      req.emit('error', err);\n      // For Safety. Some additional errors might fire later on\n      // and we need to make sure we don't double-fire the error event.\n      req._hadError = true;\n    }\n    if (err) {\n      if (sync) {\n        // need to defer the \"error\" event, when sync, because by now the `req`\n        // instance hasn't event been passed back to the user yet...\n        process.nextTick(emitErr);\n      } else {\n        emitErr();\n      }\n    } else {\n      req.onSocket(socket);\n    }\n  });\n  sync = false;\n};\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/https-proxy-agent/node_modules/debug/src/index.js":"/**\n * Detect Electron renderer process, which is node, but we should\n * treat as a browser.\n */\n\nif (typeof process !== 'undefined' && process.type === 'renderer') {\n  module.exports = require('./browser.js');\n} else {\n  module.exports = require('./node.js');\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/https-proxy-agent/node_modules/debug/src/node.js":"/**\n * Module dependencies.\n */\n\nvar tty = require('tty');\nvar util = require('util');\n\n/**\n * This is the Node.js implementation of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = require('./debug');\nexports.init = init;\nexports.log = log;\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\n\n/**\n * Colors.\n */\n\nexports.colors = [6, 2, 3, 4, 5, 1];\n\n/**\n * Build up the default `inspectOpts` object from the environment variables.\n *\n *   $ DEBUG_COLORS=no DEBUG_DEPTH=10 DEBUG_SHOW_HIDDEN=enabled node script.js\n */\n\nexports.inspectOpts = Object.keys(process.env).filter(function (key) {\n  return /^debug_/i.test(key);\n}).reduce(function (obj, key) {\n  // camel-case\n  var prop = key\n    .substring(6)\n    .toLowerCase()\n    .replace(/_([a-z])/, function (_, k) { return k.toUpperCase() });\n\n  // coerce string value into JS value\n  var val = process.env[key];\n  if (/^(yes|on|true|enabled)$/i.test(val)) val = true;\n  else if (/^(no|off|false|disabled)$/i.test(val)) val = false;\n  else if (val === 'null') val = null;\n  else val = Number(val);\n\n  obj[prop] = val;\n  return obj;\n}, {});\n\n/**\n * The file descriptor to write the `debug()` calls to.\n * Set the `DEBUG_FD` env variable to override with another value. i.e.:\n *\n *   $ DEBUG_FD=3 node script.js 3>debug.log\n */\n\nvar fd = parseInt(process.env.DEBUG_FD, 10) || 2;\n\nif (1 !== fd && 2 !== fd) {\n  util.deprecate(function(){}, 'except for stderr(2) and stdout(1), any other usage of DEBUG_FD is deprecated. Override debug.log if you want to use a different log function (https://git.io/debug_fd)')()\n}\n\nvar stream = 1 === fd ? process.stdout :\n             2 === fd ? process.stderr :\n             createWritableStdioStream(fd);\n\n/**\n * Is stdout a TTY? Colored output is enabled when `true`.\n */\n\nfunction useColors() {\n  return 'colors' in exports.inspectOpts\n    ? Boolean(exports.inspectOpts.colors)\n    : tty.isatty(fd);\n}\n\n/**\n * Map %o to `util.inspect()`, all on a single line.\n */\n\nexports.formatters.o = function(v) {\n  this.inspectOpts.colors = this.useColors;\n  return util.inspect(v, this.inspectOpts)\n    .replace(/\\s*\\n\\s*/g, ' ');\n};\n\n/**\n * Map %o to `util.inspect()`, allowing multiple lines if needed.\n */\n\nexports.formatters.O = function(v) {\n  this.inspectOpts.colors = this.useColors;\n  return util.inspect(v, this.inspectOpts);\n};\n\n/**\n * Adds ANSI color escape codes if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n  var name = this.namespace;\n  var useColors = this.useColors;\n\n  if (useColors) {\n    var c = this.color;\n    var prefix = '  \\u001b[3' + c + ';1m' + name + ' ' + '\\u001b[0m';\n\n    args[0] = prefix + args[0].split('\\n').join('\\n' + prefix);\n    args.push('\\u001b[3' + c + 'm+' + exports.humanize(this.diff) + '\\u001b[0m');\n  } else {\n    args[0] = new Date().toUTCString()\n      + ' ' + name + ' ' + args[0];\n  }\n}\n\n/**\n * Invokes `util.format()` with the specified arguments and writes to `stream`.\n */\n\nfunction log() {\n  return stream.write(util.format.apply(util, arguments) + '\\n');\n}\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\n\nfunction save(namespaces) {\n  if (null == namespaces) {\n    // If you set a process.env field to null or undefined, it gets cast to the\n    // string 'null' or 'undefined'. Just delete instead.\n    delete process.env.DEBUG;\n  } else {\n    process.env.DEBUG = namespaces;\n  }\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\n\nfunction load() {\n  return process.env.DEBUG;\n}\n\n/**\n * Copied from `node/src/node.js`.\n *\n * XXX: It's lame that node doesn't expose this API out-of-the-box. It also\n * relies on the undocumented `tty_wrap.guessHandleType()` which is also lame.\n */\n\nfunction createWritableStdioStream (fd) {\n  var stream;\n  var tty_wrap = process.binding('tty_wrap');\n\n  // Note stream._type is used for test-module-load-list.js\n\n  switch (tty_wrap.guessHandleType(fd)) {\n    case 'TTY':\n      stream = new tty.WriteStream(fd);\n      stream._type = 'tty';\n\n      // Hack to have stream not keep the event loop alive.\n      // See https://github.com/joyent/node/issues/1726\n      if (stream._handle && stream._handle.unref) {\n        stream._handle.unref();\n      }\n      break;\n\n    case 'FILE':\n      var fs = require('fs');\n      stream = new fs.SyncWriteStream(fd, { autoClose: false });\n      stream._type = 'fs';\n      break;\n\n    case 'PIPE':\n    case 'TCP':\n      var net = require('net');\n      stream = new net.Socket({\n        fd: fd,\n        readable: false,\n        writable: true\n      });\n\n      // FIXME Should probably have an option in net.Socket to create a\n      // stream from an existing fd which is writable only. But for now\n      // we'll just add this hack and set the `readable` member to false.\n      // Test: ./node test/fixtures/echo.js < /etc/passwd\n      stream.readable = false;\n      stream.read = null;\n      stream._type = 'pipe';\n\n      // FIXME Hack to have stream not keep the event loop alive.\n      // See https://github.com/joyent/node/issues/1726\n      if (stream._handle && stream._handle.unref) {\n        stream._handle.unref();\n      }\n      break;\n\n    default:\n      // Probably an error on in uv_guess_handle()\n      throw new Error('Implement me. Unknown stream file type!');\n  }\n\n  // For supporting legacy API we put the FD here.\n  stream.fd = fd;\n\n  stream._isStdio = true;\n\n  return stream;\n}\n\n/**\n * Init logic for `debug` instances.\n *\n * Create a new `inspectOpts` object in case `useColors` is set\n * differently for a particular `debug` instance.\n */\n\nfunction init (debug) {\n  debug.inspectOpts = util._extend({}, exports.inspectOpts);\n}\n\n/**\n * Enable namespaces listed in `process.env.DEBUG` initially.\n */\n\nexports.enable(load());\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/https-proxy-agent/node_modules/debug/src/debug.js":"\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = createDebug.debug = createDebug['default'] = createDebug;\nexports.coerce = coerce;\nexports.disable = disable;\nexports.enable = enable;\nexports.enabled = enabled;\nexports.humanize = require('ms');\n\n/**\n * The currently active debug mode names, and names to skip.\n */\n\nexports.names = [];\nexports.skips = [];\n\n/**\n * Map of special \"%n\" handling functions, for the debug \"format\" argument.\n *\n * Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n */\n\nexports.formatters = {};\n\n/**\n * Previous log timestamp.\n */\n\nvar prevTime;\n\n/**\n * Select a color.\n * @param {String} namespace\n * @return {Number}\n * @api private\n */\n\nfunction selectColor(namespace) {\n  var hash = 0, i;\n\n  for (i in namespace) {\n    hash  = ((hash << 5) - hash) + namespace.charCodeAt(i);\n    hash |= 0; // Convert to 32bit integer\n  }\n\n  return exports.colors[Math.abs(hash) % exports.colors.length];\n}\n\n/**\n * Create a debugger with the given `namespace`.\n *\n * @param {String} namespace\n * @return {Function}\n * @api public\n */\n\nfunction createDebug(namespace) {\n\n  function debug() {\n    // disabled?\n    if (!debug.enabled) return;\n\n    var self = debug;\n\n    // set `diff` timestamp\n    var curr = +new Date();\n    var ms = curr - (prevTime || curr);\n    self.diff = ms;\n    self.prev = prevTime;\n    self.curr = curr;\n    prevTime = curr;\n\n    // turn the `arguments` into a proper Array\n    var args = new Array(arguments.length);\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i];\n    }\n\n    args[0] = exports.coerce(args[0]);\n\n    if ('string' !== typeof args[0]) {\n      // anything else let's inspect with %O\n      args.unshift('%O');\n    }\n\n    // apply any `formatters` transformations\n    var index = 0;\n    args[0] = args[0].replace(/%([a-zA-Z%])/g, function(match, format) {\n      // if we encounter an escaped % then don't increase the array index\n      if (match === '%%') return match;\n      index++;\n      var formatter = exports.formatters[format];\n      if ('function' === typeof formatter) {\n        var val = args[index];\n        match = formatter.call(self, val);\n\n        // now we need to remove `args[index]` since it's inlined in the `format`\n        args.splice(index, 1);\n        index--;\n      }\n      return match;\n    });\n\n    // apply env-specific formatting (colors, etc.)\n    exports.formatArgs.call(self, args);\n\n    var logFn = debug.log || exports.log || console.log.bind(console);\n    logFn.apply(self, args);\n  }\n\n  debug.namespace = namespace;\n  debug.enabled = exports.enabled(namespace);\n  debug.useColors = exports.useColors();\n  debug.color = selectColor(namespace);\n\n  // env-specific initialization logic for debug instances\n  if ('function' === typeof exports.init) {\n    exports.init(debug);\n  }\n\n  return debug;\n}\n\n/**\n * Enables a debug mode by namespaces. This can include modes\n * separated by a colon and wildcards.\n *\n * @param {String} namespaces\n * @api public\n */\n\nfunction enable(namespaces) {\n  exports.save(namespaces);\n\n  exports.names = [];\n  exports.skips = [];\n\n  var split = (namespaces || '').split(/[\\s,]+/);\n  var len = split.length;\n\n  for (var i = 0; i < len; i++) {\n    if (!split[i]) continue; // ignore empty strings\n    namespaces = split[i].replace(/\\*/g, '.*?');\n    if (namespaces[0] === '-') {\n      exports.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));\n    } else {\n      exports.names.push(new RegExp('^' + namespaces + '$'));\n    }\n  }\n}\n\n/**\n * Disable debug output.\n *\n * @api public\n */\n\nfunction disable() {\n  exports.enable('');\n}\n\n/**\n * Returns true if the given mode name is enabled, false otherwise.\n *\n * @param {String} name\n * @return {Boolean}\n * @api public\n */\n\nfunction enabled(name) {\n  var i, len;\n  for (i = 0, len = exports.skips.length; i < len; i++) {\n    if (exports.skips[i].test(name)) {\n      return false;\n    }\n  }\n  for (i = 0, len = exports.names.length; i < len; i++) {\n    if (exports.names[i].test(name)) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Coerce `val`.\n *\n * @param {Mixed} val\n * @return {Mixed}\n * @api private\n */\n\nfunction coerce(val) {\n  if (val instanceof Error) return val.stack || val.message;\n  return val;\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/node_modules/https-proxy-agent/node_modules/debug/node_modules/ms/index.js":"/**\n * Helpers.\n */\n\nvar s = 1000\nvar m = s * 60\nvar h = m * 60\nvar d = h * 24\nvar y = d * 365.25\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} options\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function (val, options) {\n  options = options || {}\n  var type = typeof val\n  if (type === 'string' && val.length > 0) {\n    return parse(val)\n  } else if (type === 'number' && isNaN(val) === false) {\n    return options.long ?\n\t\t\tfmtLong(val) :\n\t\t\tfmtShort(val)\n  }\n  throw new Error('val is not a non-empty string or a valid number. val=' + JSON.stringify(val))\n}\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str)\n  if (str.length > 10000) {\n    return\n  }\n  var match = /^((?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|years?|yrs?|y)?$/i.exec(str)\n  if (!match) {\n    return\n  }\n  var n = parseFloat(match[1])\n  var type = (match[2] || 'ms').toLowerCase()\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n\n    default:\n      return undefined\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  if (ms >= d) {\n    return Math.round(ms / d) + 'd'\n  }\n  if (ms >= h) {\n    return Math.round(ms / h) + 'h'\n  }\n  if (ms >= m) {\n    return Math.round(ms / m) + 'm'\n  }\n  if (ms >= s) {\n    return Math.round(ms / s) + 's'\n  }\n  return ms + 'ms'\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  return plural(ms, d, 'day') ||\n    plural(ms, h, 'hour') ||\n    plural(ms, m, 'minute') ||\n    plural(ms, s, 'second') ||\n    ms + ' ms'\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, n, name) {\n  if (ms < n) {\n    return\n  }\n  if (ms < n * 1.5) {\n    return Math.floor(ms / n) + ' ' + name\n  }\n  return Math.ceil(ms / n) + ' ' + name + 's'\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/collector/ssl/certificates.js":"'use strict'\n\n/**\n * certificates.js - CA bundle for SSL communication with RPM.\n *\n * This file contains the X509 certificates used to communicate with New Relic\n * over SSL.\n */\n\nmodule.exports = [\n  // AddTrustExternalCARoot\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIENjCCAx6gAwIBAgIBATANBgkqhkiG9w0BAQUFADBvMQswCQYDVQQGEwJTRTEU\\n\" +\n  \"MBIGA1UEChMLQWRkVHJ1c3QgQUIxJjAkBgNVBAsTHUFkZFRydXN0IEV4dGVybmFs\\n\" +\n  \"IFRUUCBOZXR3b3JrMSIwIAYDVQQDExlBZGRUcnVzdCBFeHRlcm5hbCBDQSBSb290\\n\" +\n  \"MB4XDTAwMDUzMDEwNDgzOFoXDTIwMDUzMDEwNDgzOFowbzELMAkGA1UEBhMCU0Ux\\n\" +\n  \"FDASBgNVBAoTC0FkZFRydXN0IEFCMSYwJAYDVQQLEx1BZGRUcnVzdCBFeHRlcm5h\\n\" +\n  \"bCBUVFAgTmV0d29yazEiMCAGA1UEAxMZQWRkVHJ1c3QgRXh0ZXJuYWwgQ0EgUm9v\\n\" +\n  \"dDCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBALf3GjPm8gAELTngTlvt\\n\" +\n  \"H7xsD821+iO2zt6bETOXpClMfZOfvUq8k+0DGuOPz+VtUFrWlymUWoCwSXrbLpX9\\n\" +\n  \"uMq/NzgtHj6RQa1wVsfwTz/oMp50ysiQVOnGXw94nZpAPA6sYapeFI+eh6FqUNzX\\n\" +\n  \"mk6vBbOmcZSccbNQYArHE504B4YCqOmoaSYYkKtMsE8jqzpPhNjfzp/haW+710LX\\n\" +\n  \"a0Tkx63ubUFfclpxCDezeWWkWaCUN/cALw3CknLa0Dhy2xSoRcRdKn23tNbE7qzN\\n\" +\n  \"E0S3ySvdQwAl+mG5aWpYIxG3pzOPVnVZ9c0p10a3CitlttNCbxWyuHv77+ldU9U0\\n\" +\n  \"WicCAwEAAaOB3DCB2TAdBgNVHQ4EFgQUrb2YejS0Jvf6xCZU7wO94CTLVBowCwYD\\n\" +\n  \"VR0PBAQDAgEGMA8GA1UdEwEB/wQFMAMBAf8wgZkGA1UdIwSBkTCBjoAUrb2YejS0\\n\" +\n  \"Jvf6xCZU7wO94CTLVBqhc6RxMG8xCzAJBgNVBAYTAlNFMRQwEgYDVQQKEwtBZGRU\\n\" +\n  \"cnVzdCBBQjEmMCQGA1UECxMdQWRkVHJ1c3QgRXh0ZXJuYWwgVFRQIE5ldHdvcmsx\\n\" +\n  \"IjAgBgNVBAMTGUFkZFRydXN0IEV4dGVybmFsIENBIFJvb3SCAQEwDQYJKoZIhvcN\\n\" +\n  \"AQEFBQADggEBALCb4IUlwtYj4g+WBpKdQZic2YR5gdkeWxQHIzZlj7DYd7usQWxH\\n\" +\n  \"YINRsPkyPef89iYTx4AWpb9a/IfPeHmJIZriTAcKhjW88t5RxNKWt9x+Tu5w/Rw5\\n\" +\n  \"6wwCURQtjr0W4MHfRnXnJK3s9EK0hZNwEGe6nQY1ShjTK3rMUUKhemPR5ruhxSvC\\n\" +\n  \"Nr4TDea9Y355e6cJDUCrat2PisP29owaQgVR1EX1n6diIWgVIEM8med8vSTYqZEX\\n\" +\n  \"c4g/VhsxOBi0cQ+azcgOno4uG+GMmIPLHzHxREzGBHNJdmAPx/i9F4BrLunMTA5a\\n\" +\n  \"mnkPIAou1Z5jJh5VkpTYghdae9C8x49OhgQ=\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // DigiCertAssuredIDRootCA\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDtzCCAp+gAwIBAgIQDOfg5RfYRv6P5WD8G/AwOTANBgkqhkiG9w0BAQUFADBl\\n\" +\n  \"MQswCQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3\\n\" +\n  \"d3cuZGlnaWNlcnQuY29tMSQwIgYDVQQDExtEaWdpQ2VydCBBc3N1cmVkIElEIFJv\\n\" +\n  \"b3QgQ0EwHhcNMDYxMTEwMDAwMDAwWhcNMzExMTEwMDAwMDAwWjBlMQswCQYDVQQG\\n\" +\n  \"EwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3d3cuZGlnaWNl\\n\" +\n  \"cnQuY29tMSQwIgYDVQQDExtEaWdpQ2VydCBBc3N1cmVkIElEIFJvb3QgQ0EwggEi\\n\" +\n  \"MA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCtDhXO5EOAXLGH87dg+XESpa7c\\n\" +\n  \"JpSIqvTO9SA5KFhgDPiA2qkVlTJhPLWxKISKityfCgyDF3qPkKyK53lTXDGEKvYP\\n\" +\n  \"mDI2dsze3Tyoou9q+yHyUmHfnyDXH+Kx2f4YZNISW1/5WBg1vEfNoTb5a3/UsDg+\\n\" +\n  \"wRvDjDPZ2C8Y/igPs6eD1sNuRMBhNZYW/lmci3Zt1/GiSw0r/wty2p5g0I6QNcZ4\\n\" +\n  \"VYcgoc/lbQrISXwxmDNsIumH0DJaoroTghHtORedmTpyoeb6pNnVFzF1roV9Iq4/\\n\" +\n  \"AUaG9ih5yLHa5FcXxH4cDrC0kqZWs72yl+2qp/C3xag/lRbQ/6GW6whfGHdPAgMB\\n\" +\n  \"AAGjYzBhMA4GA1UdDwEB/wQEAwIBhjAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQW\\n\" +\n  \"BBRF66Kv9JLLgjEtUYunpyGd823IDzAfBgNVHSMEGDAWgBRF66Kv9JLLgjEtUYun\\n\" +\n  \"pyGd823IDzANBgkqhkiG9w0BAQUFAAOCAQEAog683+Lt8ONyc3pklL/3cmbYMuRC\\n\" +\n  \"dWKuh+vy1dneVrOfzM4UKLkNl2BcEkxY5NM9g0lFWJc1aRqoR+pWxnmrEthngYTf\\n\" +\n  \"fwk8lOa4JiwgvT2zKIn3X/8i4peEH+ll74fg38FnSbNd67IJKusm7Xi+fT8r87cm\\n\" +\n  \"NW1fiQG2SVufAQWbqz0lwcy2f8Lxb4bG+mRo64EtlOtCt/qMHt1i8b5QZ7dsvfPx\\n\" +\n  \"H2sMNgcWfzd8qVttevESRmCD1ycEvkvOl77DZypoEd+A5wwzZr8TDRRu838fYxAe\\n\" +\n  \"+o0bJW1sj6W3YQGx0qMmoRBxna3iw/nDmVG3KwcIzi7mULKn+gpFL6Lw8g==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // DigiCertAssuredIDRootG2\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDljCCAn6gAwIBAgIQC5McOtY5Z+pnI7/Dr5r0SzANBgkqhkiG9w0BAQsFADBl\\n\" +\n  \"MQswCQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3\\n\" +\n  \"d3cuZGlnaWNlcnQuY29tMSQwIgYDVQQDExtEaWdpQ2VydCBBc3N1cmVkIElEIFJv\\n\" +\n  \"b3QgRzIwHhcNMTMwODAxMTIwMDAwWhcNMzgwMTE1MTIwMDAwWjBlMQswCQYDVQQG\\n\" +\n  \"EwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3d3cuZGlnaWNl\\n\" +\n  \"cnQuY29tMSQwIgYDVQQDExtEaWdpQ2VydCBBc3N1cmVkIElEIFJvb3QgRzIwggEi\\n\" +\n  \"MA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDZ5ygvUj82ckmIkzTz+GoeMVSA\\n\" +\n  \"n61UQbVH35ao1K+ALbkKz3X9iaV9JPrjIgwrvJUXCzO/GU1BBpAAvQxNEP4Htecc\\n\" +\n  \"biJVMWWXvdMX0h5i89vqbFCMP4QMls+3ywPgym2hFEwbid3tALBSfK+RbLE4E9Hp\\n\" +\n  \"EgjAALAcKxHad3A2m67OeYfcgnDmCXRwVWmvo2ifv922ebPynXApVfSr/5Vh88lA\\n\" +\n  \"bx3RvpO704gqu52/clpWcTs/1PPRCv4o76Pu2ZmvA9OPYLfykqGxvYmJHzDNw6Yu\\n\" +\n  \"YjOuFgJ3RFrngQo8p0Quebg/BLxcoIfhG69Rjs3sLPr4/m3wOnyqi+RnlTGNAgMB\\n\" +\n  \"AAGjQjBAMA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgGGMB0GA1UdDgQW\\n\" +\n  \"BBTOw0q5mVXyuNtgv6l+vVa1lzan1jANBgkqhkiG9w0BAQsFAAOCAQEAyqVVjOPI\\n\" +\n  \"QW5pJ6d1Ee88hjZv0p3GeDgdaZaikmkuOGybfQTUiaWxMTeKySHMq2zNixya1r9I\\n\" +\n  \"0jJmwYrA8y8678Dj1JGG0VDjA9tzd29KOVPt3ibHtX2vK0LRdWLjSisCx1BL4Gni\\n\" +\n  \"lmwORGYQRI+tBev4eaymG+g3NJ1TyWGqolKvSnAWhsI6yLETcDbYz+70CjTVW0z9\\n\" +\n  \"B5yiutkBclzzTcHdDrEcDcRjvq30FPuJ7KJBDkzMyFdA0G4Dqs0MjomZmWzwPDCv\\n\" +\n  \"ON9vvKO+KSAnq3T/EyJ43pdSVR6DtVQgA+6uwE9W3jfMw3+qBCe703e4YtsXfJwo\\n\" +\n  \"IhNzbM8m9Yop5w==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // DigiCertAssuredIDRootG3\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIICRjCCAc2gAwIBAgIQC6Fa+h3foLVJRK/NJKBs7DAKBggqhkjOPQQDAzBlMQsw\\n\" +\n  \"CQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3d3cu\\n\" +\n  \"ZGlnaWNlcnQuY29tMSQwIgYDVQQDExtEaWdpQ2VydCBBc3N1cmVkIElEIFJvb3Qg\\n\" +\n  \"RzMwHhcNMTMwODAxMTIwMDAwWhcNMzgwMTE1MTIwMDAwWjBlMQswCQYDVQQGEwJV\\n\" +\n  \"UzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3d3cuZGlnaWNlcnQu\\n\" +\n  \"Y29tMSQwIgYDVQQDExtEaWdpQ2VydCBBc3N1cmVkIElEIFJvb3QgRzMwdjAQBgcq\\n\" +\n  \"hkjOPQIBBgUrgQQAIgNiAAQZ57ysRGXtzbg/WPuNsVepRC0FFfLvC/8QdJ+1YlJf\\n\" +\n  \"Zn4f5dwbRXkLzMZTCp2NXQLZqVneAlr2lSoOjThKiknGvMYDOAdfVdp+CW7if17Q\\n\" +\n  \"RSAPWXYQ1qAk8C3eNvJsKTmjQjBAMA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/\\n\" +\n  \"BAQDAgGGMB0GA1UdDgQWBBTL0L2p4ZgFUaFNN6KDec6NHSrkhDAKBggqhkjOPQQD\\n\" +\n  \"AwNnADBkAjAlpIFFAmsSS3V0T8gj43DydXLefInwz5FyYZ5eEJJZVrmDxxDnOOlY\\n\" +\n  \"JjZ91eQ0hjkCMHw2U/Aw5WJjOpnitqM7mzT6HtoQknFekROn3aRukswy1vUhZscv\\n\" +\n  \"6pZjamVFkpUBtA==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // DigiCertGlobalRootCA\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDrzCCApegAwIBAgIQCDvgVpBCRrGhdWrJWZHHSjANBgkqhkiG9w0BAQUFADBh\\n\" +\n  \"MQswCQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3\\n\" +\n  \"d3cuZGlnaWNlcnQuY29tMSAwHgYDVQQDExdEaWdpQ2VydCBHbG9iYWwgUm9vdCBD\\n\" +\n  \"QTAeFw0wNjExMTAwMDAwMDBaFw0zMTExMTAwMDAwMDBaMGExCzAJBgNVBAYTAlVT\\n\" +\n  \"MRUwEwYDVQQKEwxEaWdpQ2VydCBJbmMxGTAXBgNVBAsTEHd3dy5kaWdpY2VydC5j\\n\" +\n  \"b20xIDAeBgNVBAMTF0RpZ2lDZXJ0IEdsb2JhbCBSb290IENBMIIBIjANBgkqhkiG\\n\" +\n  \"9w0BAQEFAAOCAQ8AMIIBCgKCAQEA4jvhEXLeqKTTo1eqUKKPC3eQyaKl7hLOllsB\\n\" +\n  \"CSDMAZOnTjC3U/dDxGkAV53ijSLdhwZAAIEJzs4bg7/fzTtxRuLWZscFs3YnFo97\\n\" +\n  \"nh6Vfe63SKMI2tavegw5BmV/Sl0fvBf4q77uKNd0f3p4mVmFaG5cIzJLv07A6Fpt\\n\" +\n  \"43C/dxC//AH2hdmoRBBYMql1GNXRor5H4idq9Joz+EkIYIvUX7Q6hL+hqkpMfT7P\\n\" +\n  \"T19sdl6gSzeRntwi5m3OFBqOasv+zbMUZBfHWymeMr/y7vrTC0LUq7dBMtoM1O/4\\n\" +\n  \"gdW7jVg/tRvoSSiicNoxBN33shbyTApOB6jtSj1etX+jkMOvJwIDAQABo2MwYTAO\\n\" +\n  \"BgNVHQ8BAf8EBAMCAYYwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUA95QNVbR\\n\" +\n  \"TLtm8KPiGxvDl7I90VUwHwYDVR0jBBgwFoAUA95QNVbRTLtm8KPiGxvDl7I90VUw\\n\" +\n  \"DQYJKoZIhvcNAQEFBQADggEBAMucN6pIExIK+t1EnE9SsPTfrgT1eXkIoyQY/Esr\\n\" +\n  \"hMAtudXH/vTBH1jLuG2cenTnmCmrEbXjcKChzUyImZOMkXDiqw8cvpOp/2PV5Adg\\n\" +\n  \"06O/nVsJ8dWO41P0jmP6P6fbtGbfYmbW0W5BjfIttep3Sp+dWOIrWcBAI+0tKIJF\\n\" +\n  \"PnlUkiaY4IBIqDfv8NZ5YBberOgOzW6sRBc4L0na4UU+Krk2U886UAb3LujEV0ls\\n\" +\n  \"YSEY1QSteDwsOoBrp+uvFRTp2InBuThs4pFsiv9kuXclVzDAGySj4dzp30d8tbQk\\n\" +\n  \"CAUw7C29C79Fv1C5qfPrmAESrciIxpg0X40KPMbp1ZWVbd4=\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // DigiCertGlobalRootG2\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDjjCCAnagAwIBAgIQAzrx5qcRqaC7KGSxHQn65TANBgkqhkiG9w0BAQsFADBh\\n\" +\n  \"MQswCQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3\\n\" +\n  \"d3cuZGlnaWNlcnQuY29tMSAwHgYDVQQDExdEaWdpQ2VydCBHbG9iYWwgUm9vdCBH\\n\" +\n  \"MjAeFw0xMzA4MDExMjAwMDBaFw0zODAxMTUxMjAwMDBaMGExCzAJBgNVBAYTAlVT\\n\" +\n  \"MRUwEwYDVQQKEwxEaWdpQ2VydCBJbmMxGTAXBgNVBAsTEHd3dy5kaWdpY2VydC5j\\n\" +\n  \"b20xIDAeBgNVBAMTF0RpZ2lDZXJ0IEdsb2JhbCBSb290IEcyMIIBIjANBgkqhkiG\\n\" +\n  \"9w0BAQEFAAOCAQ8AMIIBCgKCAQEAuzfNNNx7a8myaJCtSnX/RrohCgiN9RlUyfuI\\n\" +\n  \"2/Ou8jqJkTx65qsGGmvPrC3oXgkkRLpimn7Wo6h+4FR1IAWsULecYxpsMNzaHxmx\\n\" +\n  \"1x7e/dfgy5SDN67sH0NO3Xss0r0upS/kqbitOtSZpLYl6ZtrAGCSYP9PIUkY92eQ\\n\" +\n  \"q2EGnI/yuum06ZIya7XzV+hdG82MHauVBJVJ8zUtluNJbd134/tJS7SsVQepj5Wz\\n\" +\n  \"tCO7TG1F8PapspUwtP1MVYwnSlcUfIKdzXOS0xZKBgyMUNGPHgm+F6HmIcr9g+UQ\\n\" +\n  \"vIOlCsRnKPZzFBQ9RnbDhxSJITRNrw9FDKZJobq7nMWxM4MphQIDAQABo0IwQDAP\\n\" +\n  \"BgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIBhjAdBgNVHQ4EFgQUTiJUIBiV\\n\" +\n  \"5uNu5g/6+rkS7QYXjzkwDQYJKoZIhvcNAQELBQADggEBAGBnKJRvDkhj6zHd6mcY\\n\" +\n  \"1Yl9PMWLSn/pvtsrF9+wX3N3KjITOYFnQoQj8kVnNeyIv/iPsGEMNKSuIEyExtv4\\n\" +\n  \"NeF22d+mQrvHRAiGfzZ0JFrabA0UWTW98kndth/Jsw1HKj2ZL7tcu7XUIOGZX1NG\\n\" +\n  \"Fdtom/DzMNU+MeKNhJ7jitralj41E6Vf8PlwUHBHQRFXGU7Aj64GxJUTFy8bJZ91\\n\" +\n  \"8rGOmaFvE7FBcf6IKshPECBV1/MUReXgRPTqh5Uykw7+U0b6LJ3/iyK5S9kJRaTe\\n\" +\n  \"pLiaWN0bfVKfjllDiIGknibVb63dDcY3fe0Dkhvld1927jyNxF1WW6LZZm6zNTfl\\n\" +\n  \"MrY=\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // DigiCertGlobalRootG3\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIICPzCCAcWgAwIBAgIQBVVWvPJepDU1w6QP1atFcjAKBggqhkjOPQQDAzBhMQsw\\n\" +\n  \"CQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3d3cu\\n\" +\n  \"ZGlnaWNlcnQuY29tMSAwHgYDVQQDExdEaWdpQ2VydCBHbG9iYWwgUm9vdCBHMzAe\\n\" +\n  \"Fw0xMzA4MDExMjAwMDBaFw0zODAxMTUxMjAwMDBaMGExCzAJBgNVBAYTAlVTMRUw\\n\" +\n  \"EwYDVQQKEwxEaWdpQ2VydCBJbmMxGTAXBgNVBAsTEHd3dy5kaWdpY2VydC5jb20x\\n\" +\n  \"IDAeBgNVBAMTF0RpZ2lDZXJ0IEdsb2JhbCBSb290IEczMHYwEAYHKoZIzj0CAQYF\\n\" +\n  \"K4EEACIDYgAE3afZu4q4C/sLfyHS8L6+c/MzXRq8NOrexpu80JX28MzQC7phW1FG\\n\" +\n  \"fp4tn+6OYwwX7Adw9c+ELkCDnOg/QW07rdOkFFk2eJ0DQ+4QE2xy3q6Ip6FrtUPO\\n\" +\n  \"Z9wj/wMco+I+o0IwQDAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIBhjAd\\n\" +\n  \"BgNVHQ4EFgQUs9tIpPmhxdiuNkHMEWNpYim8S8YwCgYIKoZIzj0EAwMDaAAwZQIx\\n\" +\n  \"AK288mw/EkrRLTnDCgmXc/SINoyIJ7vmiI1Qhadj+Z4y3maTD/HMsQmP3Wyr+mt/\\n\" +\n  \"oAIwOWZbwmSNuJ5Q3KjVSaLtx9zRSX8XAbjIho9OjIgrqJqpisXRAL34VOKa5Vt8\\n\" +\n  \"sycX\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // DigiCertHighAssuranceEVRootCA\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDxTCCAq2gAwIBAgIQAqxcJmoLQJuPC3nyrkYldzANBgkqhkiG9w0BAQUFADBs\\n\" +\n  \"MQswCQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3\\n\" +\n  \"d3cuZGlnaWNlcnQuY29tMSswKQYDVQQDEyJEaWdpQ2VydCBIaWdoIEFzc3VyYW5j\\n\" +\n  \"ZSBFViBSb290IENBMB4XDTA2MTExMDAwMDAwMFoXDTMxMTExMDAwMDAwMFowbDEL\\n\" +\n  \"MAkGA1UEBhMCVVMxFTATBgNVBAoTDERpZ2lDZXJ0IEluYzEZMBcGA1UECxMQd3d3\\n\" +\n  \"LmRpZ2ljZXJ0LmNvbTErMCkGA1UEAxMiRGlnaUNlcnQgSGlnaCBBc3N1cmFuY2Ug\\n\" +\n  \"RVYgUm9vdCBDQTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAMbM5XPm\\n\" +\n  \"+9S75S0tMqbf5YE/yc0lSbZxKsPVlDRnogocsF9ppkCxxLeyj9CYpKlBWTrT3JTW\\n\" +\n  \"PNt0OKRKzE0lgvdKpVMSOO7zSW1xkX5jtqumX8OkhPhPYlG++MXs2ziS4wblCJEM\\n\" +\n  \"xChBVfvLWokVfnHoNb9Ncgk9vjo4UFt3MRuNs8ckRZqnrG0AFFoEt7oT61EKmEFB\\n\" +\n  \"Ik5lYYeBQVCmeVyJ3hlKV9Uu5l0cUyx+mM0aBhakaHPQNAQTXKFx01p8VdteZOE3\\n\" +\n  \"hzBWBOURtCmAEvF5OYiiAhF8J2a3iLd48soKqDirCmTCv2ZdlYTBoSUeh10aUAsg\\n\" +\n  \"EsxBu24LUTi4S8sCAwEAAaNjMGEwDgYDVR0PAQH/BAQDAgGGMA8GA1UdEwEB/wQF\\n\" +\n  \"MAMBAf8wHQYDVR0OBBYEFLE+w2kD+L9HAdSYJhoIAu9jZCvDMB8GA1UdIwQYMBaA\\n\" +\n  \"FLE+w2kD+L9HAdSYJhoIAu9jZCvDMA0GCSqGSIb3DQEBBQUAA4IBAQAcGgaX3Nec\\n\" +\n  \"nzyIZgYIVyHbIUf4KmeqvxgydkAQV8GK83rZEWWONfqe/EW1ntlMMUu4kehDLI6z\\n\" +\n  \"eM7b41N5cdblIZQB2lWHmiRk9opmzN6cN82oNLFpmyPInngiK3BD41VHMWEZ71jF\\n\" +\n  \"hS9OMPagMRYjyOfiZRYzy78aG6A9+MpeizGLYAiJLQwGXFK3xPkKmNEVX58Svnw2\\n\" +\n  \"Yzi9RKR/5CYrCsSXaQ3pjOLAEFe4yHYSkVXySGnYvCoCWw9E1CAx2/S6cCZdkGCe\\n\" +\n  \"vEsXCS+0yx5DaMkHJ8HSXPfqIbloEpw8nL+e/IBcm2PN7EeqJSdnoDfzAIJ9VNep\\n\" +\n  \"+OkuE6N36B9K\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // DigiCertTrustedRootG4\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIFkDCCA3igAwIBAgIQBZsbV56OITLiOQe9p3d1XDANBgkqhkiG9w0BAQwFADBi\\n\" +\n  \"MQswCQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3\\n\" +\n  \"d3cuZGlnaWNlcnQuY29tMSEwHwYDVQQDExhEaWdpQ2VydCBUcnVzdGVkIFJvb3Qg\\n\" +\n  \"RzQwHhcNMTMwODAxMTIwMDAwWhcNMzgwMTE1MTIwMDAwWjBiMQswCQYDVQQGEwJV\\n\" +\n  \"UzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3d3cuZGlnaWNlcnQu\\n\" +\n  \"Y29tMSEwHwYDVQQDExhEaWdpQ2VydCBUcnVzdGVkIFJvb3QgRzQwggIiMA0GCSqG\\n\" +\n  \"SIb3DQEBAQUAA4ICDwAwggIKAoICAQC/5pBzaN675F1KPDAiMGkz7MKnJS7JIT3y\\n\" +\n  \"ithZwuEppz1Yq3aaza57G4QNxDAf8xukOBbrVsaXbR2rsnnyyhHS5F/WBTxSD1If\\n\" +\n  \"xp4VpX6+n6lXFllVcq9ok3DCsrp1mWpzMpTREEQQLt+C8weE5nQ7bXHiLQwb7iDV\\n\" +\n  \"ySAdYyktzuxeTsiT+CFhmzTrBcZe7FsavOvJz82sNEBfsXpm7nfISKhmV1efVFiO\\n\" +\n  \"DCu3T6cw2Vbuyntd463JT17lNecxy9qTXtyOj4DatpGYQJB5w3jHtrHEtWoYOAMQ\\n\" +\n  \"jdjUN6QuBX2I9YI+EJFwq1WCQTLX2wRzKm6RAXwhTNS8rhsDdV14Ztk6MUSaM0C/\\n\" +\n  \"CNdaSaTC5qmgZ92kJ7yhTzm1EVgX9yRcRo9k98FpiHaYdj1ZXUJ2h4mXaXpI8OCi\\n\" +\n  \"EhtmmnTK3kse5w5jrubU75KSOp493ADkRSWJtppEGSt+wJS00mFt6zPZxd9LBADM\\n\" +\n  \"fRyVw4/3IbKyEbe7f/LVjHAsQWCqsWMYRJUadmJ+9oCw++hkpjPRiQfhvbfmQ6QY\\n\" +\n  \"uKZ3AeEPlAwhHbJUKSWJbOUOUlFHdL4mrLZBdd56rF+NP8m800ERElvlEFDrMcXK\\n\" +\n  \"chYiCd98THU/Y+whX8QgUWtvsauGi0/C1kVfnSD8oR7FwI+isX4KJpn15GkvmB0t\\n\" +\n  \"9dmpsh3lGwIDAQABo0IwQDAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB\\n\" +\n  \"hjAdBgNVHQ4EFgQU7NfjgtJxXWRM3y5nP+e6mK4cD08wDQYJKoZIhvcNAQEMBQAD\\n\" +\n  \"ggIBALth2X2pbL4XxJEbw6GiAI3jZGgPVs93rnD5/ZpKmbnJeFwMDF/k5hQpVgs2\\n\" +\n  \"SV1EY+CtnJYYZhsjDT156W1r1lT40jzBQ0CuHVD1UvyQO7uYmWlrx8GnqGikJ9yd\\n\" +\n  \"+SeuMIW59mdNOj6PWTkiU0TryF0Dyu1Qen1iIQqAyHNm0aAFYF/opbSnr6j3bTWc\\n\" +\n  \"fFqK1qI4mfN4i/RN0iAL3gTujJtHgXINwBQy7zBZLq7gcfJW5GqXb5JQbZaNaHqa\\n\" +\n  \"sjYUegbyJLkJEVDXCLG4iXqEI2FCKeWjzaIgQdfRnGTZ6iahixTXTBmyUEFxPT9N\\n\" +\n  \"cCOGDErcgdLMMpSEDQgJlxxPwO5rIHQw0uA5NBCFIRUBCOhVMt5xSdkoF1BN5r5N\\n\" +\n  \"0XWs0Mr7QbhDparTwwVETyw2m+L64kW4I1NsBm9nVX9GtUw/bihaeSbSpKhil9Ie\\n\" +\n  \"4u1Ki7wb/UdKDd9nZn6yW0HQO+T0O/QEY+nvwlQAUaCKKsnOeMzV6ocEGLPOr0mI\\n\" +\n  \"r/OSmbaz5mEP0oUA51Aa5BuVnRmhuZyxm7EAHu/QD09CbMkKvO5D+jpxpchNJqU1\\n\" +\n  \"/YldvIViHTLSoCtU7ZpXwdv6EM8Zt4tKG48BtieVU+i2iW1bvGjUI+iLUaJW+fCm\\n\" +\n  \"gKDWHrO8Dw9TdSmq6hN35N6MgSGtBxBHEa2HPQfRdbzP82Z+\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // Equifax_Secure_Certificate_Authority\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDIDCCAomgAwIBAgIENd70zzANBgkqhkiG9w0BAQUFADBOMQswCQYDVQQGEwJV\\n\" +\n  \"UzEQMA4GA1UEChMHRXF1aWZheDEtMCsGA1UECxMkRXF1aWZheCBTZWN1cmUgQ2Vy\\n\" +\n  \"dGlmaWNhdGUgQXV0aG9yaXR5MB4XDTk4MDgyMjE2NDE1MVoXDTE4MDgyMjE2NDE1\\n\" +\n  \"MVowTjELMAkGA1UEBhMCVVMxEDAOBgNVBAoTB0VxdWlmYXgxLTArBgNVBAsTJEVx\\n\" +\n  \"dWlmYXggU2VjdXJlIENlcnRpZmljYXRlIEF1dGhvcml0eTCBnzANBgkqhkiG9w0B\\n\" +\n  \"AQEFAAOBjQAwgYkCgYEAwV2xWGcIYu6gmi0fCG2RFGiYCh7+2gRvE4RiIcPRfM6f\\n\" +\n  \"BeC4AfBONOziipUEZKzxa1NfBbPLZ4C/QgKO/t0BCezhABRP/PvwDN1Dulsr4R+A\\n\" +\n  \"cJkVV5MW8Q+XarfCaCMczE1ZMKxRHjuvK9buY0V7xdlfUNLjUA86iOe/FP3gx7kC\\n\" +\n  \"AwEAAaOCAQkwggEFMHAGA1UdHwRpMGcwZaBjoGGkXzBdMQswCQYDVQQGEwJVUzEQ\\n\" +\n  \"MA4GA1UEChMHRXF1aWZheDEtMCsGA1UECxMkRXF1aWZheCBTZWN1cmUgQ2VydGlm\\n\" +\n  \"aWNhdGUgQXV0aG9yaXR5MQ0wCwYDVQQDEwRDUkwxMBoGA1UdEAQTMBGBDzIwMTgw\\n\" +\n  \"ODIyMTY0MTUxWjALBgNVHQ8EBAMCAQYwHwYDVR0jBBgwFoAUSOZo+SvSspXXR9gj\\n\" +\n  \"IBBPM5iQn9QwHQYDVR0OBBYEFEjmaPkr0rKV10fYIyAQTzOYkJ/UMAwGA1UdEwQF\\n\" +\n  \"MAMBAf8wGgYJKoZIhvZ9B0EABA0wCxsFVjMuMGMDAgbAMA0GCSqGSIb3DQEBBQUA\\n\" +\n  \"A4GBAFjOKer89961zgK5F7WF0bnj4JXMJTENAKaSbn+2kmOeUJXRmm/kEd5jhW6Y\\n\" +\n  \"7qj/WsjTVbJmcVfewCHrPSqnI0kBBIZCe/zuf6IWUrVnZ9NA2zsmWLIodz2uFHdh\\n\" +\n  \"1voqZiegDfqnc1zqcPGUIWVEX/r87yloqaKHee9570+sB3c4\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // GeoTrust_Global_CA\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDVDCCAjygAwIBAgIDAjRWMA0GCSqGSIb3DQEBBQUAMEIxCzAJBgNVBAYTAlVT\\n\" +\n  \"MRYwFAYDVQQKEw1HZW9UcnVzdCBJbmMuMRswGQYDVQQDExJHZW9UcnVzdCBHbG9i\\n\" +\n  \"YWwgQ0EwHhcNMDIwNTIxMDQwMDAwWhcNMjIwNTIxMDQwMDAwWjBCMQswCQYDVQQG\\n\" +\n  \"EwJVUzEWMBQGA1UEChMNR2VvVHJ1c3QgSW5jLjEbMBkGA1UEAxMSR2VvVHJ1c3Qg\\n\" +\n  \"R2xvYmFsIENBMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA2swYYzD9\\n\" +\n  \"9BcjGlZ+W988bDjkcbd4kdS8odhM+KhDtgPpTSEHCIjaWC9mOSm9BXiLnTjoBbdq\\n\" +\n  \"fnGk5sRgprDvgOSJKA+eJdbtg/OtppHHmMlCGDUUna2YRpIuT8rxh0PBFpVXLVDv\\n\" +\n  \"iS2Aelet8u5fa9IAjbkU+BQVNdnARqN7csiRv8lVK83Qlz6cJmTM386DGXHKTubU\\n\" +\n  \"1XupGc1V3sjs0l44U+VcT4wt/lAjNvxm5suOpDkZALeVAjmRCw7+OC7RHQWa9k0+\\n\" +\n  \"bw8HHa8sHo9gOeL6NlMTOdReJivbPagUvTLrGAMoUgRx5aszPeE4uwc2hGKceeoW\\n\" +\n  \"MPRfwCvocWvk+QIDAQABo1MwUTAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBTA\\n\" +\n  \"ephojYn7qwVkDBF9qn1luMrMTjAfBgNVHSMEGDAWgBTAephojYn7qwVkDBF9qn1l\\n\" +\n  \"uMrMTjANBgkqhkiG9w0BAQUFAAOCAQEANeMpauUvXVSOKVCUn5kaFOSPeCpilKIn\\n\" +\n  \"Z57QzxpeR+nBsqTP3UEaBU6bS+5Kb1VSsyShNwrrZHYqLizz/Tt1kL/6cdjHPTfS\\n\" +\n  \"tQWVYrmm3ok9Nns4d0iXrKYgjy6myQzCsplFAMfOEVEiIuCl6rYVSAlk6l5PdPcF\\n\" +\n  \"PseKUgzbFbS9bZvlxrFUaKnjaZC2mqUPuLk/IH2uSrW4nOQdtqvmlKXBx4Ot2/Un\\n\" +\n  \"hw4EbNX/3aBd7YdStysVAq45pmp06drE57xNNB6pXE0zX5IJL4hmXXeXxx12E6nV\\n\" +\n  \"5fEWCRE11azbJHFwLJhWC9kXtNHjUStedejV0NxPNO3CBWaAocvmMw==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // GeoTrust_Global_CA2\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDZjCCAk6gAwIBAgIBATANBgkqhkiG9w0BAQUFADBEMQswCQYDVQQGEwJVUzEW\\n\" +\n  \"MBQGA1UEChMNR2VvVHJ1c3QgSW5jLjEdMBsGA1UEAxMUR2VvVHJ1c3QgR2xvYmFs\\n\" +\n  \"IENBIDIwHhcNMDQwMzA0MDUwMDAwWhcNMTkwMzA0MDUwMDAwWjBEMQswCQYDVQQG\\n\" +\n  \"EwJVUzEWMBQGA1UEChMNR2VvVHJ1c3QgSW5jLjEdMBsGA1UEAxMUR2VvVHJ1c3Qg\\n\" +\n  \"R2xvYmFsIENBIDIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDvPE1A\\n\" +\n  \"PRDfO1MA4Wf+lGAVPoWI8YkNkMgoI5kF6CsgncbzYEbYwbLVjDHZ3CB5JIG/NTL8\\n\" +\n  \"Y2nbsSpr7iFY8gjpeMtvy/wWUsiRxP89c96xPqfCfWbB9X5SJBri1WeR0IIQ13hL\\n\" +\n  \"TytCOb1kLUCgsBDTOEhGiKEMuzozKmKY+wCdE1l/bztyqu6mD4b5BWHqZ38MN5aL\\n\" +\n  \"5mkWRxHCJ1kDs6ZgwiFAVvqgx306E+PsV8ez1q6diYD3Aecs9pYrEw15LNnA5IZ7\\n\" +\n  \"S4wMcoKK+xfNAGw6EzywhIdLFnopsk/bHdQL82Y3vdj2V7teJHq4PIu5+pIaGoSe\\n\" +\n  \"2HSPqht/XvT+RSIhAgMBAAGjYzBhMA8GA1UdEwEB/wQFMAMBAf8wHQYDVR0OBBYE\\n\" +\n  \"FHE4NvICMVNHK266ZUapEBVYIAUJMB8GA1UdIwQYMBaAFHE4NvICMVNHK266ZUap\\n\" +\n  \"EBVYIAUJMA4GA1UdDwEB/wQEAwIBhjANBgkqhkiG9w0BAQUFAAOCAQEAA/e1K6td\\n\" +\n  \"EPx7srJerJsOflN4WT5CBP51o62sgU7XAotexC3IUnbHLB/8gTKY0UvGkpMzNTEv\\n\" +\n  \"/NgdRN3ggX+d6YvhZJFiCzkIjKx0nVnZellSlxG5FntvRdOW2TF9AjYPnDtuzywN\\n\" +\n  \"A0ZF66D0f0hExghAzN4bcLUprbqLOzRldRtxIR0sFAqwlpW41uryZfspuk/qkZN0\\n\" +\n  \"abby/+Ea0AzRdoXLiiW9l14sbxWZJue2Kf8i7MkCx1YAzUm5s2x7UwQa4qjJqhIF\\n\" +\n  \"I8LO57sEAszAR6LkxCkvW0VXiVHuPOtSCP8HNR6fNWpHSlaY0VqFH4z1Ir+rzoPz\\n\" +\n  \"4iIprn2DQKi6bA==\\n\" +\n  \"-----END CERTIFICATE----- \\n\",\n\n  // GeoTrust_Primary_CA\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDfDCCAmSgAwIBAgIQGKy1av1pthU6Y2yv2vrEoTANBgkqhkiG9w0BAQUFADBY\\n\" +\n  \"MQswCQYDVQQGEwJVUzEWMBQGA1UEChMNR2VvVHJ1c3QgSW5jLjExMC8GA1UEAxMo\\n\" +\n  \"R2VvVHJ1c3QgUHJpbWFyeSBDZXJ0aWZpY2F0aW9uIEF1dGhvcml0eTAeFw0wNjEx\\n\" +\n  \"MjcwMDAwMDBaFw0zNjA3MTYyMzU5NTlaMFgxCzAJBgNVBAYTAlVTMRYwFAYDVQQK\\n\" +\n  \"Ew1HZW9UcnVzdCBJbmMuMTEwLwYDVQQDEyhHZW9UcnVzdCBQcmltYXJ5IENlcnRp\\n\" +\n  \"ZmljYXRpb24gQXV0aG9yaXR5MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKC\\n\" +\n  \"AQEAvrgVe//UfH1nrYNke8hCUy3f9oQIIGHWAVlqnEQRr+92/ZV+zmEwu3qDXwK9\\n\" +\n  \"AWbK7hWNb6EwnL2hhZ6UOvNWiAAxz9juapYC2e0DjPt1befquFUWBRaa9OBesYjA\\n\" +\n  \"ZIVcFU2Ix7e64HXprQU9nceJSOC7KMgD4TCTZF5SwFlwIjVXiIrxlQqD17wxcwE0\\n\" +\n  \"7e9GceBrAqg1cmuXm2bgyxx5X9gaBGgeRwLmnWDiNpcB3841kt++Z8dtd1k7j53W\\n\" +\n  \"kBWUvEI0EME5+bEnPn7WinXFsq+W06Lem+SYvn3h6YGttm/81w7a4DSwDRp35+MI\\n\" +\n  \"mO9Y+pyEtzavwt+s0vQQBnBxNQIDAQABo0IwQDAPBgNVHRMBAf8EBTADAQH/MA4G\\n\" +\n  \"A1UdDwEB/wQEAwIBBjAdBgNVHQ4EFgQULNVQQZcVi/CPNmFbSvtr2ZnJM5IwDQYJ\\n\" +\n  \"KoZIhvcNAQEFBQADggEBAFpwfyzdtzRP9YZRqSa+S7iq8XEN3GHHoOo0Hnp3DwQ1\\n\" +\n  \"6CePbJC/kRYkRj5KTs4rFtULUh38H2eiAkUxT87z+gOneZ1TatnaYzr4gNfTmeGl\\n\" +\n  \"4b7UVXGYNTq+k+qurUKykG/g/CFNNWMziUnWm07Kx+dOCQD32sfvmWKZd7aVIl6K\\n\" +\n  \"oKv0uHiYyjgZmclynnjNS6yvGaBzEi38wkG6gZHaFloxt/m0cYASSJlyc1pZU8Fj\\n\" +\n  \"UjPtp8nSOQJw+uCxQmYpqptR7TBUIhRf2asdweSU8Pj1K/fqynhG1riR/aYNKxoU\\n\" +\n  \"AT6A8EKglQdebc3MS6RFjasS6LPeWuWgfOgPIh1a6Vk=\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // GeoTrust_Primary_CA_G2_ECC\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIICrjCCAjWgAwIBAgIQPLL0SAoA4v7rJDteYD7DazAKBggqhkjOPQQDAzCBmDEL\\n\" +\n  \"MAkGA1UEBhMCVVMxFjAUBgNVBAoTDUdlb1RydXN0IEluYy4xOTA3BgNVBAsTMChj\\n\" +\n  \"KSAyMDA3IEdlb1RydXN0IEluYy4gLSBGb3IgYXV0aG9yaXplZCB1c2Ugb25seTE2\\n\" +\n  \"MDQGA1UEAxMtR2VvVHJ1c3QgUHJpbWFyeSBDZXJ0aWZpY2F0aW9uIEF1dGhvcml0\\n\" +\n  \"eSAtIEcyMB4XDTA3MTEwNTAwMDAwMFoXDTM4MDExODIzNTk1OVowgZgxCzAJBgNV\\n\" +\n  \"BAYTAlVTMRYwFAYDVQQKEw1HZW9UcnVzdCBJbmMuMTkwNwYDVQQLEzAoYykgMjAw\\n\" +\n  \"NyBHZW9UcnVzdCBJbmMuIC0gRm9yIGF1dGhvcml6ZWQgdXNlIG9ubHkxNjA0BgNV\\n\" +\n  \"BAMTLUdlb1RydXN0IFByaW1hcnkgQ2VydGlmaWNhdGlvbiBBdXRob3JpdHkgLSBH\\n\" +\n  \"MjB2MBAGByqGSM49AgEGBSuBBAAiA2IABBWx6P0DFUPlrOuHNxFi79KDNlJ9RVcL\\n\" +\n  \"So17VDs6bl8VAsBQps8lL33KSLjHUGMcKiEIfJo22Av+0SbFWDEwKCXzXV2juLal\\n\" +\n  \"tJLtbCyf691DiaI8S0iRHVDsJt/WYC69IaNCMEAwDwYDVR0TAQH/BAUwAwEB/zAO\\n\" +\n  \"BgNVHQ8BAf8EBAMCAQYwHQYDVR0OBBYEFBVfNVdRVfslsq0DafwBo/q+EVXVMAoG\\n\" +\n  \"CCqGSM49BAMDA2cAMGQCMGSWWaboCd6LuvpaiIjwH5HTRqjySkwCY/tsXzjbLkGT\\n\" +\n  \"qQ7mndwxHLKgpxgceeHHNgIwOlavmnRs9vuD4DPTCF+hnMJbn0bWtsuRBmOiBucz\\n\" +\n  \"rD6ogRLQy7rQkgu2npaqBA+K\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // GeoTrust_Universal_CA\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIFaDCCA1CgAwIBAgIBATANBgkqhkiG9w0BAQUFADBFMQswCQYDVQQGEwJVUzEW\\n\" +\n  \"MBQGA1UEChMNR2VvVHJ1c3QgSW5jLjEeMBwGA1UEAxMVR2VvVHJ1c3QgVW5pdmVy\\n\" +\n  \"c2FsIENBMB4XDTA0MDMwNDA1MDAwMFoXDTI5MDMwNDA1MDAwMFowRTELMAkGA1UE\\n\" +\n  \"BhMCVVMxFjAUBgNVBAoTDUdlb1RydXN0IEluYy4xHjAcBgNVBAMTFUdlb1RydXN0\\n\" +\n  \"IFVuaXZlcnNhbCBDQTCCAiIwDQYJKoZIhvcNAQEBBQADggIPADCCAgoCggIBAKYV\\n\" +\n  \"VaCjxuAfjJ0hUNfBvitbtaSeodlyWL0AG0y/YckUHUWCq8YdgNY96xCcOq9tJPi8\\n\" +\n  \"cQGeBvV8Xx7BDlXKg5pZMK4ZyzBIle0iN430SppyZj6tlcDgFgDgEB8rMQ7XlFTT\\n\" +\n  \"QjOgNB0eRXbdT8oYN+yFFXoZCPzVx5zw8qkuEKmS5j1YPakWaDwvdSEYfyh3peFh\\n\" +\n  \"F7em6fgemdtzbvQKoiFs7tqqhZJmr/Z6a4LauiIINQ/PQvE1+mrufislzDoR5G2v\\n\" +\n  \"c7J2Ha3QsnhnGqQ5HFELZ1aD/ThdDc7d8Lsrlh/eezJS/R27tQahsiFepdaVaH/w\\n\" +\n  \"mZ7cRQg+59IJDTWU3YBOU5fXtQlEIGQWFwMCTFMNaN7VqnJNk22CDtucvc+081xd\\n\" +\n  \"VHppCZbW2xHBjXWotM85yM48vCR85mLK4b19p71XZQvk/iXttmkQ3CgaRr0BHdCX\\n\" +\n  \"teGYO8A3ZNY9lO4L4fUorgtWv3GLIylBjobFS1J72HGrH4oVpjuDWtdYAVHGTEHZ\\n\" +\n  \"f9hBZ3KiKN9gg6meyHv8U3NyWfWTehd2Ds735VzZC1U0oqpbtWpU5xPKV+yXbfRe\\n\" +\n  \"Bi9Fi1jUIxaS5BZuKGNZMN9QAZxjiRqf2xeUgnA3wySemkfWWspOqGmJch+RbNt+\\n\" +\n  \"nhutxx9z3SxPGWX9f5NAEC7S8O08ni4oPmkmM8V7AgMBAAGjYzBhMA8GA1UdEwEB\\n\" +\n  \"/wQFMAMBAf8wHQYDVR0OBBYEFNq7LqqwDLiIJlF0XG0D08DYj3rWMB8GA1UdIwQY\\n\" +\n  \"MBaAFNq7LqqwDLiIJlF0XG0D08DYj3rWMA4GA1UdDwEB/wQEAwIBhjANBgkqhkiG\\n\" +\n  \"9w0BAQUFAAOCAgEAMXjmx7XfuJRAyXHEqDXsRh3ChfMoWIawC/yOsjmPRFWrZIRc\\n\" +\n  \"aanQmjg8+uUfNeVE44B5lGiku8SfPeE0zTBGi1QrlaXv9z+ZhP015s8xxtxqv6fX\\n\" +\n  \"IwjhmF7DWgh2qaavdy+3YL1ERmrvl/9zlcGO6JP7/TG37FcREUWbMPEaiDnBTzyn\\n\" +\n  \"ANXH/KttgCJwpQzgXQQpAvvLoJHRfNbDflDVnVi+QTjruXU8FdmbyUqDWcDaU/0z\\n\" +\n  \"uzYYm4UPFd3uLax2k7nZAY1IEKj79TiG8dsKxr2EoyNB3tZ3b4XUhRxQ4K5RirqN\\n\" +\n  \"Pnbiucon8l+f725ZDQbYKxek0nxru18UGkiPGkzns0ccjkxFKyDuSN/n3QmOGKja\\n\" +\n  \"QI2SJhFTYXNd673nxE0pN2HrrDktZy4W1vUAg4WhzH92xH3kt0tm7wNFYGm2DFKW\\n\" +\n  \"koRepqO1pD4r2czYG0eq8kTaT/kD6PAUyz/zg97QwVTjt+gKN02LIFkDMBmhLMi9\\n\" +\n  \"ER/frslKxfMnZmaGrGiR/9nmUxwPi1xpZQomyB40w11Re9epnAahNt3ViZS82eQt\\n\" +\n  \"DF4JbAiXfKM9fJP/P6EUp8+1Xevb2xzEdt+Iub1FBZUbrvxGakyvSOPOrg/Sfuvm\\n\" +\n  \"bJxPgWp6ZKy7PtXny3YuxadIwVyQD8vIP/rmMuGNG2+k5o7Y+SlIis5z/iw=\\n\" +\n  \"-----END CERTIFICATE----- \\n\",\n\n  // GeoTrust_Universal_CA2\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIFbDCCA1SgAwIBAgIBATANBgkqhkiG9w0BAQUFADBHMQswCQYDVQQGEwJVUzEW\\n\" +\n  \"MBQGA1UEChMNR2VvVHJ1c3QgSW5jLjEgMB4GA1UEAxMXR2VvVHJ1c3QgVW5pdmVy\\n\" +\n  \"c2FsIENBIDIwHhcNMDQwMzA0MDUwMDAwWhcNMjkwMzA0MDUwMDAwWjBHMQswCQYD\\n\" +\n  \"VQQGEwJVUzEWMBQGA1UEChMNR2VvVHJ1c3QgSW5jLjEgMB4GA1UEAxMXR2VvVHJ1\\n\" +\n  \"c3QgVW5pdmVyc2FsIENBIDIwggIiMA0GCSqGSIb3DQEBAQUAA4ICDwAwggIKAoIC\\n\" +\n  \"AQCzVFLByT7y2dyxUxpZKeexw0Uo5dfR7cXFS6GqdHtXr0om/Nj1XqduGdt0DE81\\n\" +\n  \"WzILAePb63p3NeqqWuDW6KFXlPCQo3RWlEQwAx5cTiuFJnSCegx2oG9NzkEtoBUG\\n\" +\n  \"FF+3Qs17j1hhNNwqCPkuwwGmIkQcTAeC5lvO0Ep8BNMZcyfwqph/Lq9O64ceJHdq\\n\" +\n  \"XbboW0W63MOhBW9Wjo8QJqVJwy7XQYci4E+GymC16qFjwAGXEHm9ADwSbSsVsaxL\\n\" +\n  \"se4YuU6W3Nx2/zu+z18DwPw76L5GG//aQMJS9/7jOvdqdzXQ2o3rXhhqMcceujwb\\n\" +\n  \"KNZrVMaqW9eiLBsZzKIC9ptZvTdrhrVtgrrY6slWvKk2WP0+GfPtDCapkzj4T8Fd\\n\" +\n  \"IgbQl+rhrcZV4IErKIM6+vR7IVEAvlI4zs1meaj0gVbi0IMJR1FbUGrP20gaXT73\\n\" +\n  \"y/Zl92zxlfgCOzJWgjl6W70viRu/obTo/3+NjN8D8WBOWBFM66M/ECuDmgFz2ZRt\\n\" +\n  \"hAAnZqzwcEAJQpKtT5MNYQlRJNiS1QuUYbKHsu3/mjX/hVTK7URDrBs8FmtISgoc\\n\" +\n  \"QIgfksILAAX/8sgCSqSqqcyZlpwvWOB94b67B9xfBHJcMTTD7F8t4D1kkCLm0ey4\\n\" +\n  \"Lt1ZrtmhN79UNdxzMk+MBB4zsslG8dhcyFVQyWi9qLo2CQIDAQABo2MwYTAPBgNV\\n\" +\n  \"HRMBAf8EBTADAQH/MB0GA1UdDgQWBBR281Xh+qQ2+/CfXGJx7Tz0RzgQKzAfBgNV\\n\" +\n  \"HSMEGDAWgBR281Xh+qQ2+/CfXGJx7Tz0RzgQKzAOBgNVHQ8BAf8EBAMCAYYwDQYJ\\n\" +\n  \"KoZIhvcNAQEFBQADggIBAGbBxiPz2eAubl/oz66wsCVNK/g7WJtAJDday6sWSf+z\\n\" +\n  \"dXkzoS9tcBc0kf5nfo/sm+VegqlVHy/c1FEHEv6sFj4sNcZj/NwQ6w2jqtB8zNHQ\\n\" +\n  \"L1EuxBRa3ugZ4T7GzKQp5y6EqgYweHZUcyiYWTjgAA1i00J9IZ+uPTqM1fp3DRgr\\n\" +\n  \"Fg5fNuH8KrUwJM/gYwx7WBr+mbpCErGR9Hxo4sjoryzqyX6uuyo9DRXcNJW2GHSo\\n\" +\n  \"ag/HtPQTxORb7QrSpJdMKu0vbBKJPfEncKpqA1Ihn0CoZ1Dy81of398j9tx4TuaY\\n\" +\n  \"T1U6U+Pv8vSfx3zYWK8pIpe44L2RLrB27FcRz+8pRPPphXpgY+RdM4kX2TGq2tbz\\n\" +\n  \"GDVyz4crL2MjhF2EjD9XoIj8mZEoJmmZ1I+XRL6O1UixpCgp8RW04eWe3fiPpm8m\\n\" +\n  \"1wk8OhwRDqZsN/etRIcsKMfYdIKz0G9KV7s1KSegi+ghp4dkNl3M2Basx7InQJJV\\n\" +\n  \"OCiNUW7dFGdTbHFcJoRNdVq2fmBWqU2t+5sel/MN2dKXVHfaPRK34B7vCAas+YWH\\n\" +\n  \"6aLcr34YEoP9VhdBLtUpgn2Z9DH2canPLAEnpQW5qrJITirvn5NSUZU8UnOOVkwX\\n\" +\n  \"QMAJKOSLakhT2+zNVVXxxvjpoixMptEmX36vWkzaH6byHCx+rgIW0lbQL1dTR+iS\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // GlobalSign_Root_CA\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDdTCCAl2gAwIBAgILBAAAAAABFUtaw5QwDQYJKoZIhvcNAQEFBQAwVzELMAkG\\n\" +\n  \"A1UEBhMCQkUxGTAXBgNVBAoTEEdsb2JhbFNpZ24gbnYtc2ExEDAOBgNVBAsTB1Jv\\n\" +\n  \"b3QgQ0ExGzAZBgNVBAMTEkdsb2JhbFNpZ24gUm9vdCBDQTAeFw05ODA5MDExMjAw\\n\" +\n  \"MDBaFw0yODAxMjgxMjAwMDBaMFcxCzAJBgNVBAYTAkJFMRkwFwYDVQQKExBHbG9i\\n\" +\n  \"YWxTaWduIG52LXNhMRAwDgYDVQQLEwdSb290IENBMRswGQYDVQQDExJHbG9iYWxT\\n\" +\n  \"aWduIFJvb3QgQ0EwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDaDuaZ\\n\" +\n  \"jc6j40+Kfvvxi4Mla+pIH/EqsLmVEQS98GPR4mdmzxzdzxtIK+6NiY6arymAZavp\\n\" +\n  \"xy0Sy6scTHAHoT0KMM0VjU/43dSMUBUc71DuxC73/OlS8pF94G3VNTCOXkNz8kHp\\n\" +\n  \"1Wrjsok6Vjk4bwY8iGlbKk3Fp1S4bInMm/k8yuX9ifUSPJJ4ltbcdG6TRGHRjcdG\\n\" +\n  \"snUOhugZitVtbNV4FpWi6cgKOOvyJBNPc1STE4U6G7weNLWLBYy5d4ux2x8gkasJ\\n\" +\n  \"U26Qzns3dLlwR5EiUWMWea6xrkEmCMgZK9FGqkjWZCrXgzT/LCrBbBlDSgeF59N8\\n\" +\n  \"9iFo7+ryUp9/k5DPAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwIBBjAPBgNVHRMBAf8E\\n\" +\n  \"BTADAQH/MB0GA1UdDgQWBBRge2YaRQ2XyolQL30EzTSo//z9SzANBgkqhkiG9w0B\\n\" +\n  \"AQUFAAOCAQEA1nPnfE920I2/7LqivjTFKDK1fPxsnCwrvQmeU79rXqoRSLblCKOz\\n\" +\n  \"yj1hTdNGCbM+w6DjY1Ub8rrvrTnhQ7k4o+YviiY776BQVvnGCv04zcQLcFGUl5gE\\n\" +\n  \"38NflNUVyRRBnMRddWQVDf9VMOyGj/8N7yy5Y0b2qvzfvGn9LhJIZJrglfCm7ymP\\n\" +\n  \"AbEVtQwdpf5pLGkkeB6zpxxxYu7KyJesF12KwvhHhm4qxFYxldBniYUr+WymXUad\\n\" +\n  \"DKqC5JlR3XC321Y9YeRq4VzW9v493kHMB65jUr9TU/Qr6cf9tveCX4XSQRjbgbME\\n\" +\n  \"HMUfpIBvFSDJ3gyICh3WZlXi/EjJKSZp4A==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // GlobalSign_Root_CA_ECC_R4\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIB4TCCAYegAwIBAgIRKjikHJYKBN5CsiilC+g0mAIwCgYIKoZIzj0EAwIwUDEk\\n\" +\n  \"MCIGA1UECxMbR2xvYmFsU2lnbiBFQ0MgUm9vdCBDQSAtIFI0MRMwEQYDVQQKEwpH\\n\" +\n  \"bG9iYWxTaWduMRMwEQYDVQQDEwpHbG9iYWxTaWduMB4XDTEyMTExMzAwMDAwMFoX\\n\" +\n  \"DTM4MDExOTAzMTQwN1owUDEkMCIGA1UECxMbR2xvYmFsU2lnbiBFQ0MgUm9vdCBD\\n\" +\n  \"QSAtIFI0MRMwEQYDVQQKEwpHbG9iYWxTaWduMRMwEQYDVQQDEwpHbG9iYWxTaWdu\\n\" +\n  \"MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEuMZ5049sJQ6fLjkZHAOkrprlOQcJ\\n\" +\n  \"FspjsbmG+IpXwVfOQvpzofdlQv8ewQCybnMO/8ch5RikqtlxP6jUuc6MHaNCMEAw\\n\" +\n  \"DgYDVR0PAQH/BAQDAgEGMA8GA1UdEwEB/wQFMAMBAf8wHQYDVR0OBBYEFFSwe61F\\n\" +\n  \"uOJAf/sKbvu+M8k8o4TVMAoGCCqGSM49BAMCA0gAMEUCIQDckqGgE6bPA7DmxCGX\\n\" +\n  \"kPoUVy0D7O48027KqGx2vKLeuwIgJ6iFJzWbVsaj8kfSt24bAgAXqmemFZHe+pTs\\n\" +\n  \"ewv4n4Q=\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // GlobalSign_Root_CA_ECC_R5\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIICHjCCAaSgAwIBAgIRYFlJ4CYuu1X5CneKcflK2GwwCgYIKoZIzj0EAwMwUDEk\\n\" +\n  \"MCIGA1UECxMbR2xvYmFsU2lnbiBFQ0MgUm9vdCBDQSAtIFI1MRMwEQYDVQQKEwpH\\n\" +\n  \"bG9iYWxTaWduMRMwEQYDVQQDEwpHbG9iYWxTaWduMB4XDTEyMTExMzAwMDAwMFoX\\n\" +\n  \"DTM4MDExOTAzMTQwN1owUDEkMCIGA1UECxMbR2xvYmFsU2lnbiBFQ0MgUm9vdCBD\\n\" +\n  \"QSAtIFI1MRMwEQYDVQQKEwpHbG9iYWxTaWduMRMwEQYDVQQDEwpHbG9iYWxTaWdu\\n\" +\n  \"MHYwEAYHKoZIzj0CAQYFK4EEACIDYgAER0UOlvt9Xb/pOdEh+J8LttV7HpI6SFkc\\n\" +\n  \"8GIxLcB6KP4ap1yztsyX50XUWPrRd21DosCHZTQKH3rd6zwzocWdTaRvQZU4f8ke\\n\" +\n  \"hOvRnkmSh5SHDDqFSmafnVmTTZdhBoZKo0IwQDAOBgNVHQ8BAf8EBAMCAQYwDwYD\\n\" +\n  \"VR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUPeYpSJvqB8ohREom3m7e0oPQn1kwCgYI\\n\" +\n  \"KoZIzj0EAwMDaAAwZQIxAOVpEslu28YxuglB4Zf4+/2a4n0Sye18ZNPLBSWLVtmg\\n\" +\n  \"515dTguDnFt2KaAJJiFqYgIwcdK1j1zqO+F4CYWodZI7yFz9SO8NdCKoCOJuxUnO\\n\" +\n  \"xwy8p2Fp8fc74SrL+SvzZpA3\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // GlobalSign_Root_CA_R3\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDXzCCAkegAwIBAgILBAAAAAABIVhTCKIwDQYJKoZIhvcNAQELBQAwTDEgMB4G\\n\" +\n  \"A1UECxMXR2xvYmFsU2lnbiBSb290IENBIC0gUjMxEzARBgNVBAoTCkdsb2JhbFNp\\n\" +\n  \"Z24xEzARBgNVBAMTCkdsb2JhbFNpZ24wHhcNMDkwMzE4MTAwMDAwWhcNMjkwMzE4\\n\" +\n  \"MTAwMDAwWjBMMSAwHgYDVQQLExdHbG9iYWxTaWduIFJvb3QgQ0EgLSBSMzETMBEG\\n\" +\n  \"A1UEChMKR2xvYmFsU2lnbjETMBEGA1UEAxMKR2xvYmFsU2lnbjCCASIwDQYJKoZI\\n\" +\n  \"hvcNAQEBBQADggEPADCCAQoCggEBAMwldpB5BngiFvXAg7aEyiie/QV2EcWtiHL8\\n\" +\n  \"RgJDx7KKnQRfJMsuS+FggkbhUqsMgUdwbN1k0ev1LKMPgj0MK66X17YUhhB5uzsT\\n\" +\n  \"gHeMCOFJ0mpiLx9e+pZo34knlTifBtc+ycsmWQ1z3rDI6SYOgxXG71uL0gRgykmm\\n\" +\n  \"KPZpO/bLyCiR5Z2KYVc3rHQU3HTgOu5yLy6c+9C7v/U9AOEGM+iCK65TpjoWc4zd\\n\" +\n  \"QQ4gOsC0p6Hpsk+QLjJg6VfLuQSSaGjlOCZgdbKfd/+RFO+uIEn8rUAVSNECMWEZ\\n\" +\n  \"XriX7613t2Saer9fwRPvm2L7DWzgVGkWqQPabumDk3F2xmmFghcCAwEAAaNCMEAw\\n\" +\n  \"DgYDVR0PAQH/BAQDAgEGMA8GA1UdEwEB/wQFMAMBAf8wHQYDVR0OBBYEFI/wS3+o\\n\" +\n  \"LkUkrk1Q+mOai97i3Ru8MA0GCSqGSIb3DQEBCwUAA4IBAQBLQNvAUKr+yAzv95ZU\\n\" +\n  \"RUm7lgAJQayzE4aGKAczymvmdLm6AC2upArT9fHxD4q/c2dKg8dEe3jgr25sbwMp\\n\" +\n  \"jjM5RcOO5LlXbKr8EpbsU8Yt5CRsuZRj+9xTaGdWPoO4zzUhw8lo/s7awlOqzJCK\\n\" +\n  \"6fBdRoyV3XpYKBovHd7NADdBj+1EbddTKJd+82cEHhXXipa0095MJ6RMG3NzdvQX\\n\" +\n  \"mcIfeg7jLQitChws/zyrVQ4PkX4268NXSb7hLi18YIvDQVETI53O9zJrlAGomecs\\n\" +\n  \"Mx86OyXShkDOOyyGeMlhLxS67ttVb9+E7gUJTb0o2HLO02JQZR7rkpeDMdmztcpH\\n\" +\n  \"WD9f\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // GlobalSign_Root_CA_RC2\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDujCCAqKgAwIBAgILBAAAAAABD4Ym5g0wDQYJKoZIhvcNAQEFBQAwTDEgMB4G\\n\" +\n  \"A1UECxMXR2xvYmFsU2lnbiBSb290IENBIC0gUjIxEzARBgNVBAoTCkdsb2JhbFNp\\n\" +\n  \"Z24xEzARBgNVBAMTCkdsb2JhbFNpZ24wHhcNMDYxMjE1MDgwMDAwWhcNMjExMjE1\\n\" +\n  \"MDgwMDAwWjBMMSAwHgYDVQQLExdHbG9iYWxTaWduIFJvb3QgQ0EgLSBSMjETMBEG\\n\" +\n  \"A1UEChMKR2xvYmFsU2lnbjETMBEGA1UEAxMKR2xvYmFsU2lnbjCCASIwDQYJKoZI\\n\" +\n  \"hvcNAQEBBQADggEPADCCAQoCggEBAKbPJA6+Lm8omUVCxKs+IVSbC9N/hHD6ErPL\\n\" +\n  \"v4dfxn+G07IwXNb9rfF73OX4YJYJkhD10FPe+3t+c4isUoh7SqbKSaZeqKeMWhG8\\n\" +\n  \"eoLrvozps6yWJQeXSpkqBy+0Hne/ig+1AnwblrjFuTosvNYSuetZfeLQBoZfXklq\\n\" +\n  \"tTleiDTsvHgMCJiEbKjNS7SgfQx5TfC4LcshytVsW33hoCmEofnTlEnLJGKRILzd\\n\" +\n  \"C9XZzPnqJworc5HGnRusyMvo4KD0L5CLTfuwNhv2GXqF4G3yYROIXJ/gkwpRl4pa\\n\" +\n  \"zq+r1feqCapgvdzZX99yqWATXgAByUr6P6TqBwMhAo6CygPCm48CAwEAAaOBnDCB\\n\" +\n  \"mTAOBgNVHQ8BAf8EBAMCAQYwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUm+IH\\n\" +\n  \"V2ccHsBqBt5ZtJot39wZhi4wNgYDVR0fBC8wLTAroCmgJ4YlaHR0cDovL2NybC5n\\n\" +\n  \"bG9iYWxzaWduLm5ldC9yb290LXIyLmNybDAfBgNVHSMEGDAWgBSb4gdXZxwewGoG\\n\" +\n  \"3lm0mi3f3BmGLjANBgkqhkiG9w0BAQUFAAOCAQEAmYFThxxol4aR7OBKuEQLq4Gs\\n\" +\n  \"J0/WwbgcQ3izDJr86iw8bmEbTUsp9Z8FHSbBuOmDAGJFtqkIk7mpM0sYmsL4h4hO\\n\" +\n  \"291xNBrBVNpGP+DTKqttVCL1OmLNIG+6KYnX3ZHu01yiPqFbQfXf5WRDLenVOavS\\n\" +\n  \"ot+3i9DAgBkcRcAtjOj4LaR0VknFBbVPFd5uRHg5h6h+u/N5GJG79G+dwfCMNYxd\\n\" +\n  \"AfvDbbnvRG15RjF+Cv6pgsH/76tuIMRQyV+dTZsXjAzlAcmgQWpzU/qlULRuJQ/7\\n\" +\n  \"TBj0/VLZjmmx6BEP3ojY+x1J96relc8geMJgEtslQIxq/H5COEBkEveegeGTLg==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // VeriSign-PCA-2G2\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDAzCCAmwCEQC5L2DMiJ+hekYJuFtwbIqvMA0GCSqGSIb3DQEBBQUAMIHBMQsw\\n\" +\n  \"CQYDVQQGEwJVUzEXMBUGA1UEChMOVmVyaVNpZ24sIEluYy4xPDA6BgNVBAsTM0Ns\\n\" +\n  \"YXNzIDIgUHVibGljIFByaW1hcnkgQ2VydGlmaWNhdGlvbiBBdXRob3JpdHkgLSBH\\n\" +\n  \"MjE6MDgGA1UECxMxKGMpIDE5OTggVmVyaVNpZ24sIEluYy4gLSBGb3IgYXV0aG9y\\n\" +\n  \"aXplZCB1c2Ugb25seTEfMB0GA1UECxMWVmVyaVNpZ24gVHJ1c3QgTmV0d29yazAe\\n\" +\n  \"Fw05ODA1MTgwMDAwMDBaFw0yODA4MDEyMzU5NTlaMIHBMQswCQYDVQQGEwJVUzEX\\n\" +\n  \"MBUGA1UEChMOVmVyaVNpZ24sIEluYy4xPDA6BgNVBAsTM0NsYXNzIDIgUHVibGlj\\n\" +\n  \"IFByaW1hcnkgQ2VydGlmaWNhdGlvbiBBdXRob3JpdHkgLSBHMjE6MDgGA1UECxMx\\n\" +\n  \"KGMpIDE5OTggVmVyaVNpZ24sIEluYy4gLSBGb3IgYXV0aG9yaXplZCB1c2Ugb25s\\n\" +\n  \"eTEfMB0GA1UECxMWVmVyaVNpZ24gVHJ1c3QgTmV0d29yazCBnzANBgkqhkiG9w0B\\n\" +\n  \"AQEFAAOBjQAwgYkCgYEAp4gBIXQs5xoD8JjhlzwPIQjxnNuX6Zr8wgQGE75fUsjM\\n\" +\n  \"HiwSViy4AWkszJkfrbCWrnkE8hM5wXuYuggs6MKEEyyqaekJ9MepAqRCwiNPStjw\\n\" +\n  \"DqL7MWzJ5m+ZJwf15vRMeJ5t60aG+rmGyVTyssSv1EYcWskVMP8NbPUtDm3Of3cC\\n\" +\n  \"AwEAATANBgkqhkiG9w0BAQUFAAOBgQByLvl/0fFx+8Se9sVeUYpAmLho+Jscg9ji\\n\" +\n  \"nb3/7aHmZuovCfTK1+qlK5X2JGCGTUQug6XELaDTrnhpb3LabK4I8GOSN+a7xDAX\\n\" +\n  \"rXfMSTWqz9iP0b63GJZHc2pUIjRkLbYWm1lbtFFZOrMLFPQS32eg9K0yZF6xRnIn\\n\" +\n  \"jBJ7xUS0rg==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // VeriSign-PCA-2G3\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIEGTCCAwECEGFwy0mMX5hFKeewptlQW3owDQYJKoZIhvcNAQEFBQAwgcoxCzAJ\\n\" +\n  \"BgNVBAYTAlVTMRcwFQYDVQQKEw5WZXJpU2lnbiwgSW5jLjEfMB0GA1UECxMWVmVy\\n\" +\n  \"aVNpZ24gVHJ1c3QgTmV0d29yazE6MDgGA1UECxMxKGMpIDE5OTkgVmVyaVNpZ24s\\n\" +\n  \"IEluYy4gLSBGb3IgYXV0aG9yaXplZCB1c2Ugb25seTFFMEMGA1UEAxM8VmVyaVNp\\n\" +\n  \"Z24gQ2xhc3MgMiBQdWJsaWMgUHJpbWFyeSBDZXJ0aWZpY2F0aW9uIEF1dGhvcml0\\n\" +\n  \"eSAtIEczMB4XDTk5MTAwMTAwMDAwMFoXDTM2MDcxNjIzNTk1OVowgcoxCzAJBgNV\\n\" +\n  \"BAYTAlVTMRcwFQYDVQQKEw5WZXJpU2lnbiwgSW5jLjEfMB0GA1UECxMWVmVyaVNp\\n\" +\n  \"Z24gVHJ1c3QgTmV0d29yazE6MDgGA1UECxMxKGMpIDE5OTkgVmVyaVNpZ24sIElu\\n\" +\n  \"Yy4gLSBGb3IgYXV0aG9yaXplZCB1c2Ugb25seTFFMEMGA1UEAxM8VmVyaVNpZ24g\\n\" +\n  \"Q2xhc3MgMiBQdWJsaWMgUHJpbWFyeSBDZXJ0aWZpY2F0aW9uIEF1dGhvcml0eSAt\\n\" +\n  \"IEczMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEArwoNwtUs22e5LeWU\\n\" +\n  \"J92lvuCwTY+zYVY81nzD9M0+hsuiiOLh2KRpxbXiv8GmR1BeRjmL1Za6tW8UvxDO\\n\" +\n  \"JxOeBUebMXoT2B/Z0wI3i60sR/COgQanDTAM6/c8DyAd3HJG7qUCyFvDyVZpTMUY\\n\" +\n  \"wZF7C9UTAJu878NIPkZgIIUq1ZC2zYugzDLdt/1AVbJQHFauzI13TccgTacxdu9o\\n\" +\n  \"koqQHgiBVrKtaaNS0MscxCM9H5n+TOgWY47GCI72MfbS+uV23bUckqNJzc0BzWjN\\n\" +\n  \"qWm6o+sdDZykIKbBoMXRRkwXbdKsZj+WjOCE1Db/IlnF+RFgqF8EffIa9iVCYQ/E\\n\" +\n  \"Srg+iQIDAQABMA0GCSqGSIb3DQEBBQUAA4IBAQA0JhU8wI1NQ0kdvekhktdmnLfe\\n\" +\n  \"xbjQ5F1fdiLAJvmEOjr5jLX77GDx6M4EsMjdpwOPMPOY36TmpDHf0xwLRtxyID+u\\n\" +\n  \"7gU8pDM/CzmscHhzS5kr3zDCVLCoO1Wh/hYozUK9dG6A2ydEp85EXdQbkJgNHkKU\\n\" +\n  \"sQAsBNB0owIFImNjzYO1+8FtYmtpdf1dcEG59b98377BMnMiIYtYgXsVkXq642RI\\n\" +\n  \"sH/7NiXaldDxJBQX3RiAa0YjOVT1jmIJBB2UkKab5iXiQkWquJCtvgiPqQtCGJTP\\n\" +\n  \"cjnhsUPgKM+351psE2tJs//jGHyJizNdrDPXp/naOlXJWBD5qu9ats9LS98q\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // VeriSign-PCA-3\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIICPDCCAaUCEDyRMcsf9tAbDpq40ES/Er4wDQYJKoZIhvcNAQEFBQAwXzELMAkG\\n\" +\n  \"A1UEBhMCVVMxFzAVBgNVBAoTDlZlcmlTaWduLCBJbmMuMTcwNQYDVQQLEy5DbGFz\\n\" +\n  \"cyAzIFB1YmxpYyBQcmltYXJ5IENlcnRpZmljYXRpb24gQXV0aG9yaXR5MB4XDTk2\\n\" +\n  \"MDEyOTAwMDAwMFoXDTI4MDgwMjIzNTk1OVowXzELMAkGA1UEBhMCVVMxFzAVBgNV\\n\" +\n  \"BAoTDlZlcmlTaWduLCBJbmMuMTcwNQYDVQQLEy5DbGFzcyAzIFB1YmxpYyBQcmlt\\n\" +\n  \"YXJ5IENlcnRpZmljYXRpb24gQXV0aG9yaXR5MIGfMA0GCSqGSIb3DQEBAQUAA4GN\\n\" +\n  \"ADCBiQKBgQDJXFme8huKARS0EN8EQNvjV69qRUCPhAwL0TPZ2RHP7gJYHyX3KqhE\\n\" +\n  \"BarsAx94f56TuZoAqiN91qyFomNFx3InzPRMxnVx0jnvT0Lwdd8KkMaOIG+YD/is\\n\" +\n  \"I19wKTakyYbnsZogy1Olhec9vn2a/iRFM9x2Fe0PonFkTGUugWhFpwIDAQABMA0G\\n\" +\n  \"CSqGSIb3DQEBBQUAA4GBABByUqkFFBkyCEHwxWsKzH4PIRnN5GfcX6kb5sroc50i\\n\" +\n  \"2JhucwNhkcV8sEVAbkSdjbCxlnRhLQ2pRdKkkirWmnWXbj9T/UWZYB2oK0z5XqcJ\\n\" +\n  \"2HUw19JlYD1n1khVdWk/kfVIC0dpImmClr7JyDiGSnoscxlIaU5rfGW/D/xwzoiQ\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // VeriSign-PCA-3G2\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDAjCCAmsCEH3Z/gfPqB63EHln+6eJNMYwDQYJKoZIhvcNAQEFBQAwgcExCzAJ\\n\" +\n  \"BgNVBAYTAlVTMRcwFQYDVQQKEw5WZXJpU2lnbiwgSW5jLjE8MDoGA1UECxMzQ2xh\\n\" +\n  \"c3MgMyBQdWJsaWMgUHJpbWFyeSBDZXJ0aWZpY2F0aW9uIEF1dGhvcml0eSAtIEcy\\n\" +\n  \"MTowOAYDVQQLEzEoYykgMTk5OCBWZXJpU2lnbiwgSW5jLiAtIEZvciBhdXRob3Jp\\n\" +\n  \"emVkIHVzZSBvbmx5MR8wHQYDVQQLExZWZXJpU2lnbiBUcnVzdCBOZXR3b3JrMB4X\\n\" +\n  \"DTk4MDUxODAwMDAwMFoXDTI4MDgwMTIzNTk1OVowgcExCzAJBgNVBAYTAlVTMRcw\\n\" +\n  \"FQYDVQQKEw5WZXJpU2lnbiwgSW5jLjE8MDoGA1UECxMzQ2xhc3MgMyBQdWJsaWMg\\n\" +\n  \"UHJpbWFyeSBDZXJ0aWZpY2F0aW9uIEF1dGhvcml0eSAtIEcyMTowOAYDVQQLEzEo\\n\" +\n  \"YykgMTk5OCBWZXJpU2lnbiwgSW5jLiAtIEZvciBhdXRob3JpemVkIHVzZSBvbmx5\\n\" +\n  \"MR8wHQYDVQQLExZWZXJpU2lnbiBUcnVzdCBOZXR3b3JrMIGfMA0GCSqGSIb3DQEB\\n\" +\n  \"AQUAA4GNADCBiQKBgQDMXtERXVxp0KvTuWpMmR9ZmDCOFoUgRm1HP9SFIIThbbP4\\n\" +\n  \"pO0M8RcPO/mn+SXXwc+EY/J8Y8+iR/LGWzOOZEAEaMGAuWQcRXfH2G71lSk8UOg0\\n\" +\n  \"13gfqLptQ5GVj0VXXn7F+8qkBOvqlzdUMG+7AUcyM83cV5tkaWH4mx0ciU9cZwID\\n\" +\n  \"AQABMA0GCSqGSIb3DQEBBQUAA4GBAFFNzb5cy5gZnBWyATl4Lk0PZ3BwmcYQWpSk\\n\" +\n  \"U01UbSuvDV1Ai2TT1+7eVmGSX6bEHRBhNtMsJzzoKQm5EWR0zLVznxxIqbxhAe7i\\n\" +\n  \"F6YM40AIOw7n60RzKprxaZLvcRTDOaxxp5EJb+RxBrO6WVcmeQD2+A2iMzAo1KpY\\n\" +\n  \"oJ2daZH9\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // VeriSign-PCA-3G3\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIEGjCCAwICEQCbfgZJoz5iudXukEhxKe9XMA0GCSqGSIb3DQEBBQUAMIHKMQsw\\n\" +\n  \"CQYDVQQGEwJVUzEXMBUGA1UEChMOVmVyaVNpZ24sIEluYy4xHzAdBgNVBAsTFlZl\\n\" +\n  \"cmlTaWduIFRydXN0IE5ldHdvcmsxOjA4BgNVBAsTMShjKSAxOTk5IFZlcmlTaWdu\\n\" +\n  \"LCBJbmMuIC0gRm9yIGF1dGhvcml6ZWQgdXNlIG9ubHkxRTBDBgNVBAMTPFZlcmlT\\n\" +\n  \"aWduIENsYXNzIDMgUHVibGljIFByaW1hcnkgQ2VydGlmaWNhdGlvbiBBdXRob3Jp\\n\" +\n  \"dHkgLSBHMzAeFw05OTEwMDEwMDAwMDBaFw0zNjA3MTYyMzU5NTlaMIHKMQswCQYD\\n\" +\n  \"VQQGEwJVUzEXMBUGA1UEChMOVmVyaVNpZ24sIEluYy4xHzAdBgNVBAsTFlZlcmlT\\n\" +\n  \"aWduIFRydXN0IE5ldHdvcmsxOjA4BgNVBAsTMShjKSAxOTk5IFZlcmlTaWduLCBJ\\n\" +\n  \"bmMuIC0gRm9yIGF1dGhvcml6ZWQgdXNlIG9ubHkxRTBDBgNVBAMTPFZlcmlTaWdu\\n\" +\n  \"IENsYXNzIDMgUHVibGljIFByaW1hcnkgQ2VydGlmaWNhdGlvbiBBdXRob3JpdHkg\\n\" +\n  \"LSBHMzCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAMu6nFL8eB8aHm8b\\n\" +\n  \"N3O9+MlrlBIwT/A2R/XQkQr1F8ilYcEWQE37imGQ5XYgwREGfassbqb1EUGO+i2t\\n\" +\n  \"KmFZpGcmTNDovFJbcCAEWNF6yaRpvIMXZK0Fi7zQWM6NjPXr8EJJC52XJ2cybuGu\\n\" +\n  \"kxUccLwgTS8Y3pKI6GyFVxEa6X7jJhFUokWWVYPKMIno3Nij7SqAP395ZVc+FSBm\\n\" +\n  \"CC+Vk7+qRy+oRpfwEuL+wgorUeZ25rdGt+INpsyow0xZVYnm6FNcHOqd8GIWC6fJ\\n\" +\n  \"Xwzw3sJ2zq/3avL6QaaiMxTJ5Xpj055iN9WFZZ4O5lMkdBteHRJTW8cs54NJOxWu\\n\" +\n  \"imi5V5cCAwEAATANBgkqhkiG9w0BAQUFAAOCAQEAERSWwauSCPc/L8my/uRan2Te\\n\" +\n  \"2yFPhpk0djZX3dAVL8WtfxUfN2JzPtTnX84XA9s1+ivbrmAJXx5fj267Cz3qWhMe\\n\" +\n  \"DGBvtcC1IyIuBwvLqXTLR7sdwdela8wv0kL9Sd2nic9TutoAWii/gt/4uhMdUIaC\\n\" +\n  \"/Y4wjylGsB49Ndo4YhYYSq3mtlFs3q9i6wHQHiT+eo8SGhJouPtmmRQURVyu565p\\n\" +\n  \"F4ErWjfJXir0xuKhXFSbplQAz/DxwceYMBo7Nhbbo27q/a2ywtrvAkcTisDxszGt\\n\" +\n  \"TxzhT5yvDwyd93gN2PQ1VoDat20Xj50egWTh/sVFuq1ruQp6Tk9LhO5L8X3dEQ==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // VeriSign-PCA-3G4\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDhDCCAwqgAwIBAgIQL4D+I4wOIg9IZxIokYesszAKBggqhkjOPQQDAzCByjEL\\n\" +\n  \"MAkGA1UEBhMCVVMxFzAVBgNVBAoTDlZlcmlTaWduLCBJbmMuMR8wHQYDVQQLExZW\\n\" +\n  \"ZXJpU2lnbiBUcnVzdCBOZXR3b3JrMTowOAYDVQQLEzEoYykgMjAwNyBWZXJpU2ln\\n\" +\n  \"biwgSW5jLiAtIEZvciBhdXRob3JpemVkIHVzZSBvbmx5MUUwQwYDVQQDEzxWZXJp\\n\" +\n  \"U2lnbiBDbGFzcyAzIFB1YmxpYyBQcmltYXJ5IENlcnRpZmljYXRpb24gQXV0aG9y\\n\" +\n  \"aXR5IC0gRzQwHhcNMDcxMTA1MDAwMDAwWhcNMzgwMTE4MjM1OTU5WjCByjELMAkG\\n\" +\n  \"A1UEBhMCVVMxFzAVBgNVBAoTDlZlcmlTaWduLCBJbmMuMR8wHQYDVQQLExZWZXJp\\n\" +\n  \"U2lnbiBUcnVzdCBOZXR3b3JrMTowOAYDVQQLEzEoYykgMjAwNyBWZXJpU2lnbiwg\\n\" +\n  \"SW5jLiAtIEZvciBhdXRob3JpemVkIHVzZSBvbmx5MUUwQwYDVQQDEzxWZXJpU2ln\\n\" +\n  \"biBDbGFzcyAzIFB1YmxpYyBQcmltYXJ5IENlcnRpZmljYXRpb24gQXV0aG9yaXR5\\n\" +\n  \"IC0gRzQwdjAQBgcqhkjOPQIBBgUrgQQAIgNiAASnVnp8Utpkmw4tXNherJI9/gHm\\n\" +\n  \"GUo9FANL+mAnINmDiWn6VMaaGF5VKmTeBvaNSjutEDxlPZCIBIngMGGzrl0Bp3ve\\n\" +\n  \"fLK+ymVhAIau2o970ImtTR1ZmkGxvEeA3J5iw/mjgbIwga8wDwYDVR0TAQH/BAUw\\n\" +\n  \"AwEB/zAOBgNVHQ8BAf8EBAMCAQYwbQYIKwYBBQUHAQwEYTBfoV2gWzBZMFcwVRYJ\\n\" +\n  \"aW1hZ2UvZ2lmMCEwHzAHBgUrDgMCGgQUj+XTGoasjY5rw8+AatRIGCx7GS4wJRYj\\n\" +\n  \"aHR0cDovL2xvZ28udmVyaXNpZ24uY29tL3ZzbG9nby5naWYwHQYDVR0OBBYEFLMW\\n\" +\n  \"kf3upm7ktS5Jj4d4gYDs5bG1MAoGCCqGSM49BAMDA2gAMGUCMGYhDBgmYFo4e1ZC\\n\" +\n  \"4Kf8NoRRkSAsdk1DPcQdhCPQrNZ8NQbOzWm9kA3bbEhCHQ6qQgIxAJw9SDkjOVga\\n\" +\n  \"FRJZap7v1VmyHVIsmXHNxynfGyphe3HR3vPA5Q06Sqotp9iGKt0uEA==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // VeriSign-PCA-3G5\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIE0zCCA7ugAwIBAgIQGNrRniZ96LtKIVjNzGs7SjANBgkqhkiG9w0BAQUFADCB\\n\" +\n  \"yjELMAkGA1UEBhMCVVMxFzAVBgNVBAoTDlZlcmlTaWduLCBJbmMuMR8wHQYDVQQL\\n\" +\n  \"ExZWZXJpU2lnbiBUcnVzdCBOZXR3b3JrMTowOAYDVQQLEzEoYykgMjAwNiBWZXJp\\n\" +\n  \"U2lnbiwgSW5jLiAtIEZvciBhdXRob3JpemVkIHVzZSBvbmx5MUUwQwYDVQQDEzxW\\n\" +\n  \"ZXJpU2lnbiBDbGFzcyAzIFB1YmxpYyBQcmltYXJ5IENlcnRpZmljYXRpb24gQXV0\\n\" +\n  \"aG9yaXR5IC0gRzUwHhcNMDYxMTA4MDAwMDAwWhcNMzYwNzE2MjM1OTU5WjCByjEL\\n\" +\n  \"MAkGA1UEBhMCVVMxFzAVBgNVBAoTDlZlcmlTaWduLCBJbmMuMR8wHQYDVQQLExZW\\n\" +\n  \"ZXJpU2lnbiBUcnVzdCBOZXR3b3JrMTowOAYDVQQLEzEoYykgMjAwNiBWZXJpU2ln\\n\" +\n  \"biwgSW5jLiAtIEZvciBhdXRob3JpemVkIHVzZSBvbmx5MUUwQwYDVQQDEzxWZXJp\\n\" +\n  \"U2lnbiBDbGFzcyAzIFB1YmxpYyBQcmltYXJ5IENlcnRpZmljYXRpb24gQXV0aG9y\\n\" +\n  \"aXR5IC0gRzUwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCvJAgIKXo1\\n\" +\n  \"nmAMqudLO07cfLw8RRy7K+D+KQL5VwijZIUVJ/XxrcgxiV0i6CqqpkKzj/i5Vbex\\n\" +\n  \"t0uz/o9+B1fs70PbZmIVYc9gDaTY3vjgw2IIPVQT60nKWVSFJuUrjxuf6/WhkcIz\\n\" +\n  \"SdhDY2pSS9KP6HBRTdGJaXvHcPaz3BJ023tdS1bTlr8Vd6Gw9KIl8q8ckmcY5fQG\\n\" +\n  \"BO+QueQA5N06tRn/Arr0PO7gi+s3i+z016zy9vA9r911kTMZHRxAy3QkGSGT2RT+\\n\" +\n  \"rCpSx4/VBEnkjWNHiDxpg8v+R70rfk/Fla4OndTRQ8Bnc+MUCH7lP59zuDMKz10/\\n\" +\n  \"NIeWiu5T6CUVAgMBAAGjgbIwga8wDwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8E\\n\" +\n  \"BAMCAQYwbQYIKwYBBQUHAQwEYTBfoV2gWzBZMFcwVRYJaW1hZ2UvZ2lmMCEwHzAH\\n\" +\n  \"BgUrDgMCGgQUj+XTGoasjY5rw8+AatRIGCx7GS4wJRYjaHR0cDovL2xvZ28udmVy\\n\" +\n  \"aXNpZ24uY29tL3ZzbG9nby5naWYwHQYDVR0OBBYEFH/TZafC3ey78DAJ80M5+gKv\\n\" +\n  \"MzEzMA0GCSqGSIb3DQEBBQUAA4IBAQCTJEowX2LP2BqYLz3q3JktvXf2pXkiOOzE\\n\" +\n  \"p6B4Eq1iDkVwZMXnl2YtmAl+X6/WzChl8gGqCBpH3vn5fJJaCGkgDdk+bW48DW7Y\\n\" +\n  \"5gaRQBi5+MHt39tBquCWIMnNZBU4gcmU7qKEKQsTb47bDN0lAtukixlE0kF6BWlK\\n\" +\n  \"WE9gyn6CagsCqiUXObXbf+eEZSqVir2G3l6BFoMtEMze/aiCKm0oHw0LxOXnGiYZ\\n\" +\n  \"4fQRbxC1lfznQgUy286dUV4otp6F01vvpX1FQHKOtw5rDgb7MzVIcbidJ4vEZV8N\\n\" +\n  \"hnacRHr2lVz2XTIIM6RUthg/aFzyQkqFOFSDX9HoLPKsEdao7WNq\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // VeriSign-PCA-4G3\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIEGjCCAwICEQDsoKeLbnVqAc/EfMwvlF7XMA0GCSqGSIb3DQEBBQUAMIHKMQsw\\n\" +\n  \"CQYDVQQGEwJVUzEXMBUGA1UEChMOVmVyaVNpZ24sIEluYy4xHzAdBgNVBAsTFlZl\\n\" +\n  \"cmlTaWduIFRydXN0IE5ldHdvcmsxOjA4BgNVBAsTMShjKSAxOTk5IFZlcmlTaWdu\\n\" +\n  \"LCBJbmMuIC0gRm9yIGF1dGhvcml6ZWQgdXNlIG9ubHkxRTBDBgNVBAMTPFZlcmlT\\n\" +\n  \"aWduIENsYXNzIDQgUHVibGljIFByaW1hcnkgQ2VydGlmaWNhdGlvbiBBdXRob3Jp\\n\" +\n  \"dHkgLSBHMzAeFw05OTEwMDEwMDAwMDBaFw0zNjA3MTYyMzU5NTlaMIHKMQswCQYD\\n\" +\n  \"VQQGEwJVUzEXMBUGA1UEChMOVmVyaVNpZ24sIEluYy4xHzAdBgNVBAsTFlZlcmlT\\n\" +\n  \"aWduIFRydXN0IE5ldHdvcmsxOjA4BgNVBAsTMShjKSAxOTk5IFZlcmlTaWduLCBJ\\n\" +\n  \"bmMuIC0gRm9yIGF1dGhvcml6ZWQgdXNlIG9ubHkxRTBDBgNVBAMTPFZlcmlTaWdu\\n\" +\n  \"IENsYXNzIDQgUHVibGljIFByaW1hcnkgQ2VydGlmaWNhdGlvbiBBdXRob3JpdHkg\\n\" +\n  \"LSBHMzCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAK3LpRFpxlmr8Y+1\\n\" +\n  \"GQ9Wzsy1HyDkniYlS+BzZYlZ3tCD5PUPtbut8XzoIfzk6AzufEUiGXaStBO3IFsJ\\n\" +\n  \"+mGuqPKljYXCKtbeZjbSmwL0qJJgfJxptI8kHtCGUvYynEFYHiK9zUVilQhu0Gbd\\n\" +\n  \"U6LM8BDcVHOLBKFGMzNcF0C5nk3T875Vg+ixiY5afJqWIpA7iCXy0lOIAgwLePLm\\n\" +\n  \"NxdLMEYH5IBtptiWLugs+BGzOA1mppvqySNb247i8xOOGlktqgLw7KSHZtzBP/XY\\n\" +\n  \"ufTsgsbSPZUd5cBPhMnZo0QoBmrXRazwa2rvTl/4EYIeOGM0ZlDUPpNz+jDDZq3/\\n\" +\n  \"ky2X7wMCAwEAATANBgkqhkiG9w0BAQUFAAOCAQEAj/ola09b5KROJ1WrIhVZPMq1\\n\" +\n  \"CtRK26vdoV9TxaBXOcLORyu+OshWv8LZJxA6sQU8wHcxuzrTBXttmhwwjIDLk5Mq\\n\" +\n  \"g6sFUYICABFna/OIYUdfA5PVWw3g8dShMjWFsjrbsIKr0csKvE+MW8VLADsfKoKm\\n\" +\n  \"fjaF3H48ZwC15DtS4KjrXRX5xm3wrR0OhbepmnMUWluPQSjA1egtTaRezarZ7c7c\\n\" +\n  \"2NU8Qh0XwRJdRTjDOPP8hS6DRkiy1yBfkjaP53kPmF6Z6PDQpLv1U70qzlmwr25/\\n\" +\n  \"bLvSHgCwIe34QWKCudiyxLtGUPMxxY8BqHTr9Xgn2uf3ZkPznoM+IKrDNWCRzg==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // VeriSign-PCA-universal\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIEuTCCA6GgAwIBAgIQQBrEZCGzEyEDDrvkEhrFHTANBgkqhkiG9w0BAQsFADCB\\n\" +\n  \"vTELMAkGA1UEBhMCVVMxFzAVBgNVBAoTDlZlcmlTaWduLCBJbmMuMR8wHQYDVQQL\\n\" +\n  \"ExZWZXJpU2lnbiBUcnVzdCBOZXR3b3JrMTowOAYDVQQLEzEoYykgMjAwOCBWZXJp\\n\" +\n  \"U2lnbiwgSW5jLiAtIEZvciBhdXRob3JpemVkIHVzZSBvbmx5MTgwNgYDVQQDEy9W\\n\" +\n  \"ZXJpU2lnbiBVbml2ZXJzYWwgUm9vdCBDZXJ0aWZpY2F0aW9uIEF1dGhvcml0eTAe\\n\" +\n  \"Fw0wODA0MDIwMDAwMDBaFw0zNzEyMDEyMzU5NTlaMIG9MQswCQYDVQQGEwJVUzEX\\n\" +\n  \"MBUGA1UEChMOVmVyaVNpZ24sIEluYy4xHzAdBgNVBAsTFlZlcmlTaWduIFRydXN0\\n\" +\n  \"IE5ldHdvcmsxOjA4BgNVBAsTMShjKSAyMDA4IFZlcmlTaWduLCBJbmMuIC0gRm9y\\n\" +\n  \"IGF1dGhvcml6ZWQgdXNlIG9ubHkxODA2BgNVBAMTL1ZlcmlTaWduIFVuaXZlcnNh\\n\" +\n  \"bCBSb290IENlcnRpZmljYXRpb24gQXV0aG9yaXR5MIIBIjANBgkqhkiG9w0BAQEF\\n\" +\n  \"AAOCAQ8AMIIBCgKCAQEAx2E3XrEBNNti1xWb/1hajCMj1mCOkdeQmIN65lgZOIzF\\n\" +\n  \"9uVkhbSicfvtvbnazU0AtMgtc6XHaXGVHzk8skQHnOgO+k1KxCHfKWGPMiJhgsWH\\n\" +\n  \"H26MfF8WIFFE0XBPV+rjHOPMee5Y2A7Cs0WTwCznmhcrewA3ekEzeOEz4vMQGn+H\\n\" +\n  \"LL729fdC4uW/h2KJXwBL38Xd5HVEMkE6HnFuacsLdUYI0crSK5XQz/u5QGtkjFdN\\n\" +\n  \"/BMReYTtXlT2NJ8IAfMQJQYXStrxHXpma5hgZqTZ79IugvHw7wnqRMkVauIDbjPT\\n\" +\n  \"rJ9VAMf2CGqUuV/c4DPxhGD5WycRtPwW8rtWaoAljQIDAQABo4GyMIGvMA8GA1Ud\\n\" +\n  \"EwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMG0GCCsGAQUFBwEMBGEwX6FdoFsw\\n\" +\n  \"WTBXMFUWCWltYWdlL2dpZjAhMB8wBwYFKw4DAhoEFI/l0xqGrI2Oa8PPgGrUSBgs\\n\" +\n  \"exkuMCUWI2h0dHA6Ly9sb2dvLnZlcmlzaWduLmNvbS92c2xvZ28uZ2lmMB0GA1Ud\\n\" +\n  \"DgQWBBS2d/ppSEefUxLVwuoHMnYH0ZcHGTANBgkqhkiG9w0BAQsFAAOCAQEASvj4\\n\" +\n  \"sAPmLGd75JR3Y8xuTPl9Dg3cyLk1uXBPY/ok+myDjEedO2Pzmvl2MpWRsXe8rJq+\\n\" +\n  \"seQxIcaBlVZaDrHC1LGmWazxY8u4TB1ZkErvkBYoH1quEPuBUDgMbMzxPcP1Y+Oz\\n\" +\n  \"4yHJJDnp/RVmRvQbEdBNc6N9Rvk97ahfYtTxP/jgdFcrGJ2BtMQo2pSXpXDrrB2+\\n\" +\n  \"BxHw1dvd5Yzw1TKwg+ZX4o+/vqGqvz0dtdQ46tewXDpPaj+PwGZsY6rp2aQW9IHR\\n\" +\n  \"lRQOfc2VNNnSj3BzgXucfr2YYdhFh5iQxeuGMMY1v/D/w1WIg0vvBZIGcfK4mJO3\\n\" +\n  \"7M2CYfE45k+XmCpajQ==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // gd-class2-root\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIEADCCAuigAwIBAgIBADANBgkqhkiG9w0BAQUFADBjMQswCQYDVQQGEwJVUzEh\\n\" +\n  \"MB8GA1UEChMYVGhlIEdvIERhZGR5IEdyb3VwLCBJbmMuMTEwLwYDVQQLEyhHbyBE\\n\" +\n  \"YWRkeSBDbGFzcyAyIENlcnRpZmljYXRpb24gQXV0aG9yaXR5MB4XDTA0MDYyOTE3\\n\" +\n  \"MDYyMFoXDTM0MDYyOTE3MDYyMFowYzELMAkGA1UEBhMCVVMxITAfBgNVBAoTGFRo\\n\" +\n  \"ZSBHbyBEYWRkeSBHcm91cCwgSW5jLjExMC8GA1UECxMoR28gRGFkZHkgQ2xhc3Mg\\n\" +\n  \"MiBDZXJ0aWZpY2F0aW9uIEF1dGhvcml0eTCCASAwDQYJKoZIhvcNAQEBBQADggEN\\n\" +\n  \"ADCCAQgCggEBAN6d1+pXGEmhW+vXX0iG6r7d/+TvZxz0ZWizV3GgXne77ZtJ6XCA\\n\" +\n  \"PVYYYwhv2vLM0D9/AlQiVBDYsoHUwHU9S3/Hd8M+eKsaA7Ugay9qK7HFiH7Eux6w\\n\" +\n  \"wdhFJ2+qN1j3hybX2C32qRe3H3I2TqYXP2WYktsqbl2i/ojgC95/5Y0V4evLOtXi\\n\" +\n  \"EqITLdiOr18SPaAIBQi2XKVlOARFmR6jYGB0xUGlcmIbYsUfb18aQr4CUWWoriMY\\n\" +\n  \"avx4A6lNf4DD+qta/KFApMoZFv6yyO9ecw3ud72a9nmYvLEHZ6IVDd2gWMZEewo+\\n\" +\n  \"YihfukEHU1jPEX44dMX4/7VpkI+EdOqXG68CAQOjgcAwgb0wHQYDVR0OBBYEFNLE\\n\" +\n  \"sNKR1EwRcbNhyz2h/t2oatTjMIGNBgNVHSMEgYUwgYKAFNLEsNKR1EwRcbNhyz2h\\n\" +\n  \"/t2oatTjoWekZTBjMQswCQYDVQQGEwJVUzEhMB8GA1UEChMYVGhlIEdvIERhZGR5\\n\" +\n  \"IEdyb3VwLCBJbmMuMTEwLwYDVQQLEyhHbyBEYWRkeSBDbGFzcyAyIENlcnRpZmlj\\n\" +\n  \"YXRpb24gQXV0aG9yaXR5ggEAMAwGA1UdEwQFMAMBAf8wDQYJKoZIhvcNAQEFBQAD\\n\" +\n  \"ggEBADJL87LKPpH8EsahB4yOd6AzBhRckB4Y9wimPQoZ+YeAEW5p5JYXMP80kWNy\\n\" +\n  \"OO7MHAGjHZQopDH2esRU1/blMVgDoszOYtuURXO1v0XJJLXVggKtI3lpjbi2Tc7P\\n\" +\n  \"TMozI+gciKqdi0FuFskg5YmezTvacPd+mSYgFFQlq25zheabIZ0KbIIOqPjCDPoQ\\n\" +\n  \"HmyW74cNxA9hi63ugyuV+I6ShHI56yDqg+2DzZduCLzrTia2cyvk0/ZM/iZx4mER\\n\" +\n  \"dEr/VxqHD3VILs9RaRegAhJhldXRQLIQTO7ErBBDpqWeCtWVYpoNz4iCxTIM5Cuf\\n\" +\n  \"ReYNnyicsbkqWletNw+vHX/bvZ8=\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // gdroot-g2\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDxTCCAq2gAwIBAgIBADANBgkqhkiG9w0BAQsFADCBgzELMAkGA1UEBhMCVVMx\\n\" +\n  \"EDAOBgNVBAgTB0FyaXpvbmExEzARBgNVBAcTClNjb3R0c2RhbGUxGjAYBgNVBAoT\\n\" +\n  \"EUdvRGFkZHkuY29tLCBJbmMuMTEwLwYDVQQDEyhHbyBEYWRkeSBSb290IENlcnRp\\n\" +\n  \"ZmljYXRlIEF1dGhvcml0eSAtIEcyMB4XDTA5MDkwMTAwMDAwMFoXDTM3MTIzMTIz\\n\" +\n  \"NTk1OVowgYMxCzAJBgNVBAYTAlVTMRAwDgYDVQQIEwdBcml6b25hMRMwEQYDVQQH\\n\" +\n  \"EwpTY290dHNkYWxlMRowGAYDVQQKExFHb0RhZGR5LmNvbSwgSW5jLjExMC8GA1UE\\n\" +\n  \"AxMoR28gRGFkZHkgUm9vdCBDZXJ0aWZpY2F0ZSBBdXRob3JpdHkgLSBHMjCCASIw\\n\" +\n  \"DQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAL9xYgjx+lk09xvJGKP3gElY6SKD\\n\" +\n  \"E6bFIEMBO4Tx5oVJnyfq9oQbTqC023CYxzIBsQU+B07u9PpPL1kwIuerGVZr4oAH\\n\" +\n  \"/PMWdYA5UXvl+TW2dE6pjYIT5LY/qQOD+qK+ihVqf94Lw7YZFAXK6sOoBJQ7Rnwy\\n\" +\n  \"DfMAZiLIjWltNowRGLfTshxgtDj6AozO091GB94KPutdfMh8+7ArU6SSYmlRJQVh\\n\" +\n  \"GkSBjCypQ5Yj36w6gZoOKcUcqeldHraenjAKOc7xiID7S13MMuyFYkMlNAJWJwGR\\n\" +\n  \"tDtwKj9useiciAF9n9T521NtYJ2/LOdYq7hfRvzOxBsDPAnrSTFcaUaz4EcCAwEA\\n\" +\n  \"AaNCMEAwDwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAQYwHQYDVR0OBBYE\\n\" +\n  \"FDqahQcQZyi27/a9BUFuIMGU2g/eMA0GCSqGSIb3DQEBCwUAA4IBAQCZ21151fmX\\n\" +\n  \"WWcDYfF+OwYxdS2hII5PZYe096acvNjpL9DbWu7PdIxztDhC2gV7+AJ1uP2lsdeu\\n\" +\n  \"9tfeE8tTEH6KRtGX+rcuKxGrkLAngPnon1rpN5+r5N9ss4UXnT3ZJE95kTXWXwTr\\n\" +\n  \"gIOrmgIttRD02JDHBHNA7XIloKmf7J6raBKZV8aPEjoJpL1E/QYVN8Gb5DKj7Tjo\\n\" +\n  \"2GTzLH4U/ALqn83/B2gX2yKQOC16jdFU8WnjXzPKej17CuPKf1855eJ1usV2GDPO\\n\" +\n  \"LPAvTK33sefOT6jEm0pUBsV/fdUID+Ic/n4XuKxe9tQWskMJDE32p2u0mYRlynqI\\n\" +\n  \"4uJEvlz36hz1\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // sf-class2-root\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIEDzCCAvegAwIBAgIBADANBgkqhkiG9w0BAQUFADBoMQswCQYDVQQGEwJVUzEl\\n\" +\n  \"MCMGA1UEChMcU3RhcmZpZWxkIFRlY2hub2xvZ2llcywgSW5jLjEyMDAGA1UECxMp\\n\" +\n  \"U3RhcmZpZWxkIENsYXNzIDIgQ2VydGlmaWNhdGlvbiBBdXRob3JpdHkwHhcNMDQw\\n\" +\n  \"NjI5MTczOTE2WhcNMzQwNjI5MTczOTE2WjBoMQswCQYDVQQGEwJVUzElMCMGA1UE\\n\" +\n  \"ChMcU3RhcmZpZWxkIFRlY2hub2xvZ2llcywgSW5jLjEyMDAGA1UECxMpU3RhcmZp\\n\" +\n  \"ZWxkIENsYXNzIDIgQ2VydGlmaWNhdGlvbiBBdXRob3JpdHkwggEgMA0GCSqGSIb3\\n\" +\n  \"DQEBAQUAA4IBDQAwggEIAoIBAQC3Msj+6XGmBIWtDBFk385N78gDGIc/oav7PKaf\\n\" +\n  \"8MOh2tTYbitTkPskpD6E8J7oX+zlJ0T1KKY/e97gKvDIr1MvnsoFAZMej2YcOadN\\n\" +\n  \"+lq2cwQlZut3f+dZxkqZJRRU6ybH838Z1TBwj6+wRir/resp7defqgSHo9T5iaU0\\n\" +\n  \"X9tDkYI22WY8sbi5gv2cOj4QyDvvBmVmepsZGD3/cVE8MC5fvj13c7JdBmzDI1aa\\n\" +\n  \"K4UmkhynArPkPw2vCHmCuDY96pzTNbO8acr1zJ3o/WSNF4Azbl5KXZnJHoe0nRrA\\n\" +\n  \"1W4TNSNe35tfPe/W93bC6j67eA0cQmdrBNj41tpvi/JEoAGrAgEDo4HFMIHCMB0G\\n\" +\n  \"A1UdDgQWBBS/X7fRzt0fhvRbVazc1xDCDqmI5zCBkgYDVR0jBIGKMIGHgBS/X7fR\\n\" +\n  \"zt0fhvRbVazc1xDCDqmI56FspGowaDELMAkGA1UEBhMCVVMxJTAjBgNVBAoTHFN0\\n\" +\n  \"YXJmaWVsZCBUZWNobm9sb2dpZXMsIEluYy4xMjAwBgNVBAsTKVN0YXJmaWVsZCBD\\n\" +\n  \"bGFzcyAyIENlcnRpZmljYXRpb24gQXV0aG9yaXR5ggEAMAwGA1UdEwQFMAMBAf8w\\n\" +\n  \"DQYJKoZIhvcNAQEFBQADggEBAAWdP4id0ckaVaGsafPzWdqbAYcaT1epoXkJKtv3\\n\" +\n  \"L7IezMdeatiDh6GX70k1PncGQVhiv45YuApnP+yz3SFmH8lU+nLMPUxA2IGvd56D\\n\" +\n  \"eruix/U0F47ZEUD0/CwqTRV/p2JdLiXTAAsgGh1o+Re49L2L7ShZ3U0WixeDyLJl\\n\" +\n  \"xy16paq8U4Zt3VekyvggQQto8PT7dL5WXXp59fkdheMtlb71cZBDzI0fmgAKhynp\\n\" +\n  \"VSJYACPq4xJDKVtHCN2MQWplBqjlIapBtJUhlbl90TSrE9atvNziPTnNvT51cKEY\\n\" +\n  \"WQPJIrSPnNVeKtelttQKbfi3QBFGmh95DmK/D5fs4C8fF5Q=\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // sfroot-g2\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIID3TCCAsWgAwIBAgIBADANBgkqhkiG9w0BAQsFADCBjzELMAkGA1UEBhMCVVMx\\n\" +\n  \"EDAOBgNVBAgTB0FyaXpvbmExEzARBgNVBAcTClNjb3R0c2RhbGUxJTAjBgNVBAoT\\n\" +\n  \"HFN0YXJmaWVsZCBUZWNobm9sb2dpZXMsIEluYy4xMjAwBgNVBAMTKVN0YXJmaWVs\\n\" +\n  \"ZCBSb290IENlcnRpZmljYXRlIEF1dGhvcml0eSAtIEcyMB4XDTA5MDkwMTAwMDAw\\n\" +\n  \"MFoXDTM3MTIzMTIzNTk1OVowgY8xCzAJBgNVBAYTAlVTMRAwDgYDVQQIEwdBcml6\\n\" +\n  \"b25hMRMwEQYDVQQHEwpTY290dHNkYWxlMSUwIwYDVQQKExxTdGFyZmllbGQgVGVj\\n\" +\n  \"aG5vbG9naWVzLCBJbmMuMTIwMAYDVQQDEylTdGFyZmllbGQgUm9vdCBDZXJ0aWZp\\n\" +\n  \"Y2F0ZSBBdXRob3JpdHkgLSBHMjCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoC\\n\" +\n  \"ggEBAL3twQP89o/8ArFvW59I2Z154qK3A2FWGMNHttfKPTUuiUP3oWmb3ooa/RMg\\n\" +\n  \"nLRJdzIpVv257IzdIvpy3Cdhl+72WoTsbhm5iSzchFvVdPtrX8WJpRBSiUZV9Lh1\\n\" +\n  \"HOZ/5FSuS/hVclcCGfgXcVnrHigHdMWdSL5stPSksPNkN3mSwOxGXn/hbVNMYq/N\\n\" +\n  \"Hwtjuzqd+/x5AJhhdM8mgkBj87JyahkNmcrUDnXMN/uLicFZ8WJ/X7NfZTD4p7dN\\n\" +\n  \"dloedl40wOiWVpmKs/B/pM293DIxfJHP4F8R+GuqSVzRmZTRouNjWwl2tVZi4Ut0\\n\" +\n  \"HZbUJtQIBFnQmA4O5t78w+wfkPECAwEAAaNCMEAwDwYDVR0TAQH/BAUwAwEB/zAO\\n\" +\n  \"BgNVHQ8BAf8EBAMCAQYwHQYDVR0OBBYEFHwMMh+n2TB/xH1oo2Kooc6rB1snMA0G\\n\" +\n  \"CSqGSIb3DQEBCwUAA4IBAQARWfolTwNvlJk7mh+ChTnUdgWUXuEok21iXQnCoKjU\\n\" +\n  \"sHU48TRqneSfioYmUeYs0cYtbpUgSpIB7LiKZ3sx4mcujJUDJi5DnUox9g61DLu3\\n\" +\n  \"4jd/IroAow57UvtruzvE03lRTs2Q9GcHGcg8RnoNAX3FWOdt5oUwF5okxBDgBPfg\\n\" +\n  \"8n/Uqgr/Qh037ZTlZFkSIHc40zI+OIF1lnP6aI+xy84fxez6nH7PfrHxBy22/L/K\\n\" +\n  \"pL/QlwVKvOoYKAKQvVR4CSFx09F9HdkWsKlhPdAKACL8x3vLCWRFCztAgfd9fDL1\\n\" +\n  \"mMpYjn0q7pBZc2T5NnReJaH1ZgUufzkVqSr7UIuOhWn0\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // sfsroot-g2\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIID7zCCAtegAwIBAgIBADANBgkqhkiG9w0BAQsFADCBmDELMAkGA1UEBhMCVVMx\\n\" +\n  \"EDAOBgNVBAgTB0FyaXpvbmExEzARBgNVBAcTClNjb3R0c2RhbGUxJTAjBgNVBAoT\\n\" +\n  \"HFN0YXJmaWVsZCBUZWNobm9sb2dpZXMsIEluYy4xOzA5BgNVBAMTMlN0YXJmaWVs\\n\" +\n  \"ZCBTZXJ2aWNlcyBSb290IENlcnRpZmljYXRlIEF1dGhvcml0eSAtIEcyMB4XDTA5\\n\" +\n  \"MDkwMTAwMDAwMFoXDTM3MTIzMTIzNTk1OVowgZgxCzAJBgNVBAYTAlVTMRAwDgYD\\n\" +\n  \"VQQIEwdBcml6b25hMRMwEQYDVQQHEwpTY290dHNkYWxlMSUwIwYDVQQKExxTdGFy\\n\" +\n  \"ZmllbGQgVGVjaG5vbG9naWVzLCBJbmMuMTswOQYDVQQDEzJTdGFyZmllbGQgU2Vy\\n\" +\n  \"dmljZXMgUm9vdCBDZXJ0aWZpY2F0ZSBBdXRob3JpdHkgLSBHMjCCASIwDQYJKoZI\\n\" +\n  \"hvcNAQEBBQADggEPADCCAQoCggEBANUMOsQq+U7i9b4Zl1+OiFOxHz/Lz58gE20p\\n\" +\n  \"OsgPfTz3a3Y4Y9k2YKibXlwAgLIvWX/2h/klQ4bnaRtSmpDhcePYLQ1Ob/bISdm2\\n\" +\n  \"8xpWriu2dBTrz/sm4xq6HZYuajtYlIlHVv8loJNwU4PahHQUw2eeBGg6345AWh1K\\n\" +\n  \"Ts9DkTvnVtYAcMtS7nt9rjrnvDH5RfbCYM8TWQIrgMw0R9+53pBlbQLPLJGmpufe\\n\" +\n  \"hRhJfGZOozptqbXuNC66DQO4M99H67FrjSXZm86B0UVGMpZwh94CDklDhbZsc7tk\\n\" +\n  \"6mFBrMnUVN+HL8cisibMn1lUaJ/8viovxFUcdUBgF4UCVTmLfwUCAwEAAaNCMEAw\\n\" +\n  \"DwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAQYwHQYDVR0OBBYEFJxfAN+q\\n\" +\n  \"AdcwKziIorhtSpzyEZGDMA0GCSqGSIb3DQEBCwUAA4IBAQBLNqaEd2ndOxmfZyMI\\n\" +\n  \"bw5hyf2E3F/YNoHN2BtBLZ9g3ccaaNnRbobhiCPPE95Dz+I0swSdHynVv/heyNXB\\n\" +\n  \"ve6SbzJ08pGCL72CQnqtKrcgfU28elUSwhXqvfdqlS5sdJ/PHLTyxQGjhdByPq1z\\n\" +\n  \"qwubdQxtRbeOlKyWN7Wg0I8VRw7j6IPdj/3vQQF3zCepYoUz8jcI73HPdwbeyBkd\\n\" +\n  \"iEDPfUYd/x7H4c7/I9vG+o1VTqkC50cRRj70/b17KSa7qWFiNyi2LSr2EIZkyXCn\\n\" +\n  \"0q23KXB56jzaYyWf/Wi3MOxw+3WKt21gZ7IeyLnp2KhvAotnDU0mV3HaIPzBSlCN\\n\" +\n  \"sSi6\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // sfsroot\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIEfjCCA2agAwIBAgIBADANBgkqhkiG9w0BAQUFADCBzzELMAkGA1UEBhMCVVMx\\n\" +\n  \"EDAOBgNVBAgTB0FyaXpvbmExEzARBgNVBAcTClNjb3R0c2RhbGUxJTAjBgNVBAoT\\n\" +\n  \"HFN0YXJmaWVsZCBUZWNobm9sb2dpZXMsIEluYy4xOjA4BgNVBAsTMWh0dHA6Ly9j\\n\" +\n  \"ZXJ0aWZpY2F0ZXMuc3RhcmZpZWxkdGVjaC5jb20vcmVwb3NpdG9yeS8xNjA0BgNV\\n\" +\n  \"BAMTLVN0YXJmaWVsZCBTZXJ2aWNlcyBSb290IENlcnRpZmljYXRlIEF1dGhvcml0\\n\" +\n  \"eTAeFw0wODA2MDIwMDAwMDBaFw0yOTEyMzEyMzU5NTlaMIHPMQswCQYDVQQGEwJV\\n\" +\n  \"UzEQMA4GA1UECBMHQXJpem9uYTETMBEGA1UEBxMKU2NvdHRzZGFsZTElMCMGA1UE\\n\" +\n  \"ChMcU3RhcmZpZWxkIFRlY2hub2xvZ2llcywgSW5jLjE6MDgGA1UECxMxaHR0cDov\\n\" +\n  \"L2NlcnRpZmljYXRlcy5zdGFyZmllbGR0ZWNoLmNvbS9yZXBvc2l0b3J5LzE2MDQG\\n\" +\n  \"A1UEAxMtU3RhcmZpZWxkIFNlcnZpY2VzIFJvb3QgQ2VydGlmaWNhdGUgQXV0aG9y\\n\" +\n  \"aXR5MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA8sxWKk3mFjdal+pt\\n\" +\n  \"NTjREJvbuNypBAmVMy4JxQB7GnhCj8j0BY7+0miDHk6ZzRfbRz5Q84nS59yY+wX4\\n\" +\n  \"qtZj9FRNwXEDsB8bdrMaNDBz8SgyYIP9tJzXttIiN3wZqjveExBpblwG02+j8mZa\\n\" +\n  \"dkJIr4DRVFk91LnU2+25qzmZ9O5iq+F4cnvYOI1AtszcEgBwQ4Vp2Bjjyldyn7Tf\\n\" +\n  \"P/wiqEJS9XdbmfBWLSZwFjYSwieeV6Z80CPxedyjk1goOD2frTZD7jf7+PlDrchW\\n\" +\n  \"8pQSXkLrc7gTDcum1Ya5qihqVAOhPw8p6wkA6D9eon8XPaEr+L7QdR2khOOrF2UG\\n\" +\n  \"UgCvsQIDAQABo2MwYTAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIBBjAd\\n\" +\n  \"BgNVHQ4EFgQUtMZ/GkPMm3VdL8RL8ouYEOnxURAwHwYDVR0jBBgwFoAUtMZ/GkPM\\n\" +\n  \"m3VdL8RL8ouYEOnxURAwDQYJKoZIhvcNAQEFBQADggEBAKyAu8QlBQtYpOR+KX6v\\n\" +\n  \"vDvsLcBELvmR4NI7MieQLfaACVzCq2Uk2jgQRsRJ0v2aqyhId4jG6W/RR5HVNU8U\\n\" +\n  \"CahbQAcdfHFWy4lC1L9hwCL3Lt+r83JDi0DolOuwJtrRE9Or0DYtLjqVs3cuFTkY\\n\" +\n  \"DGm6qoDt8VNOM5toBOKgMC7X0V3UpmadhObnuzyJuzad/BepPVUrivubxEyE/9/S\\n\" +\n  \"vmkbdLCo9uqwnLIpdIFMaDqaf3MlOfUT4GaRadRXS7furUXgLMOI076USYkf/3DV\\n\" +\n  \"W205E7Ady5jmZ2MNY/b7w9dhcoOIP3B+U8meiVTWT399cbmu8WCLd2Ds+L/6aqOc\\n\" +\n  \"ASI=\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // thawte_Premium_Server_CA\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDNjCCAp+gAwIBAgIQNhIilsXjOKUgodJfTNcJVDANBgkqhkiG9w0BAQUFADCB\\n\" +\n  \"zjELMAkGA1UEBhMCWkExFTATBgNVBAgTDFdlc3Rlcm4gQ2FwZTESMBAGA1UEBxMJ\\n\" +\n  \"Q2FwZSBUb3duMR0wGwYDVQQKExRUaGF3dGUgQ29uc3VsdGluZyBjYzEoMCYGA1UE\\n\" +\n  \"CxMfQ2VydGlmaWNhdGlvbiBTZXJ2aWNlcyBEaXZpc2lvbjEhMB8GA1UEAxMYVGhh\\n\" +\n  \"d3RlIFByZW1pdW0gU2VydmVyIENBMSgwJgYJKoZIhvcNAQkBFhlwcmVtaXVtLXNl\\n\" +\n  \"cnZlckB0aGF3dGUuY29tMB4XDTk2MDgwMTAwMDAwMFoXDTIxMDEwMTIzNTk1OVow\\n\" +\n  \"gc4xCzAJBgNVBAYTAlpBMRUwEwYDVQQIEwxXZXN0ZXJuIENhcGUxEjAQBgNVBAcT\\n\" +\n  \"CUNhcGUgVG93bjEdMBsGA1UEChMUVGhhd3RlIENvbnN1bHRpbmcgY2MxKDAmBgNV\\n\" +\n  \"BAsTH0NlcnRpZmljYXRpb24gU2VydmljZXMgRGl2aXNpb24xITAfBgNVBAMTGFRo\\n\" +\n  \"YXd0ZSBQcmVtaXVtIFNlcnZlciBDQTEoMCYGCSqGSIb3DQEJARYZcHJlbWl1bS1z\\n\" +\n  \"ZXJ2ZXJAdGhhd3RlLmNvbTCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEA0jY2\\n\" +\n  \"aovXwlue2oFBYo847kkEVdbQ7xwblRZH7xhINTpS9CtqBo87L+pW46+GjZ4X9560\\n\" +\n  \"ZXUCTe/LCaIhUdib0GfQug2SBhRz1JPLlyoAnFxODLz6FVL88kRu2hFKbgifLy3j\\n\" +\n  \"+ao6hnO2RlNYyIkFvYMRuHM/qgeN9EJN50CdHDcCAwEAAaMTMBEwDwYDVR0TAQH/\\n\" +\n  \"BAUwAwEB/zANBgkqhkiG9w0BAQUFAAOBgQBlkKyID1bZ5jA01CbH0FDxkt5r1DmI\\n\" +\n  \"CSLGpmODA/eZd9iy5Ri4XWPz1HP7bJyZePFLeH0ZJMMrAoT4vCLZiiLXoPxx7JGH\\n\" +\n  \"IPG47LHlVYCsPVLIOQ7C8MAFT9aCdYy9X9LcdpoFEsmvcsPcJX6kTY4XpeCHf+Ga\\n\" +\n  \"WuFg3GQjPEIuTQ==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // thawte_Primary_Root_CA-G2_ECC\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIICiDCCAg2gAwIBAgIQNfwmXNmET8k9Jj1Xm67XVjAKBggqhkjOPQQDAzCBhDEL\\n\" +\n  \"MAkGA1UEBhMCVVMxFTATBgNVBAoTDHRoYXd0ZSwgSW5jLjE4MDYGA1UECxMvKGMp\\n\" +\n  \"IDIwMDcgdGhhd3RlLCBJbmMuIC0gRm9yIGF1dGhvcml6ZWQgdXNlIG9ubHkxJDAi\\n\" +\n  \"BgNVBAMTG3RoYXd0ZSBQcmltYXJ5IFJvb3QgQ0EgLSBHMjAeFw0wNzExMDUwMDAw\\n\" +\n  \"MDBaFw0zODAxMTgyMzU5NTlaMIGEMQswCQYDVQQGEwJVUzEVMBMGA1UEChMMdGhh\\n\" +\n  \"d3RlLCBJbmMuMTgwNgYDVQQLEy8oYykgMjAwNyB0aGF3dGUsIEluYy4gLSBGb3Ig\\n\" +\n  \"YXV0aG9yaXplZCB1c2Ugb25seTEkMCIGA1UEAxMbdGhhd3RlIFByaW1hcnkgUm9v\\n\" +\n  \"dCBDQSAtIEcyMHYwEAYHKoZIzj0CAQYFK4EEACIDYgAEotWcgnuVnfFSeIf+iha/\\n\" +\n  \"BebfowJPDQfGAFG6DAJSLSKkQjnE/o/qycG+1E3/n3qe4rF8mq2nhglzh9HnmuN6\\n\" +\n  \"papu+7qzcMBniKI11KOasf2twu8x+qi58/sIxpHR+ymVo0IwQDAPBgNVHRMBAf8E\\n\" +\n  \"BTADAQH/MA4GA1UdDwEB/wQEAwIBBjAdBgNVHQ4EFgQUmtgAMADna3+FGO6Lts6K\\n\" +\n  \"DPgR4bswCgYIKoZIzj0EAwMDaQAwZgIxAN344FdHW6fmCsO99YCKlzUNG4k8VIZ3\\n\" +\n  \"KMqh9HneteY4sPBlcIx/AlTCv//YoT7ZzwIxAMSNlPzcU9LcnXgWHxUzI1NS41ox\\n\" +\n  \"XZ3Krr0TKUQNJ1uo52icEvdYPy5yAlejj6EULg==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // thawte_Primary_Root_CA-G3_SHA256\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIEKjCCAxKgAwIBAgIQYAGXt0an6rS0mtZLL/eQ+zANBgkqhkiG9w0BAQsFADCB\\n\" +\n  \"rjELMAkGA1UEBhMCVVMxFTATBgNVBAoTDHRoYXd0ZSwgSW5jLjEoMCYGA1UECxMf\\n\" +\n  \"Q2VydGlmaWNhdGlvbiBTZXJ2aWNlcyBEaXZpc2lvbjE4MDYGA1UECxMvKGMpIDIw\\n\" +\n  \"MDggdGhhd3RlLCBJbmMuIC0gRm9yIGF1dGhvcml6ZWQgdXNlIG9ubHkxJDAiBgNV\\n\" +\n  \"BAMTG3RoYXd0ZSBQcmltYXJ5IFJvb3QgQ0EgLSBHMzAeFw0wODA0MDIwMDAwMDBa\\n\" +\n  \"Fw0zNzEyMDEyMzU5NTlaMIGuMQswCQYDVQQGEwJVUzEVMBMGA1UEChMMdGhhd3Rl\\n\" +\n  \"LCBJbmMuMSgwJgYDVQQLEx9DZXJ0aWZpY2F0aW9uIFNlcnZpY2VzIERpdmlzaW9u\\n\" +\n  \"MTgwNgYDVQQLEy8oYykgMjAwOCB0aGF3dGUsIEluYy4gLSBGb3IgYXV0aG9yaXpl\\n\" +\n  \"ZCB1c2Ugb25seTEkMCIGA1UEAxMbdGhhd3RlIFByaW1hcnkgUm9vdCBDQSAtIEcz\\n\" +\n  \"MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAsr8nLPvb2FvdeHsbnndm\\n\" +\n  \"gcs+vHyu86YnmjSjaDFxODNi5PNxZnmxqWWjpYvVj2AtP0LMqmsywCPLLEHd5N/8\\n\" +\n  \"YZzic7IilRFDGF/Eth9XbAoFWCLINkw6fKXRz4aviKdEAhN0cXMKQlkC+BsUa0Lf\\n\" +\n  \"b1+6a4KinVvnSr0eAXLbS3ToO39/fR8EtCab4LRarEc9VbjXsCZSKAExQGbY2SS9\\n\" +\n  \"9irY7CFJXJv2eul/VTV+lmuNk5Mny5K76qxAwJ/C+IDPXfRa3M50hqY+bAtTyr2S\\n\" +\n  \"zhkGcuYMXDhpxwTWvGzOW/b3aJzcJRVIiKHpqfiYnODz1TEoYRFsZ5aNOZnLwkUk\\n\" +\n  \"OQIDAQABo0IwQDAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIBBjAdBgNV\\n\" +\n  \"HQ4EFgQUrWyqlGCc7eT/+j4KdCtjA/e2Wb8wDQYJKoZIhvcNAQELBQADggEBABpA\\n\" +\n  \"2JVlrAmSicY59BDlqQ5mU1143vokkbvnRFHfxhY0Cu9qRFHqKweKA3rD6z8KLFIW\\n\" +\n  \"oCtDuSWQP3CpMyVtRRooOyfPqsMpQhvfO0zAMzRbQYi/aytlryjvsvXDqmbOe1bu\\n\" +\n  \"t8jLZ8HJnBoYuMTDSQPxYA5QzUbF83d597YV4Djbxy8ooAw/dyZ02SUS2jHaGh7c\\n\" +\n  \"KUGRIjxpp7sC8rZcJwOJ9Abqm+RyguOhCcHpABnTPtRwa7pxpqpYrvS76Wy274fM\\n\" +\n  \"m7v/OeZWYdMKp8RcTGB7BXcmer/YB1IsYvdwY9k5vG8cwnncdimvzsUsZAReiDZu\\n\" +\n  \"MdRAGmI0Nj81Aa6sY6A=\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // thawte_Primary_Root_CA\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIEIDCCAwigAwIBAgIQNE7VVyDV7exJ9C/ON9srbTANBgkqhkiG9w0BAQUFADCB\\n\" +\n  \"qTELMAkGA1UEBhMCVVMxFTATBgNVBAoTDHRoYXd0ZSwgSW5jLjEoMCYGA1UECxMf\\n\" +\n  \"Q2VydGlmaWNhdGlvbiBTZXJ2aWNlcyBEaXZpc2lvbjE4MDYGA1UECxMvKGMpIDIw\\n\" +\n  \"MDYgdGhhd3RlLCBJbmMuIC0gRm9yIGF1dGhvcml6ZWQgdXNlIG9ubHkxHzAdBgNV\\n\" +\n  \"BAMTFnRoYXd0ZSBQcmltYXJ5IFJvb3QgQ0EwHhcNMDYxMTE3MDAwMDAwWhcNMzYw\\n\" +\n  \"NzE2MjM1OTU5WjCBqTELMAkGA1UEBhMCVVMxFTATBgNVBAoTDHRoYXd0ZSwgSW5j\\n\" +\n  \"LjEoMCYGA1UECxMfQ2VydGlmaWNhdGlvbiBTZXJ2aWNlcyBEaXZpc2lvbjE4MDYG\\n\" +\n  \"A1UECxMvKGMpIDIwMDYgdGhhd3RlLCBJbmMuIC0gRm9yIGF1dGhvcml6ZWQgdXNl\\n\" +\n  \"IG9ubHkxHzAdBgNVBAMTFnRoYXd0ZSBQcmltYXJ5IFJvb3QgQ0EwggEiMA0GCSqG\\n\" +\n  \"SIb3DQEBAQUAA4IBDwAwggEKAoIBAQCsoPD7gFnUnMekz52hWXMJEEUMDSxuaPFs\\n\" +\n  \"W0hoSVk3/AszGcJ3f8wQLZU0HObrTQmnHNK4yZc2AreJ1CRfBsDMRJSUjQJib+ta\\n\" +\n  \"3RGNKJpchJAQeg29dGYvajig4tVUROsdB58Hum/u6f1OCyn1PoSgAfGcq/gcfomk\\n\" +\n  \"6KHYcWUNo1F77rzSImANuVud37r8UVsLr5iy6S7pBOhih94ryNdOwUxkHt3Ph1i6\\n\" +\n  \"Sk/KaAcdHJ1KxtUvkcx8cXIcxcBn6zL9yZJclNqFwJu/U30rCfSMnZEfl2pSy94J\\n\" +\n  \"NqR32HuHUETVPm4pafs5SSYeCaWAe0At6+gnhcn+Yf1+5nyXHdWdAgMBAAGjQjBA\\n\" +\n  \"MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMB0GA1UdDgQWBBR7W0XP\\n\" +\n  \"r87Lev0xkhpqtvNG61dIUDANBgkqhkiG9w0BAQUFAAOCAQEAeRHAS7ORtvzw6WfU\\n\" +\n  \"DW5FvlXok9LOAz/t2iWwHVfLHjp2oEzsUHboZHIMpKnxuIvW1oeEuzLlQRHAd9mz\\n\" +\n  \"YJ3rG9XRbkREqaYB7FViHXe4XI5ISXycO1cRrK1zN44veFyQaEfZYGDm/Ac9IiAX\\n\" +\n  \"xPcW6cTYcvnIc3zfFi8VqT79aie2oetaupgf1eNNZAqdE8hhuvU5HIe6uL17In/2\\n\" +\n  \"/qxAeeWsEG89jxt5dovEN7MhGITlNgDrYyCZuen+MwS7QcjBAvlEYyCegc5C09Y/\\n\" +\n  \"LHbTY5xZ3Y+m4Q6gLkH3LpVHz7z9M/P2C2F+fpErgUfCJzDupxBdN49cOSvkBPB7\\n\" +\n  \"jVaMaA==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // thawte_Server_CA\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDIjCCAougAwIBAgIQNKT/9jCvTKU8MxdCoZRmdTANBgkqhkiG9w0BAQUFADCB\\n\" +\n  \"xDELMAkGA1UEBhMCWkExFTATBgNVBAgTDFdlc3Rlcm4gQ2FwZTESMBAGA1UEBxMJ\\n\" +\n  \"Q2FwZSBUb3duMR0wGwYDVQQKExRUaGF3dGUgQ29uc3VsdGluZyBjYzEoMCYGA1UE\\n\" +\n  \"CxMfQ2VydGlmaWNhdGlvbiBTZXJ2aWNlcyBEaXZpc2lvbjEZMBcGA1UEAxMQVGhh\\n\" +\n  \"d3RlIFNlcnZlciBDQTEmMCQGCSqGSIb3DQEJARYXc2VydmVyLWNlcnRzQHRoYXd0\\n\" +\n  \"ZS5jb20wHhcNOTYwODAxMDAwMDAwWhcNMjEwMTAxMjM1OTU5WjCBxDELMAkGA1UE\\n\" +\n  \"BhMCWkExFTATBgNVBAgTDFdlc3Rlcm4gQ2FwZTESMBAGA1UEBxMJQ2FwZSBUb3du\\n\" +\n  \"MR0wGwYDVQQKExRUaGF3dGUgQ29uc3VsdGluZyBjYzEoMCYGA1UECxMfQ2VydGlm\\n\" +\n  \"aWNhdGlvbiBTZXJ2aWNlcyBEaXZpc2lvbjEZMBcGA1UEAxMQVGhhd3RlIFNlcnZl\\n\" +\n  \"ciBDQTEmMCQGCSqGSIb3DQEJARYXc2VydmVyLWNlcnRzQHRoYXd0ZS5jb20wgZ8w\\n\" +\n  \"DQYJKoZIhvcNAQEBBQADgY0AMIGJAoGBANOkUG7I/1Zr5s9dtuoMaHVHoqrC2oQl\\n\" +\n  \"/Kj0R1HahbUgdJSGHg91yekIYfUGbTBuFRkC6VLAYttNmZ7iagxEOM3+vuNkCXDF\\n\" +\n  \"/rFrKbYvScg71CcEJRCXL+eQbcAoQpnXTEPew/UhbVSfXcNY4cDk2VuwuNy0e982\\n\" +\n  \"OsK1ZiIS1ocNAgMBAAGjEzARMA8GA1UdEwEB/wQFMAMBAf8wDQYJKoZIhvcNAQEF\\n\" +\n  \"BQADgYEAvkBpQW/G28GnvwfAReTQtUMeTJUzNelewj4o9qgNUNX/4gwP/FACjq6R\\n\" +\n  \"ua00io2fJ3GqGcxL6ATK1BdrEhrWxl/WzV7/iXa/2EjYWb0IiokdV81FHlK6EpqE\\n\" +\n  \"+hiJX+j5MDVqAWC5mYCDhQpu2vTJj15zLTFKY6B08h+LItIpPus=\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // trustcenter_TC_Universal_CA_III\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIID4TCCAsmgAwIBAgIOYyUAAQACFI0zFQLkbPQwDQYJKoZIhvcNAQEFBQAwezEL\\n\" +\n  \"MAkGA1UEBhMCREUxHDAaBgNVBAoTE1RDIFRydXN0Q2VudGVyIEdtYkgxJDAiBgNV\\n\" +\n  \"BAsTG1RDIFRydXN0Q2VudGVyIFVuaXZlcnNhbCBDQTEoMCYGA1UEAxMfVEMgVHJ1\\n\" +\n  \"c3RDZW50ZXIgVW5pdmVyc2FsIENBIElJSTAeFw0wOTA5MDkwODE1MjdaFw0yOTEy\\n\" +\n  \"MzEyMzU5NTlaMHsxCzAJBgNVBAYTAkRFMRwwGgYDVQQKExNUQyBUcnVzdENlbnRl\\n\" +\n  \"ciBHbWJIMSQwIgYDVQQLExtUQyBUcnVzdENlbnRlciBVbml2ZXJzYWwgQ0ExKDAm\\n\" +\n  \"BgNVBAMTH1RDIFRydXN0Q2VudGVyIFVuaXZlcnNhbCBDQSBJSUkwggEiMA0GCSqG\\n\" +\n  \"SIb3DQEBAQUAA4IBDwAwggEKAoIBAQDC2pxisLlxErALyBpXsq6DFJmzNEubkKLF\\n\" +\n  \"5+cvAqBNLaT6hdqbJYUtQCggbergvbFIgyIpRJ9Og+41URNzdNW88jBmlFPAQDYv\\n\" +\n  \"DIRlzg9uwliT6CwLOunBjvvya8o84pxOjuT5fdMnnxvVZ3iHLX8LR7PH6MlIfK8v\\n\" +\n  \"zArZQe+f/prhsq75U7Xl6UafYOPfjdN/+5Z+s7Vy+EutCHnNaYlAJ/Uqwa1D7KRT\\n\" +\n  \"yGG299J5KmcYdkhtWyUB0SbFt1dpIxVbYYqt8Bst2a9c8SaQaanVDED1M4BDj5yj\\n\" +\n  \"dipFtK+/fz6HP3bFzSreIMUWWMv5G/UPyw0RUmS40nZid4PxWJ//AgMBAAGjYzBh\\n\" +\n  \"MB8GA1UdIwQYMBaAFFbn4VslQ4Dg9ozhcbyO5YAvxEjiMA8GA1UdEwEB/wQFMAMB\\n\" +\n  \"Af8wDgYDVR0PAQH/BAQDAgEGMB0GA1UdDgQWBBRW5+FbJUOA4PaM4XG8juWAL8RI\\n\" +\n  \"4jANBgkqhkiG9w0BAQUFAAOCAQEAg8ev6n9NCjw5sWi+e22JLumzCecYV42Fmhfz\\n\" +\n  \"dkJQEw/HkG8zrcVJYCtsSVgZ1OK+t7+rSbyUyKu+KGwWaODIl0YgoGhnYIg5IFHY\\n\" +\n  \"aAERzqf2EQf27OysGh+yZm5WZ2B6dF7AbZc2rrUNXWZzwCUyRdhKBgePxLcHsU0G\\n\" +\n  \"DeGl6/R1yrqc0L2z0zIkTO5+4nYES0lT2PLpVDP85XEfPRRclkvxOvIAu2y0+pZV\\n\" +\n  \"CIgJwcyRGSmwIC3/yzikQOEXvnlhgP8HA4ZMTnsGnxGGjYnuJ8Tb4rwZjgvDwxPH\\n\" +\n  \"LQNjO9Po5KIqwoIIlBZU8O8fJ5AluA0OKBtHd0e9HKgl8ZS0Zg==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // trustcenter_Universal_CA-I\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIID3TCCAsWgAwIBAgIOHaIAAQAC7LdggHiNtgYwDQYJKoZIhvcNAQEFBQAweTEL\\n\" +\n  \"MAkGA1UEBhMCREUxHDAaBgNVBAoTE1RDIFRydXN0Q2VudGVyIEdtYkgxJDAiBgNV\\n\" +\n  \"BAsTG1RDIFRydXN0Q2VudGVyIFVuaXZlcnNhbCBDQTEmMCQGA1UEAxMdVEMgVHJ1\\n\" +\n  \"c3RDZW50ZXIgVW5pdmVyc2FsIENBIEkwHhcNMDYwMzIyMTU1NDI4WhcNMjUxMjMx\\n\" +\n  \"MjI1OTU5WjB5MQswCQYDVQQGEwJERTEcMBoGA1UEChMTVEMgVHJ1c3RDZW50ZXIg\\n\" +\n  \"R21iSDEkMCIGA1UECxMbVEMgVHJ1c3RDZW50ZXIgVW5pdmVyc2FsIENBMSYwJAYD\\n\" +\n  \"VQQDEx1UQyBUcnVzdENlbnRlciBVbml2ZXJzYWwgQ0EgSTCCASIwDQYJKoZIhvcN\\n\" +\n  \"AQEBBQADggEPADCCAQoCggEBAKR3I5ZEr5D0MacQ9CaHnPM42Q9e3s9B6DGtxnSR\\n\" +\n  \"JJZ4Hgmgm5qVSkr1YnwCqMqs+1oEdjneX/H5s7/zA1hV0qq34wQi0fiU2iIIAI3T\\n\" +\n  \"fCZdzHd55yx4Oagmcw6iXSVphU9VDprvxrlE4Vc93x9UIuVvZaozhDrzznq+VZeu\\n\" +\n  \"jRIPFDPiUHDDSYcTvFHe15gSWu86gzOSBnWLknwSaHtwag+1m7Z3W0hZneTvWq3z\\n\" +\n  \"wZ7U10VOylY0Ibw+F1tvdwxIAUMpsN0/lm7mlaoMwCC2/T42J5zjXM9OgdwZu5GQ\\n\" +\n  \"fezmlwQek8wiSdeXhrYTCjxDI3d+8NzmzSQfO4ObNDqDNOMCAwEAAaNjMGEwHwYD\\n\" +\n  \"VR0jBBgwFoAUkqR1LKSevoFE63n8isWVpesQdXMwDwYDVR0TAQH/BAUwAwEB/zAO\\n\" +\n  \"BgNVHQ8BAf8EBAMCAYYwHQYDVR0OBBYEFJKkdSyknr6BROt5/IrFlaXrEHVzMA0G\\n\" +\n  \"CSqGSIb3DQEBBQUAA4IBAQAo0uCG1eb4e/CX3CJrO5UUVg8RMKWaTzqwOuAGy2X1\\n\" +\n  \"7caXJ/4l8lfmXpWMPmRgFVp/Lw0BxbFg/UU1z/CyvwbZ71q+s2IhtNerNXxTPqYn\\n\" +\n  \"8aEt2hojnczd7Dwtnic0XQ/CNnm8yUpiLe1r2X1BQ3y2qsrtYbE3ghUJGooWMNjs\\n\" +\n  \"ydZHcnhLEEYUjl8Or+zHL6sQ17bxbuyGssLoDZJz3KL0Dzq/YSMQiZxIQG5wALPT\\n\" +\n  \"ujdEWBF6AmqI8Dc08BnprNRlc/ZpjGSUOnmFKbAWKwyCPwacx/0QK54PLLae4xW/\\n\" +\n  \"2TYcuiUaUj0a7CIMHOCkoj3w6DnPgcB77V0fb8XQC9eY\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // trustcenter_Universal_CA-II\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIF3zCCA8egAwIBAgIOGTMAAQACKBqaBLzyVUUwDQYJKoZIhvcNAQEFBQAwejEL\\n\" +\n  \"MAkGA1UEBhMCREUxHDAaBgNVBAoTE1RDIFRydXN0Q2VudGVyIEdtYkgxJDAiBgNV\\n\" +\n  \"BAsTG1RDIFRydXN0Q2VudGVyIFVuaXZlcnNhbCBDQTEnMCUGA1UEAxMeVEMgVHJ1\\n\" +\n  \"c3RDZW50ZXIgVW5pdmVyc2FsIENBIElJMB4XDTA2MDMyMjE1NTgzNFoXDTMwMTIz\\n\" +\n  \"MTIyNTk1OVowejELMAkGA1UEBhMCREUxHDAaBgNVBAoTE1RDIFRydXN0Q2VudGVy\\n\" +\n  \"IEdtYkgxJDAiBgNVBAsTG1RDIFRydXN0Q2VudGVyIFVuaXZlcnNhbCBDQTEnMCUG\\n\" +\n  \"A1UEAxMeVEMgVHJ1c3RDZW50ZXIgVW5pdmVyc2FsIENBIElJMIICIjANBgkqhkiG\\n\" +\n  \"9w0BAQEFAAOCAg8AMIICCgKCAgEAi9R3azRs5TbYalxeOO781R15Azt7g2JEgk6I\\n\" +\n  \"7d6D/+7MUGIFBZWZdpj2ufJf2AaRksL2LWYXH/1TA+iojWOpbuHWG4y8mLOLO9Tk\\n\" +\n  \"Lsp9hUkmW3m4GotAnn+7yT9jLM/RWny6KCJBElpN+Rd3/IX9wkngKhh/6aAsnPlE\\n\" +\n  \"/AxoOUL1JwW+jhV6YJ3wO8c85j4WvK923mq3ouGrRkXrjGV90ZfzlxElq1nroCLZ\\n\" +\n  \"gt2Y7X7i+qBhCkoy3iwX921E6oFHWZdXNwM53V6CItQzuPomCba8OYgvURVOm8M7\\n\" +\n  \"3xOCiN1LNPIz1pDp81PcNXzAw9l8eLPNcD+NauCjgUjkKa1juPD8KGQ7mbN9/pqd\\n\" +\n  \"iPaZIgiRRxaJNXhdd6HPv0nh/SSUK2k2e+gc5iqQilvVOzRZQtxtz7sPQRxVzfUN\\n\" +\n  \"Wy4WIibvYR6X/OJTyM9bo8ep8boOhhLLE8oVx+zkNo3aXBM9ZdIOXXB03L+PemrB\\n\" +\n  \"Lg/Txl4PK1lszGFs/sBhTtnmT0ayWuIZFHCE+CAA7QGnl37DvRJckiMXoKUdRRcV\\n\" +\n  \"I5qSCLUiiI3cKyTr4LEXaNOvYb3ZhXj2jbp4yjeNY77nrB/fpUcJucglMVRGURFV\\n\" +\n  \"DYlcjdrSGC1z8rjVJ/VIIjfRYvd7Dcg4i6FKsPzQ8eu3hmPn4A5zf/1yUbXpfeJV\\n\" +\n  \"BWR4Z38CAwEAAaNjMGEwHwYDVR0jBBgwFoAUzdeQoW6jv9sw1toyJZAM5jkegGUw\\n\" +\n  \"DwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAYYwHQYDVR0OBBYEFM3XkKFu\\n\" +\n  \"o7/bMNbaMiWQDOY5HoBlMA0GCSqGSIb3DQEBBQUAA4ICAQB+FojoEw42zG4qhQc4\\n\" +\n  \"xlaJeuNHIWZMUAgxWlHQ/KZeFHXeTDvs8e3MfhEHSmHu6rOOOqQzxu2KQmZP8Tx7\\n\" +\n  \"yaUFQZmx7Cxb7tyW0ohTS3g0uW7muw/FeqZ8Dhjfbw90TNGp8aHp2FRkzF6WeKJW\\n\" +\n  \"GsFzshXGVwXf2vdIJIqOf2qp+U3pPmrOYCx9LZAI9mOPFdAtnIz/8f38DBZQVhT7\\n\" +\n  \"upeG7rRJA1TuG1l/MDoCgoYhrv7wFfLfToPmmcW6NfcgkIw47XXP4S73BDD7Ua2O\\n\" +\n  \"giRAyn0pXdXZ92Vk/KqfdLh9kl3ShCngE+qK99CrxK7vFcXCifJ7tjtJmGHzTnKR\\n\" +\n  \"N4xJkunI7Cqg90lufA0kxmts8jgvynAF5X/fxisrgIDV2m/LQLvYG/AkyRDIRAJ+\\n\" +\n  \"LtOYqqIN8SvQ2vqOHP9U6OFKbt2o1ni1N6WsZNUUI8cOpevhCTjXwHxgpV2Yj4wC\\n\" +\n  \"1dxWqPNNWKkL1HxkdAEy8t8PSoqpAqKiHYR3wvHMl700GXRd4nQ+dSf3r7/ufA5t\\n\" +\n  \"VIimVuImrTESPB5BeW0X6hNeH/Vcn0lZo7Ivo0LD+qh+v6WfSMlgYmIK371F3uNC\\n\" +\n  \"tVGW/cT1Gpm4UqJEzS1hjBWPgdVdotSQPYxuQGHDWV3Y2eH2dEcieXR92sqjbzcV\\n\" +\n  \"NvAsGnE8EXbfXRo+VGN4a2V+Hw==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // trustcenter_class_2_ii\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIEqjCCA5KgAwIBAgIOLmoAAQACH9dSISwRXDswDQYJKoZIhvcNAQEFBQAwdjEL\\n\" +\n  \"MAkGA1UEBhMCREUxHDAaBgNVBAoTE1RDIFRydXN0Q2VudGVyIEdtYkgxIjAgBgNV\\n\" +\n  \"BAsTGVRDIFRydXN0Q2VudGVyIENsYXNzIDIgQ0ExJTAjBgNVBAMTHFRDIFRydXN0\\n\" +\n  \"Q2VudGVyIENsYXNzIDIgQ0EgSUkwHhcNMDYwMTEyMTQzODQzWhcNMjUxMjMxMjI1\\n\" +\n  \"OTU5WjB2MQswCQYDVQQGEwJERTEcMBoGA1UEChMTVEMgVHJ1c3RDZW50ZXIgR21i\\n\" +\n  \"SDEiMCAGA1UECxMZVEMgVHJ1c3RDZW50ZXIgQ2xhc3MgMiBDQTElMCMGA1UEAxMc\\n\" +\n  \"VEMgVHJ1c3RDZW50ZXIgQ2xhc3MgMiBDQSBJSTCCASIwDQYJKoZIhvcNAQEBBQAD\\n\" +\n  \"ggEPADCCAQoCggEBAKuAh5uO8MN8h9foJIIRszzdQ2Lu+MNF2ujhoF/RKrLqk2jf\\n\" +\n  \"tMjWQ+nEdVl//OEd+DFwIxuInie5e/060smp6RQvkL4DUsFJzfb95AhmC1eKokKg\\n\" +\n  \"uNV/aVyQMrKXDcpK3EY+AlWJU+MaWss2xgdW94zPEfRMuzBwBJWl9jmM/XOBCH2J\\n\" +\n  \"XjIeIqkiRUuwZi4wzJ9l/fzLganx4Duvo4bRierERXlQXa7pIXSSTYtZgo+U4+lK\\n\" +\n  \"8edJsBTj9WLL1XK9H7nSn6DNqPoByNkN39r8R52zyFTfSUrxIan+GE7uSNQZu+99\\n\" +\n  \"5OKdy1u2bv/jzVrndIIFuoAlOMvkaZ6vQaoahPUCAwEAAaOCATQwggEwMA8GA1Ud\\n\" +\n  \"EwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMB0GA1UdDgQWBBTjq1RMgKHbVkO3\\n\" +\n  \"kUrL84J6E1wIqzCB7QYDVR0fBIHlMIHiMIHfoIHcoIHZhjVodHRwOi8vd3d3LnRy\\n\" +\n  \"dXN0Y2VudGVyLmRlL2NybC92Mi90Y19jbGFzc18yX2NhX0lJLmNybIaBn2xkYXA6\\n\" +\n  \"Ly93d3cudHJ1c3RjZW50ZXIuZGUvQ049VEMlMjBUcnVzdENlbnRlciUyMENsYXNz\\n\" +\n  \"JTIwMiUyMENBJTIwSUksTz1UQyUyMFRydXN0Q2VudGVyJTIwR21iSCxPVT1yb290\\n\" +\n  \"Y2VydHMsREM9dHJ1c3RjZW50ZXIsREM9ZGU/Y2VydGlmaWNhdGVSZXZvY2F0aW9u\\n\" +\n  \"TGlzdD9iYXNlPzANBgkqhkiG9w0BAQUFAAOCAQEAjNfffu4bgBCzg/XbEeprS6iS\\n\" +\n  \"GNn3Bzn1LL4GdXpoUxUc6krtXvwjshOg0wn/9vYua0Fxec3ibf2uWWuFHbhOIprt\\n\" +\n  \"ZjluS5TmVfwLG4t3wVMTZonZKNaL80VKY7f9ewthXbhtvsPcW3nS7Yblok2+XnR8\\n\" +\n  \"au0WOB9/WIFaGusyiC2y8zl3gK9etmF1KdsjTYjKUCjLhdLTEKJZbtOTVAB6okaV\\n\" +\n  \"hgWcqRmY5TFyDADiZ9lA4CQze28suVyrZZ0srHbqNZn1l7kPJOzHdiEoZa5X6AeI\\n\" +\n  \"dUpWoNIFOqTmjZKILPPy4cHGYdtBxceb9w4aUUXCYWvcZCcXjFq32nQozZfkvQ==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // trustcenter_class_3_ii\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIEqjCCA5KgAwIBAgIOSkcAAQAC5aBd1j8AUb8wDQYJKoZIhvcNAQEFBQAwdjEL\\n\" +\n  \"MAkGA1UEBhMCREUxHDAaBgNVBAoTE1RDIFRydXN0Q2VudGVyIEdtYkgxIjAgBgNV\\n\" +\n  \"BAsTGVRDIFRydXN0Q2VudGVyIENsYXNzIDMgQ0ExJTAjBgNVBAMTHFRDIFRydXN0\\n\" +\n  \"Q2VudGVyIENsYXNzIDMgQ0EgSUkwHhcNMDYwMTEyMTQ0MTU3WhcNMjUxMjMxMjI1\\n\" +\n  \"OTU5WjB2MQswCQYDVQQGEwJERTEcMBoGA1UEChMTVEMgVHJ1c3RDZW50ZXIgR21i\\n\" +\n  \"SDEiMCAGA1UECxMZVEMgVHJ1c3RDZW50ZXIgQ2xhc3MgMyBDQTElMCMGA1UEAxMc\\n\" +\n  \"VEMgVHJ1c3RDZW50ZXIgQ2xhc3MgMyBDQSBJSTCCASIwDQYJKoZIhvcNAQEBBQAD\\n\" +\n  \"ggEPADCCAQoCggEBALTgu1G7OVyLBMVMeRwjhjEQY0NVJz/GRcekPewJDRoeIMJW\\n\" +\n  \"Ht4bNwcwIi9v8Qbxq63WyKthoy9DxLCyLfzDlml7forkzMA5EpBCYMnMNWju2l+Q\\n\" +\n  \"Vl/NHE1bWEnrDgFPZPosPIlY2C8u4rBo6SI7dYnWRBpl8huXJh0obazovVkdKyT2\\n\" +\n  \"1oQDZogkAHhg8fir/gKya/si+zXmFtGt9i4S5Po1auUZuV3bOx4a+9P/FRQI2Alq\\n\" +\n  \"ukWdFHlgfa9Aigdzs5OW03Q0jTo3Kd5c7PXuLjHCINy+8U9/I1LZW+Jk2ZyqBwi1\\n\" +\n  \"Rb3R0DHBq1SfqdLDYmAD8bs5SpJKPQq5ncWg/jcCAwEAAaOCATQwggEwMA8GA1Ud\\n\" +\n  \"EwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMB0GA1UdDgQWBBTUovyfs8PYA9NX\\n\" +\n  \"XAek0CSnwPIA1DCB7QYDVR0fBIHlMIHiMIHfoIHcoIHZhjVodHRwOi8vd3d3LnRy\\n\" +\n  \"dXN0Y2VudGVyLmRlL2NybC92Mi90Y19jbGFzc18zX2NhX0lJLmNybIaBn2xkYXA6\\n\" +\n  \"Ly93d3cudHJ1c3RjZW50ZXIuZGUvQ049VEMlMjBUcnVzdENlbnRlciUyMENsYXNz\\n\" +\n  \"JTIwMyUyMENBJTIwSUksTz1UQyUyMFRydXN0Q2VudGVyJTIwR21iSCxPVT1yb290\\n\" +\n  \"Y2VydHMsREM9dHJ1c3RjZW50ZXIsREM9ZGU/Y2VydGlmaWNhdGVSZXZvY2F0aW9u\\n\" +\n  \"TGlzdD9iYXNlPzANBgkqhkiG9w0BAQUFAAOCAQEANmDkcPcGIEPZIxpC8vijsrlN\\n\" +\n  \"irTzwppVMXzEO2eatN9NDoqTSheLG43KieHPOh6sHfGcMrSOWXaiQYUlN6AT0PV8\\n\" +\n  \"TtXqluJucsG7Kv5sbviRmEb8yRtXW+rIGjs/sFGYPAfaLFkB2otE6OF0/ado3VS6\\n\" +\n  \"g0bsyEa1+K+XwDsJHI/OcpY9M1ZwvJbL2NV9IJqDnxrcOfHFcqMRA/07QlIp2+gB\\n\" +\n  \"95tejNaNhk4Z+rwcvsUhpYeeeC422wlxo3I0+GzjBgnyXlal092Y+tTmBvTwtiBj\\n\" +\n  \"S+opvaqCZh77gaqnN60TGOaSw4HBM7uIHqHn4rS9MWwOUT1v+5ZWgOI2F9Hc5A==\\n\" +\n  \"-----END CERTIFICATE-----\\n\",\n\n  // trustcenter_class_4_ii\n  \"-----BEGIN CERTIFICATE-----\\n\" +\n  \"MIIDtjCCAp6gAwIBAgIOBcAAAQACQdAGCk3OdRAwDQYJKoZIhvcNAQEFBQAwdjEL\\n\" +\n  \"MAkGA1UEBhMCREUxHDAaBgNVBAoTE1RDIFRydXN0Q2VudGVyIEdtYkgxIjAgBgNV\\n\" +\n  \"BAsTGVRDIFRydXN0Q2VudGVyIENsYXNzIDQgQ0ExJTAjBgNVBAMTHFRDIFRydXN0\\n\" +\n  \"Q2VudGVyIENsYXNzIDQgQ0EgSUkwHhcNMDYwMzIzMTQxMDIzWhcNMjUxMjMxMjI1\\n\" +\n  \"OTU5WjB2MQswCQYDVQQGEwJERTEcMBoGA1UEChMTVEMgVHJ1c3RDZW50ZXIgR21i\\n\" +\n  \"SDEiMCAGA1UECxMZVEMgVHJ1c3RDZW50ZXIgQ2xhc3MgNCBDQTElMCMGA1UEAxMc\\n\" +\n  \"VEMgVHJ1c3RDZW50ZXIgQ2xhc3MgNCBDQSBJSTCCASIwDQYJKoZIhvcNAQEBBQAD\\n\" +\n  \"ggEPADCCAQoCggEBALXNTJytrlG7fEjFDSmGehSt2VA9CXIgDRS2Y8b+WJ7gIV7z\\n\" +\n  \"jyIZ3E6RIM1viCmis8GsKnK6i1S4QF/yqvhDhsIwXMynXX/GCEnkDjkvjhjWkd0j\\n\" +\n  \"FnmA22xIHbzB3ygQY9GB493fL3l1oht48pQB5hBiecugfQLANIJ7x8CtHUzXapZ2\\n\" +\n  \"W78mhEj9h/aECqqSB5lIPGG8ToVYx5ct/YFKocabEvVCUNFkPologiJw3fX64yhC\\n\" +\n  \"L04y87OjNopq1mJcrPoBbbTgci6VaLTxkwzGioLSHVPqfOA/QrcSWrjN2qUGZ8uh\\n\" +\n  \"d32llvCSHmcOHUJG5vnt+0dTf1cERh9GX8eu4I8CAwEAAaNCMEAwDwYDVR0TAQH/\\n\" +\n  \"BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAYYwHQYDVR0OBBYEFB/quz4lGwa9pd1iBX7G\\n\" +\n  \"TFq/6A9DMA0GCSqGSIb3DQEBBQUAA4IBAQBYpCubTPfkpJKknGWYGWIi/HIy6QRd\\n\" +\n  \"xMRwLVpG3kxHiiW5ot3u6hKvSI3vK2fbO8w0mCr3CEf/Iq978fTr4jgCMxh1KBue\\n\" +\n  \"dmWsiANy8jhHHYz1nwqIUxAUu4DlDLNdjRfuHhkcho0UZ3iMksseIUn3f9MYv5x5\\n\" +\n  \"+F0IebWqak2SNmy8eesOPXmK2PajVnBd3ttPedJ60pVchidlvqDTB4FAVd0Qy+BL\\n\" +\n  \"iILAkH0457+W4Ze6mqtCD9Of2J4VMxHL94J59bXAQVaS4d9VA61Iz9PyLrHHLVZM\\n\" +\n  \"ZHQqMc7cdalUR6SnQnIJ5+ECpkeyBM1CE+FhDOB4OiIgohxgQoaH96Xm\\n\" +\n  \"-----END CERTIFICATE-----\\n\"\n]\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/errors/aggregator.js":"'use strict'\n\nvar copy = require('../util/copy')\nvar urltils = require('../util/urltils')\nvar logger = require('../logger').child({component: 'error_tracer'})\nvar NAMES = require('../metrics/names')\nvar errorsModule = require('./index')\nvar Reservoir = require('../reservoir.js')\nvar WeakSet = global.WeakSet\n\n\nvar createError = errorsModule.createError\nvar createEvent = errorsModule.createEvent\n\nmodule.exports = ErrorAggregator\n\n/*\n *\n * CONSTANTS\n *\n */\nvar MAX_ERRORS = 20\n\n/**\n * ErrorAggregator is responsible for collecting JS errors and errored-out HTTP\n * transactions, and for converting them to error traces and error events expected by\n * the collector.\n */\nfunction ErrorAggregator(config) {\n  this.config = config\n  this.errorCount = 0\n  this.webTransactionErrorCount = 0\n  this.otherTransactionErrorCount = 0\n  this.errors = []\n  this.seenObjectsByTransaction = {}\n  this.seenStringsByTransaction = {}\n\n  // reservoir used for error events\n  this.events = new Reservoir(this.config.error_collector.max_event_samples_stored)\n}\n\n/**\n * Every finished transaction goes through this handler, so do as\n * little as possible.\n */\nErrorAggregator.prototype.onTransactionFinished = onTransactionFinished\n\nfunction onTransactionFinished(transaction, metrics) {\n  if (!transaction) throw new Error(\"Error collector got a blank transaction.\")\n  if (!metrics) throw new Error(\"Error collector requires metrics to count errors.\")\n  if (transaction.ignore) return\n\n  // collect user errors even if status code is ignored\n  var collectedErrors = 0\n  var exception, i\n  if (transaction.userErrors.length > 0) {\n    for (i = 0; i < transaction.userErrors.length; i++) {\n      exception = transaction.userErrors[i]\n      if (this._collect(transaction, exception[0], exception[1], exception[2])) {\n        collectedErrors++\n      }\n    }\n  }\n\n  var hasExceptions = transaction.exceptions.length > 0\n  var isErroredTransaction = urltils.isError(this.config, transaction.statusCode)\n  var isIgnoredErrorStatusCode = urltils.isIgnoredError(this.config,\n      transaction.statusCode)\n\n  // collect other exceptions only if status code is not ignored\n  if (hasExceptions && !isIgnoredErrorStatusCode) {\n    for (i = 0; i < transaction.exceptions.length; i++) {\n      exception = transaction.exceptions[i]\n      if (this._collect(transaction, exception[0], exception[1], exception[2])) {\n        collectedErrors++\n      }\n    }\n  } else if (isErroredTransaction) {\n    if (this._collect(transaction)) {\n      collectedErrors++\n    }\n  }\n\n  // the metric should be incremented only if the error was actually collected\n  if (collectedErrors > 0) {\n    var count = metrics.getOrCreateMetric(NAMES.ERRORS.PREFIX + transaction.name)\n    count.incrementCallCount(collectedErrors)\n  }\n}\n\n/**\n * This function collects the error right away when transaction is not supplied.\n * Otherwise it delays collecting the error until the transaction ends.\n *\n * NOTE: this interface is unofficial and may change in future.\n *\n * @param {Transaction} transaction      Transaction associated with the error\n *                                       (optional).\n * @param {Error}       exception        The error to be traced.\n * @param {object}      customParameters Any custom parameters associated with\n *                                       the request (optional).\n */\nErrorAggregator.prototype.add = function add(transaction, exception, customParameters) {\n  if (!exception) return\n\n  var timestamp = Date.now()\n\n  if (transaction) {\n    transaction.addException(exception, customParameters, timestamp)\n  } else {\n    this._collect(transaction, exception, customParameters, timestamp)\n  }\n}\n\n/**\n * This function is used to collect errors specifically added using the noticeError() API.\n * Similarly to add(), it collects the error right away when transaction is not supplied.\n * Otherwise it delays collecting the error until the transaction ends.\n * The reason for separating the API errors from other exceptions is that different ignore\n * rules apply to them.\n *\n * NOTE: this interface is unofficial and may change in future.\n *\n * @param {Transaction} transaction      Transaction associated with the error\n *                                       (optional).\n * @param {Error}       exception        The error to be traced.\n * @param {object}      customParameters Any custom parameters associated with\n *                                       the request (optional).\n */\nErrorAggregator.prototype.addUserError = function addUserError(transaction, exception,\n    customParameters) {\n  if (!exception) return\n\n  var timestamp = Date.now()\n\n  if (transaction) {\n    transaction.addUserError(exception, customParameters, timestamp)\n  } else {\n    this._collect(transaction, exception, customParameters, timestamp)\n  }\n}\n\n/**\n *\n * This function takes an exception and determines whether the exception\n * has been seen before by this aggregator.  This function mutates the\n * book keeping structures to reflect the exception has been seen.\n *\n * @param {Error} exception  The error to be checked.\n *\n */\n\nErrorAggregator.prototype.haveSeen = function haveSeen(transaction, exception) {\n  if (!transaction) {\n    transaction = {id: 'Unknown'}\n  }\n\n\n  if (typeof exception === 'object') {\n    if (!this.seenObjectsByTransaction[transaction.id]) {\n      if (WeakSet) {\n        this.seenObjectsByTransaction[transaction.id] = new WeakSet()\n      } else {\n        this.seenObjectsByTransaction[transaction.id] = []\n      }\n    }\n\n    var seenObjects = this.seenObjectsByTransaction[transaction.id]\n\n    if (WeakSet) {\n      if (seenObjects.has(exception)) {\n        return true\n      }\n\n      seenObjects.add(exception)\n    } else {\n      if (seenObjects.indexOf(exception) !== -1) {\n        return true\n      }\n\n      seenObjects.push(exception)\n    }\n  } else { // typeof exception !== 'object'\n    if (!this.seenStringsByTransaction[transaction.id]) {\n      this.seenStringsByTransaction[transaction.id] = {}\n    }\n\n    var seenStrings = this.seenStringsByTransaction[transaction.id]\n    if (seenStrings[exception]) {\n      return true\n    }\n\n    seenStrings[exception] = true\n  }\n  return false\n}\n\n/**\n * Collects the error and also creates the error event.\n * This function uses an array of seen exceptions to ensure errors don't get\n * double-counted. It can also be used as an unofficial means of marking that\n * user errors shouldn't be traced.\n *\n * For an error to be traced, at least one of the transaction or the error\n * must be present.\n *\n * NOTE: this interface is unofficial and may change in future.\n *\n * @param {Transaction} transaction      Transaction associated with the error\n *                                       (optional).\n * @param {Error}       exception        The error to be traced (optional).\n * @param {object}      customParameters Any custom parameters associated with\n *                                       the request (optional).\n * @returns {bool}  True if the error was collected.\n */\nErrorAggregator.prototype._collect = _collect\n\nfunction _collect(transaction, exception, customParameters, timestamp) {\n  if (exception) {\n    if (this.haveSeen(transaction, exception)) {\n      return\n    }\n\n    if (typeof exception !== 'string' && !exception.message && !exception.stack) {\n      logger.trace(exception,\n        \"Got error that is not an instance of Error or string.\")\n      exception = null\n    }\n  }\n\n  if (!exception) {\n    if (!transaction) return\n    if (!transaction.statusCode) return\n    if (transaction.error) return\n  }\n\n  this.errorCount++\n\n  if (transaction) {\n    if (transaction.isWeb()) {\n      this.webTransactionErrorCount++\n    } else {\n      this.otherTransactionErrorCount++\n    }\n  }\n\n  // allow enabling & disabling the error tracer at runtime\n  // TODO: it would be better to check config in the public add() to prevents collecting\n  // errors on the transaction unnecessarily\n  if (!this.config.collect_errors ||\n      !this.config.error_collector || !this.config.error_collector.enabled) return\n\n  if (exception) {\n    logger.trace(exception, \"Got exception to trace:\")\n  }\n\n  var error = createError(transaction, exception, customParameters, this.config)\n\n  if (this.errors.length < MAX_ERRORS) {\n    logger.debug({error: error}, \"Error to be sent to collector:\")\n\n    // XXX: 2016-05-24 Remove this when APM UI is updated to use correct request_uri\n    //\n    // For right now, when this flag is enabled, the request_uri will be added\n    // to the error data. This will result in duplicated data being displayed on\n    // APM which is a no-go, so we need to remove it here. However, we want the\n    // data to still be there for error events metrics, so we need to perform a\n    // deep copy and only remove it from this data.\n    //\n    // In order to save cycles, we perform a smart deep copy in the form of a\n    // series of shallow copies down just the path that needs to change.\n    if (this.config.feature_flag.send_request_uri_attribute) {\n      var err = []\n      err.push.apply(err, error)\n      err[4] = copy.shallow(err[4])\n      err[4].agentAttributes = copy.shallow(err[4].agentAttributes)\n      delete err[4].agentAttributes.request_uri\n      this.errors.push(err)\n    } else {\n      this.errors.push(error)\n    }\n  } else {\n    logger.debug(\"Already have %d errors to send to collector, not keeping.\",\n                 MAX_ERRORS)\n  }\n\n  // add error event\n  if (this.config.error_collector.capture_events === true) {\n    this.events.add(createEvent(transaction, error, timestamp))\n  }\n  return true\n}\n\n/**\n * Returns collected errors.\n */\nErrorAggregator.prototype.getErrors = function getErrors() {\n  return this.errors\n}\n\n/**\n * Returns error events based on seen errors.\n */\nErrorAggregator.prototype.getEvents = function getEvents() {\n  return this.events.toArray()\n}\n\n/**\n * Returns maximum number of events that are collected per a harvest cycle.\n */\nErrorAggregator.prototype.getEventsLimit = function getEventsLimit() {\n  return this.events.limit\n}\n\n/**\n * Returns number of events that have been seen since the last harvest cycle.\n */\nErrorAggregator.prototype.getEventsSeen = function getEventsSeen() {\n  return this.events.seen\n}\n\n/**\n * Returns total number of collected errors.\n */\nErrorAggregator.prototype.getTotalErrorCount = function getTotalErrorCount() {\n  return this.errorCount\n}\n\n/**\n * Returns total number of errors collected during web transactions.\n */\nErrorAggregator.prototype.getWebTransactionsErrorCount =\n    function getWebTransactionsErrorCount() {\n  return this.webTransactionErrorCount\n}\n\n/**\n * Returns total number of errors collected during background transactions.\n */\nErrorAggregator.prototype.getBackgroundTransactionsErrorCount =\n    function getOtherTransactionsErrorCount() {\n  return this.otherTransactionErrorCount\n}\n\n/**\n * If the connection to the collector fails, retain as many as will fit without\n * overflowing the current error list.\n *\n * @param array errors Previously harvested errors.\n */\nErrorAggregator.prototype.merge = function merge(errors) {\n  if (!errors) return\n\n  var len = Math.min(errors.length, MAX_ERRORS - this.errors.length)\n  logger.warn(\"Merging %s (of %s) errors for next delivery.\", len, errors.length)\n  for (var i = 0; i < len; i++) this.errors.push(errors[i])\n}\n\nErrorAggregator.prototype.mergeEvents = function mergeEvents(events) {\n  this.events.merge(events)\n}\n\nErrorAggregator.prototype.clearEvents = function clearEvents() {\n  this.events = new Reservoir(this.config.error_collector.max_event_samples_stored)\n}\n\nErrorAggregator.prototype.clearErrors = function clearErrors() {\n  this.errors = []\n  this.seenStringsByTransaction = {}\n  this.seenObjectsByTransaction = {}\n  this.errorCount = 0\n  this.webTransactionErrorCount = 0\n  this.otherTransactionErrorCount = 0\n}\n\nErrorAggregator.prototype.reconfigure = function reconfigure(config) {\n  this.config = config\n  this.events.setLimit(this.config.error_collector.max_event_samples_stored)\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/util/copy.js":"'use strict'\n\nexports.shallow = shallowCopy\n\n/**\n * Performs a shallow copy of all properties on the source object.\n *\n * @param {object} source     - The object to copy the properties from.\n * @param {object} [dest={}]  - The object to copy the properties to.\n *\n * @return {object} The destination object.\n */\nfunction shallowCopy(source, dest) {\n  dest = dest || {}\n  for (var k in source) {\n    if (source.hasOwnProperty(k)) {\n      dest[k] = source[k]\n    }\n  }\n  return dest\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/util/urltils.js":"'use strict'\n\nvar url = require('url')\n\n// TODO: Once Node v0.10 is deprecated, change this to use a `Set` instead.\nvar LOCALHOST_NAMES = {\n  \"localhost\": true,\n  \"127.0.0.1\": true,\n  \"0.0.0.0\": true,\n  \"0:0:0:0:0:0:0:1\": true,\n  \"::1\": true,\n  \"0:0:0:0:0:0:0:0\": true,\n  \"::\": true\n}\n\n/**\n * Utility functions for enforcing New Relic naming conditions on URLs,\n * and extracting and setting parameters on traces / web trace segments.\n */\nmodule.exports = {\n  /**\n   * Dictionary whose keys are all synonyms for localhost.\n   *\n   * @const\n   */\n  LOCALHOST_NAMES: LOCALHOST_NAMES,\n\n  /**\n   * Checks if the given name is in the dictionary of localhost names.\n   *\n   * @param {string} host - The hostname to lookup.\n   *\n   * @return {bool} - True if the given hostname is a synonym for localhost.\n   */\n  isLocalhost: function isLocahost(host) {\n    return LOCALHOST_NAMES.hasOwnProperty(host)\n  },\n\n  /**\n   * This was handed down from the prototype as the canonical list of status\n   * codes that short-circuit naming and normalization. The agent can be\n   * configured to mark HTTP status codes as not being errors.\n   *\n   * @param {Config} config The configuration containing the error list.\n   * @param {string} code   The HTTP status code to check.\n   *\n   * @returns {bool} Whether the status code should be ignored.\n   */\n  isError: function isError(config, code) {\n    return code >= 400 && !isIgnoredStatusCodeForErrors(config, code)\n  },\n\n  /**\n   * Returns true if the status code is an HTTP error, and it is configured to be ignored.\n   *\n   * @param {Config} config The configuration containing the error list.\n   * @param {string} code   The HTTP status code to check.\n   *\n   * @returns {bool} Whether the status code should be ignored.\n   */\n  isIgnoredError: function isIgnoredError(config, code) {\n    return code >= 400 && isIgnoredStatusCodeForErrors(config, code)\n  },\n\n  /**\n   * Get back the pieces of the URL that New Relic cares about. Apply these\n   * restrictions, in order:\n   *\n   * 1. Ensure that after parsing the URL, there's at least '/'\n   * 2. Strip off session trackers after ';' (a New Relic convention)\n   * 3. Remove trailing slash.\n   *\n   * @param {string} requestURL The URL fragment to be scrubbed.\n   * @return {string} The cleaned URL.\n   */\n  scrub: function scrub(requestURL) {\n    if (typeof requestURL === 'string') {\n      requestURL = url.parse(requestURL)\n    }\n\n    var path = requestURL.pathname\n\n    if (path) {\n      path = path.split(';')[0]\n\n      if (path !== '/' && path.charAt(path.length - 1) === '/') {\n        path = path.substring(0, path.length - 1)\n      }\n    } else {\n      path = '/'\n    }\n\n    return path\n  },\n\n  /**\n   * Extract query parameters, dealing with bare parameters and parameters with\n   * no value as appropriate:\n   *\n   * 'var1&var2=value' is not necessarily the same as 'var1=&var2=value'\n   *\n   * In my world, one is an assertion of presence, and the other is an empty\n   * variable. Some web frameworks behave this way as well, so don't lose\n   * information.\n   *\n   * @param {string} requestURL The URL to be parsed.\n   * @returns {object} The parameters parsed from the request\n   */\n  parseParameters: function parseParameters(requestURL) {\n    var parsed = requestURL\n\n    if (typeof requestURL === 'string') {\n      parsed = url.parse(requestURL, true)\n    }\n\n    var parameters = {}\n\n    if (parsed.query) {\n      var keys = Object.keys(parsed.query)\n\n      for (var i = 0, l = keys.length; i < l; ++i) {\n        var key = keys[i]\n        if (parsed.query[key] === '' && parsed.path.indexOf(key + '=') === -1) {\n          parameters[key] = true\n        } else {\n          parameters[key] = parsed.query[key]\n        }\n      }\n    }\n\n    return parameters\n  },\n\n  /**\n   * Performs the logic of `urltils.scrub` and `urltils.parseParameters` with\n   * only a single parse of the given URL.\n   *\n   * @param {string} requestURL - The URL to scrub and extra parameters from.\n   *\n   * @return {object} An object containing the scrubbed url at `.path` and the\n   *  parsed parameters at `.parameters`.\n   */\n  scrubAndParseParameters: function scrubAndParseParameters(requestURL) {\n    if (typeof requestURL === 'string') {\n      requestURL = url.parse(requestURL, true)\n    }\n    return {\n      path: this.scrub(requestURL),\n      parameters: this.parseParameters(requestURL)\n    }\n  },\n\n  /**\n   * Copy a set of request parameters from one object to another, following\n   * a few important rules:\n   *\n   * 1. Do not copy a parameter if it's in config.ignored_params.\n   * 2. Do not overwrite any existing parameters in destination, including\n   *    parameters set to null or undefined.\n   *\n   * @param {Config} config      Configuration, where `ignored_params` is\n   *                             guaranteed to be an Array.\n   * @param {object} source      Parameters to be copied (not changed).\n   * @param {object} destination Dictionary to which parameters are copied\n   *                             (mutated in place).\n   */\n  copyParameters: function copyParameters(config, source, destination) {\n    if (!(config && config.capture_params && source && destination)) return\n\n    var keys = Object.keys(source)\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i]\n      if (config.ignored_params.indexOf(key) === -1 && !(key in destination)) {\n        destination[key] = source[key]\n      }\n    }\n  },\n\n  /**\n   * Copy a set of request parameters from one object to another.\n   * Existing attributes on the `destination` will be overwritten.\n   * Unlike `copyParameters`, this function will operate when\n   * `capture_params` is not enabled.\n   *\n   * @param {Config} config      Configuration, where `ignored_params` is\n   *                             guaranteed to be an Array.\n   * @param {object} source      Parameters to be copied (not changed).\n   * @param {object} destination Dictionary to which parameters are copied\n   *                             (mutated in place).\n   */\n  overwriteParameters: function overwriteParameters(config, source, destination) {\n    if (!(config && source && destination)) return\n\n    var keys = Object.keys(source)\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i]\n      if (config.ignored_params.indexOf(key) === -1) {\n        destination[key] = source[key]\n      }\n    }\n  }\n}\n\nfunction isIgnoredStatusCodeForErrors(config, code) {\n  var codes = []\n  if (config &&\n      config.error_collector &&\n      config.error_collector.ignore_status_codes) {\n    codes = config.error_collector.ignore_status_codes\n  }\n  return codes.indexOf(parseInt(code, 10)) >= 0\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/errors/index.js":"'use strict'\n\nvar urltils = require('../util/urltils')\nvar NAMES = require('../metrics/names')\nvar util = require('util')\n\nmodule.exports.createError = createError\nmodule.exports.createEvent = createEvent\n\n/**\n * Given either or both of a transaction and an exception, generate an error\n * trace in the JSON format expected by the collector. Since this will be\n * used by both the HTTP instrumentation, which uses HTTP status codes to\n * determine whether a transaction is in error, and the domain-based error\n * handler, which traps actual instances of Error, try to set sensible\n * defaults for everything.\n *\n * @param {Transaction} transaction      The agent transaction, presumably\n *                                       coming out of the instrumentation.\n * @param {Error}       exception        Something trapped by an error listener.\n * @param {object}      customParameters Any custom parameters associated with\n *                                       the request (optional).\n */\nfunction createError(transaction, exception, customParameters, config) {\n  var name = 'Unknown'\n  var message = ''\n  var type = 'Error'\n  var params = {\n    request_uri: '',\n    userAttributes: {},\n    agentAttributes: {},\n    intrinsics: {}\n  }\n\n  // String errors do not provide us with as much information to provide to the\n  // user, but it is a common pattern.\n  if (typeof exception === 'string') {\n    message = exception\n  } else if (exception !== null && typeof exception === 'object' && exception.message) {\n    message = exception.message\n\n    if (exception.name) {\n      type = exception.name\n    } else if (exception.constructor && exception.constructor.name) {\n      type = exception.constructor.name\n    }\n  } else if (transaction && transaction.statusCode &&\n             urltils.isError(config, transaction.statusCode)) {\n    message = 'HttpError ' + transaction.statusCode\n  }\n\n  if (transaction) {\n    // transaction.getName is expensive due to running normalizers and ignore\n    // rules if a name hasn't been assigned yet. Also has the side effect of\n    // changing the transaction's url property or ignore status.\n    var txName = transaction.getName()\n    if (txName) {\n      name = txName\n    }\n\n    if (transaction.isWeb()) {\n      params.request_uri = transaction.getScrubbedUrl()\n    }\n\n    // Copy all of the parameters off of the transaction.\n    params.agentAttributes = transaction.trace.parameters\n    params.intrinsics = transaction.getIntrinsicAttributes()\n\n    // Custom params aren't filtered by capture_params or ignore_params, just by\n    // high security mode.\n    if (!config.high_security) {\n      urltils.overwriteParameters(config, transaction.trace.custom, params.userAttributes)\n    }\n  }\n  // This will strip out any ignored params or not include the custom params if\n  // capture params is disabled.\n  if (!config.high_security && customParameters) {\n    urltils.overwriteParameters(config, customParameters, params.userAttributes)\n  }\n\n\n  var stack = exception && exception.stack\n  if (stack) params.stack_trace = ('' + stack).split(/[\\n\\r]/g)\n\n  var res = [0, name, message, type, params]\n  if (transaction) {\n    Object.defineProperty(res, 'transaction', {\n      value: transaction.id\n    })\n  }\n  return res\n}\n\n/**\n * Creates a structure for error event that is sent to the collector.\n * The error parameter is an output of the createError() function for a given exception.\n */\nfunction createEvent(transaction, error, timestamp) {\n  var message = error[2]\n  var errorClass = error[3]\n  var paramsFromError = error[4]\n\n  var intrinsicAttributes = _getErrorEventIntrinsicAttrs(transaction, errorClass, message,\n      timestamp)\n\n  // the error structure created by createError() already performs filtering of custom\n  // and agent attributes, so it is ok to just copy them\n  var userAttributes = util._extend({}, paramsFromError.userAttributes)\n  var agentAttributes = util._extend({}, paramsFromError.agentAttributes)\n\n  var errorEvent = [\n    intrinsicAttributes,\n    userAttributes,\n    agentAttributes\n  ]\n\n  return errorEvent\n}\n\nfunction _getErrorEventIntrinsicAttrs(transaction, errorClass, message, timestamp) {\n  // the server expects seconds instead of milliseconds\n  if (timestamp) timestamp = timestamp / 1000\n\n  var attributes = {\n    type: \"TransactionError\",\n    \"error.class\": errorClass,\n    \"error.message\": message,\n    timestamp: timestamp\n  }\n\n  if (transaction) {\n    attributes.transactionName = transaction.name\n    attributes.duration = transaction.timer.getDurationInMillis() / 1000\n\n    var metric = transaction.metrics.getMetric(NAMES.QUEUETIME)\n    if (metric) {\n      attributes.queueDuration = metric.total\n    }\n\n    metric = transaction.metrics.getMetric(NAMES.EXTERNAL.ALL)\n    if (metric) {\n      attributes.externalDuration = metric.total\n      attributes.externalCallCount = metric.callCount\n    }\n\n    metric = transaction.metrics.getMetric(NAMES.DB.ALL)\n    if (metric) {\n      attributes.databaseDuration = metric.total\n      attributes.databaseCallCount = metric.callCount\n    }\n\n    if (transaction.syntheticsData) {\n      attributes[\"nr.syntheticsResourceId\"] = transaction.syntheticsData.resourceId\n      attributes[\"nr.syntheticsJobId\"] = transaction.syntheticsData.jobId\n      attributes[\"nr.syntheticsMonitorId\"] = transaction.syntheticsData.monitorId\n    }\n\n    attributes['nr.transactionGuid'] = transaction.id\n    attributes['nr.referringTransactionGuid'] = transaction.referringTransactionGuid\n\n    if (transaction.port) {\n      attributes.port = transaction.port\n    }\n  } else {\n    attributes.transactionName = 'Unknown'\n  }\n\n  return attributes\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/metrics/index.js":"'use strict'\n\nvar Stats = require('../stats')\nvar ApdexStats = require('../stats/apdex.js')\nvar NAMES = require('./names')\n\n\n/*\n *\n * CONSTANTS\n *\n */\nvar FROM_MILLIS = 1e-3\n\n/**\n * A metric is a set of aggregated data (summary statistics) associated with a\n * metric name. Some metrics belong to scopes, which are typically the name of\n * a transaction or a background task. This class is a collection of mappings\n * from names (or scopes and names) to data, as well as functions for\n * manipulating those data directly. It also can produce a serialized\n * representation suitable for stringifying into JSON and sending to the\n * collector.\n *\n * There are several metrics collections in existence at any given time. Each\n * agent has one metrics collection, which is created at the beginning of each\n * harvest cycle. Each new transaction also gets its own metrics collection,\n * which is merged into the agent's metrics when the transaction is finalized.\n * This allows each set of metrics to be added to the harvest cycle atomically,\n * which guarantees that each transaction will not have its metrics split\n * across multiple harvest cycles. If delivery to the collector fails, the\n * metrics collection associated with the failed delivery can be merged back\n * into the metrics collection for the ongoing harvest cycle.  Finally, if so\n * configured, the agent will have an internal set of supportability metrics\n * that can be used to report information about the operation of the agent.\n *\n * Metrics can be remapped, which is a process by which they are assigned a\n * short, numerical ID by New Relic. This can shrink the serialized JSON\n * considerably. The mapping from transaction name (and scope) happens only\n * at serialization time, which allows the mappings from name to ID to happen\n * on the fly.\n *\n * @param {Number} apdexT The apdex-tolerating value, for use in creating apdex\n *                        statistics.\n * @param {MetricMapper} mapper The mapper that turns metric names into IDs.\n */\nfunction Metrics(apdexT, mapper, normalizer) {\n  if (apdexT === undefined || apdexT === null || apdexT === '') {\n    throw new Error(\"metrics must be created with apdexT\")\n  }\n  if (!mapper) throw new Error(\"metrics must be created with a mapper\")\n  if (!normalizer) throw new Error(\"metrics must be created with a name normalizer\")\n\n  this.started = Date.now()\n  this.apdexT = apdexT\n  this.mapper = mapper\n  this.normalizer = normalizer\n  this.unscoped = {} // {name : stats}\n  this.scoped = {} // {scope : {name : stats}}\n}\n\n/**\n * This is the preferred way for interacting with metrics. Set the duration\n * (and optionally the amount of that duration that was exclusive to that\n * particular metric and not any child operations to that metric) of an\n * operation. If there are no data for the name (and optional scope) existing,\n * the collection will create a set of data before recording the measurement.\n *\n * @param {string} name The name of the metric.\n * @param {string} scope (Optional) The scope to which the metric belongs.\n * @param {Number} duration The duration of the related operation, in milliseconds.\n * @param {Number} exclusive (Optional) The portion of the operation specific to this\n *                           metric.\n * @return {Stats} The aggregated data related to this metric.\n */\nMetrics.prototype.measureMilliseconds = measureMilliseconds\n\nfunction measureMilliseconds(name, scope, duration, exclusive) {\n  var stats = this.getOrCreateMetric(name, scope)\n  stats.recordValueInMillis(duration, exclusive)\n  return stats\n}\n\n/**\n * Set the size of an operation. If there are no data for the name existing,\n * the collection will create a set of data before recording the measurement.\n *\n * @param {string} name The name of the metric.\n * @param {Number} size The size of the related operation, in bytes.\n * @return {Stats} The aggregated data related to this metric.\n */\nMetrics.prototype.measureBytes = function measureBytes(name, size) {\n  var stats = this.getOrCreateMetric(name)\n  stats.recordValueInBytes(size)\n  return stats\n}\n\n/**\n * Look up the mapping from a name (and optionally a scope) to a set of metric\n * data for that name, creating the data if they don't already exist.\n *\n * @param {string} name The name of the requested metric.\n * @param {string} scope (Optional) The scope to which the metric is bound.\n * @return {Stats} The aggregated data for that name.\n */\nMetrics.prototype.getOrCreateMetric = function getOrCreateMetric(name, scope) {\n  if (!name) throw new Error('Metrics must be named')\n\n  var resolved = this._resolve(scope)\n  if (!resolved[name]) resolved[name] = new Stats()\n  return resolved[name]\n}\n\n/**\n * Look up the mapping from a name (and optionally a scope) to a set of metric\n * apdex data for that name, creating the data if they don't already exist.\n *\n * @param {string} name          The name of the requested metric.\n * @param {string} scope         The scope to which the metric is bound\n *                               (optional).\n * @param {number} overrideApdex A custom apdexT for this metric, in\n *                               milliseconds. This will be the same for\n *                               a given run, because key transaction metrics\n *                               are set at connect time via server-side\n *                               configuration.\n *\n * @return {ApdexStats} The aggregated data for that name.\n */\nMetrics.prototype.getOrCreateApdexMetric = getOrCreateApdexMetric\n\nfunction getOrCreateApdexMetric(name, scope, overrideApdex) {\n  if (!name) throw new Error('Metrics must be named')\n\n  var resolved = this._resolve(scope)\n\n  if (!resolved[name]) {\n    // Only use the given override to create the metric if this is not the\n    // global apdex AND we have a valid value.\n    var apdexT = name !== NAMES.APDEX && overrideApdex > 0\n      ? (overrideApdex * FROM_MILLIS) : this.apdexT\n    resolved[name] = new ApdexStats(apdexT)\n  }\n  return resolved[name]\n}\n\n/**\n * Look up a metric, and don't create it if it doesn't exist. Can create scopes\n * as a byproduct, but this function is only intended for use in testing, so\n * it's not a big deal.\n *\n * @param {string} name Metric name.\n * @param {string} scope (Optional) The scope, if any, to which the metric\n *                       belongs.\n * @return {object} Either a stats aggregate, an apdex stats aggregate, or\n *                  undefined.\n */\nMetrics.prototype.getMetric = function getMetric(name, scope) {\n  if (!name) throw new Error('Metrics must be named')\n\n  return this._resolve(scope)[name]\n}\n\n/**\n * Convert this collection into a representation suitable for serialization\n * by JSON.stringify and delivery to the collector. Hope you like nested\n * arrays!\n *\n * @return {Object} Set of nested arrays containing metric information.\n */\nMetrics.prototype.toJSON = function toJSON() {\n  return this._toUnscopedData().concat(this._toScopedData())\n}\n\n/**\n * Combine two sets of metric data. Intended to be used as described above,\n * either when folding a transaction's metrics into the agent's metrics for\n * later harvest, or one harvest cycle's metrics into the next when a\n * delivery attempt to the collector fails. Among the more performance-\n * critical pieces of code in the agent, so some performance tuning would\n * probably be a good idea.\n *\n * @param {Metrics} other The collection to be folded into this one.\n */\nMetrics.prototype.merge = function merge(other) {\n  this.started = Math.min(this.started, other.started)\n\n  Object.keys(other.unscoped).forEach(function cb_forEach(name) {\n    if (this.unscoped[name]) {\n      this.unscoped[name].merge(other.unscoped[name])\n    } else {\n      this.unscoped[name] = other.unscoped[name]\n    }\n  }, this)\n\n  Object.keys(other.scoped).forEach(function cb_forEach(scope) {\n    Object.keys(other.scoped[scope]).forEach(function cb_forEach(name) {\n      if (other.scoped[scope][name]) {\n        var resolved = this._resolve(scope)\n        if (resolved[name]) {\n          resolved[name].merge(other.scoped[scope][name])\n        } else {\n          resolved[name] = other.scoped[scope][name]\n        }\n      }\n    }, this)\n  }, this)\n}\n\n/**\n * Look up the metric namespace belonging to a scope, creating it if it doesn't\n * already exist.\n *\n * @param {string} scope (Optional) The scope to look up.\n * @return {object} The namespace associated with the provided scope, or the\n *                  un-scoped metrics if the scope isn't set.\n */\nMetrics.prototype._resolve = function _resolve(scope) {\n  var resolved\n\n  if (scope) {\n    if (!this.scoped[scope]) this.scoped[scope] = {}\n\n    resolved = this.scoped[scope]\n  } else {\n    resolved = this.unscoped\n  }\n\n  return resolved\n}\n\n/**\n * Map a metric to its nested-array representation, applying any name -> ID\n * mappings along the way. Split from _getScopedData for performance.\n *\n * @param {string} name The string to look up.\n */\nMetrics.prototype._getUnscopedData = function _getUnscopedData(name) {\n  if (!this.unscoped[name]) return\n\n  var normalized = this.normalizer.normalize(name)\n  if (normalized.ignore || !normalized.value) return\n\n  return [this.mapper.map(normalized.value), this.unscoped[name]]\n}\n\n/**\n * Map a metric to its nested-array representation, applying any name -> ID\n * mappings along the way. Split from _getUnscopedData for performance.\n *\n * @param {string} name The string to look up.\n */\nMetrics.prototype._getScopedData = function _getScopedData(name, scope) {\n  if (!this.scoped[scope][name]) return\n\n  var normalized = this.normalizer.normalize(name)\n  if (normalized.ignore || !normalized.value) return\n\n  return [this.mapper.map(normalized.value, scope), this.scoped[scope][name]]\n}\n\n/**\n * @return {object} A serializable version of the unscoped metrics. Intended\n *                  for use by toJSON.\n */\nMetrics.prototype._toUnscopedData = function _toUnscopedData() {\n  var metricData = []\n\n  Object.keys(this.unscoped).forEach(function cb_forEach(name) {\n    var data = this._getUnscopedData(name)\n    if (data) metricData.push(data)\n  }, this)\n\n  return metricData\n}\n\n/**\n * @return {object} A serializable version of the scoped metrics. Intended for\n *                  use by toJSON.\n */\nMetrics.prototype._toScopedData = function _toScopedData() {\n  var metricData = []\n\n  Object.keys(this.scoped).forEach(function cb_forEach(scope) {\n    Object.keys(this.scoped[scope]).forEach(function cb_forEach(name) {\n      var data = this._getScopedData(name, scope)\n      if (data) metricData.push(data)\n    }, this)\n  }, this)\n\n  return metricData\n}\n\nmodule.exports = Metrics\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/stats/index.js":"'use strict'\n\n/*\n *\n * CONSTANTS\n *\n */\nvar BYTES_PER_MB = 1024 * 1024\nvar FROM_MILLIS = 1e-3\n\n\n/**\n * Simple container for tracking running statistics for a metric.\n */\nfunction Stats() {\n  this.total = 0\n  this.totalExclusive = 0\n  this.min = 0\n  this.max = 0\n  this.sumOfSquares = 0\n  this.callCount = 0\n}\n\n/**\n * Update the summary statistics with a new value.\n *\n * @param {Number} totalTime Time, in seconds, of the measurement.\n * @param {Number} exclusiveTime Time that was taken by only the\n *                               current measurement (optional).\n */\nStats.prototype.recordValue = function recordValue(totalTime, exclusiveTime) {\n  // even if a caller messes up, don't break everything else\n  if (totalTime !== 0 && !totalTime) totalTime = 0\n  if (exclusiveTime !== 0 && !exclusiveTime) exclusiveTime = totalTime\n\n  if (this.callCount > 0) {\n    this.min = Math.min(totalTime, this.min)\n  } else {\n    this.min = totalTime\n  }\n  this.max = Math.max(totalTime, this.max)\n\n  this.sumOfSquares += (totalTime * totalTime)\n  this.callCount += 1\n  this.total += totalTime\n  this.totalExclusive += exclusiveTime\n}\n\n/**\n * Until the collector accepts statistics in milliseconds, this code is going\n * to have some hinky floating-point values to deal with.\n */\nStats.prototype.recordValueInMillis = recordValueInMillis\nfunction recordValueInMillis(totalTime, exclusiveTime) {\n  this.recordValue(\n    totalTime * FROM_MILLIS,\n    exclusiveTime >= 0 ? exclusiveTime * FROM_MILLIS : null\n  )\n}\n\n/**\n * Really?\n *\n * FIXME: Really?\n */\nStats.prototype.recordValueInBytes = function recordValueInBytes(bytes, exclusiveBytes) {\n  exclusiveBytes = exclusiveBytes || bytes\n  this.recordValue(bytes / BYTES_PER_MB, exclusiveBytes / BYTES_PER_MB)\n}\n\nStats.prototype.incrementCallCount = function incrementCallCount(count) {\n  if (typeof count === 'undefined') count = 1\n  this.callCount += count\n}\n\n/**\n * Fold another summary's statistics into this one.\n */\nStats.prototype.merge = function merge(other) {\n  if (other.count && !other.callCount) {\n    other.callCount = other.count\n  }\n\n  if (other.totalExclusive == null) {\n    other.totalExclusive = other.total\n  }\n\n  if (other.callCount > 0) {\n    if (this.callCount > 0) {\n      this.min = Math.min(this.min, other.min)\n    } else {\n      this.min = other.min\n    }\n  }\n  this.max = Math.max(this.max, other.max)\n\n  this.total += other.total\n  this.totalExclusive += other.totalExclusive\n  this.sumOfSquares += other.sumOfSquares\n  this.callCount += other.callCount\n}\n\n/**\n * The serializer relies upon this representation, so don't change the\n * values, cardinality, or ordering of this array without ensuring that\n * it matches the version of the \"protocol\" being sent to the collector.\n *\n * @returns {Array} Number of calls,\n *                  total time in seconds,\n *                  time for this metric alone in seconds,\n *                  shortest individual time in seconds,\n *                  longest individual time in seconds,\n *                  running sum of squares.\n */\nStats.prototype.toJSON = function toJSON() {\n  return [\n    this.callCount,\n    this.total,\n    this.totalExclusive,\n    this.min,\n    this.max,\n    this.sumOfSquares\n  ]\n}\n\nmodule.exports = Stats\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/stats/apdex.js":"'use strict'\n\n/*\n *\n * CONSTANTS\n *\n */\nvar FROM_MILLIS = 1e-3\n\n\nfunction ApdexStats(apdexT) {\n  if (!apdexT && apdexT !== 0) {\n    throw new Error('Apdex summary must be created with apdexT.')\n  }\n  this.apdexT = apdexT\n\n  this.satisfying = 0\n  this.tolerating = 0\n  this.frustrating = 0\n}\n\nApdexStats.prototype.recordValue = function recordValue(time, overrideApdex) {\n  var apdexT = overrideApdex || this.apdexT\n  if (time <= apdexT) {\n    ++this.satisfying\n  } else if (time <= 4 * apdexT) {\n    ++this.tolerating\n  } else {\n    ++this.frustrating\n  }\n}\n\nApdexStats.prototype.recordValueInMillis =\nfunction recordValueInMillis(timeInMillis, overrideApdex) {\n  this.recordValue(timeInMillis * FROM_MILLIS, overrideApdex * FROM_MILLIS)\n}\n\n/**\n * Used by the error handler to indicate that a user was frustrated by a page\n * error.\n */\nApdexStats.prototype.incrementFrustrating = function incrementFrustrating() {\n  ++this.frustrating\n}\n\n/**\n * When merging apdex stastics, the apdex tolerating value isn't brought along\n * for the ride.\n *\n * @param {ApdexStats} other The existing apdex stats being merged in.\n */\nApdexStats.prototype.merge = function merge(other) {\n  this.satisfying += other.satisfying\n  this.tolerating += other.tolerating\n  this.frustrating += other.frustrating\n}\n\n/**\n * This feels dirty: ApdexStats override the ordinary statistics serialization\n * format by putting satisfying, tolerating and frustrating values in the\n * first three fields in the array and setting the next two to the apdex (used\n * by calculations inside RPM), followed by 0.\n *\n * @returns {Array} A six-value array where only the first three values are\n *                  significant: satisfying, tolerating, and frustrating\n *                  load times, respectively.\n */\nApdexStats.prototype.toJSON = function toJSON() {\n  return [\n    this.satisfying,\n    this.tolerating,\n    this.frustrating,\n    this.apdexT,\n    this.apdexT,\n    0\n  ]\n}\n\nmodule.exports = ApdexStats\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/metrics/normalizer.js":"'use strict'\n\nvar EventEmitter = require('events').EventEmitter\nvar util = require('util')\nvar arrUtil = require('../util/arrays')\nvar logger = require('../logger').child({component: 'metric_normalizer'})\nvar deepEqual = require('../util/deep-equal')\nvar Rule = require('./normalizer/rule')\nvar NAMES = require('../metrics/names.js')\n\n\nfunction url(normalized, path, config) {\n  if (normalized) return NAMES.NORMALIZED + normalized\n\n  if (config.enforce_backstop) {\n    return NAMES.NORMALIZED + '/*'\n  }\n\n  return NAMES.URI + path\n}\n\nfunction plain(normalized, path) {\n  if (normalized) {\n    return normalized\n  }\n\n  return path\n}\n\n/**\n * The collector keeps track of rules that should be applied to metric names,\n * and sends these rules to the agent at connection time. These rules can\n * either change the name of the metric or indicate that metrics associated with\n * this name (which is generally a URL path) should be ignored altogether.\n *\n * @param {object} config The agent's configuration blob, which has a parameter\n *                        that indicates whether to enforce the normalization\n *                        backstop.\n */\nfunction MetricNormalizer(config, type) {\n  if (!config) throw new Error(\"normalizer must be created with configuration.\")\n  if (!type) throw new Error(\"normalizer must be created with a type.\")\n\n  EventEmitter.call(this)\n\n  this.config = config\n  this.type = type\n  // some mildly cheesy polymorphism to make normalizers work generically\n  if (type === 'URL') {\n    this.formatter = url\n  } else {\n    this.formatter = plain\n  }\n\n  this.rules = []\n}\nutil.inherits(MetricNormalizer, EventEmitter)\n\n// -------------------------------------------------------------------------- //\n\n/**\n * @typedef {Object} NormalizationResults\n *\n * @property {bool}   matched - True if a rule was found that matched.\n * @property {bool}   ignore  - True if the given input should be ignored.\n * @property {string} value   - The normalized input value.\n */\n\n// -------------------------------------------------------------------------- //\n\n/**\n * Convert the raw, de-serialized JSON response into a set of\n * NormalizationRules.\n *\n * @param object json The de-serialized JSON response sent on collector\n *                    connection.\n */\nMetricNormalizer.prototype.load = function load(json) {\n  if (json) {\n    this.rules = []\n    logger.debug(\"Received %s %s normalization rule(s) from the server\",\n      json.length, this.type)\n\n    json.forEach(function cb_forEach(ruleJSON) {\n      // no need to add the same rule twice\n      var rule = new Rule(ruleJSON)\n      if (!arrUtil.find(this.rules, deepEqual.bind(null, rule))) {\n        this.rules.push(rule)\n        logger.trace(\"Loaded %s normalization rule: %s\", this.type, rule)\n      }\n    }, this)\n\n    /* I (FLN) always forget this, so making a note: JS sort is always\n     * IN-PLACE, even though it returns the sorted array.\n     */\n    this.rules.sort(function cb_sort(a, b) {\n      return a.precedence - b.precedence\n    })\n\n    logger.debug(\"Loaded %s %s normalization rule(s).\",\n                 this.rules.length, this.type)\n  }\n}\n\n/**\n * Load any rules found in the configuration into a metric normalizer.\n *\n * Operates via side effects.\n */\nMetricNormalizer.prototype.loadFromConfig = function loadFromConfig() {\n  var rules = this.config.rules\n\n  if (rules && rules.name && rules.name.length > 0) {\n    rules.name.forEach(function cb_forEach(rule) {\n      if (!rule.pattern) {\n        return logger.error(\n          {rule: rule},\n          \"Simple naming rules require a pattern.\"\n        )\n      }\n      if (!rule.name) {\n        return logger.error(\n          {rule: rule},\n          \"Simple naming rules require a replacement name.\"\n        )\n      }\n\n      var precedence = rule.precedence\n      var terminal = rule.terminate_chain\n      var json = {\n        match_expression: rule.pattern,\n        eval_order: (typeof precedence === 'number') ? precedence : 500,\n        terminate_chain: (typeof terminal === 'boolean') ? terminal : true,\n        replace_all: rule.replace_all,\n        replacement: rule.name,\n        ignore: false\n      }\n\n      // Find where the rule should be inserted and do so.\n      var reverse = this.config.feature_flag.reverse_naming_rules\n      var insert = arrUtil.findIndex(this.rules, function findRule(r) {\n        return reverse\n          ? r.precedence >= json.eval_order\n          : r.precedence > json.eval_order\n      })\n      if (insert === -1) {\n        this.rules.push(new Rule(json))\n      } else {\n        this.rules.splice(insert, 0, new Rule(json))\n      }\n    }, this)\n  }\n\n  if (rules && rules.ignore && rules.ignore.length > 0) {\n    rules.ignore.forEach(function cb_forEach(pattern) {\n      this.addSimple(pattern)\n    }, this)\n  }\n}\n\n/**\n * Add simple, user-provided rules to the head of the match list. These rules\n * will always be highest precedence, always will terminate matching, and\n * will always apply to the URL as a whole. If no name is provided, then\n * transactions attached to the matching URLs will be ignored.\n *\n *  - `addSimple(opts)`\n *  - `addSimple(pattern [, name])`\n *\n * @param {RegExp} pattern The pattern to rename (with capture groups).\n * @param {string} [name]  The name to use for the transaction.\n */\nMetricNormalizer.prototype.addSimple = function addSimple(pattern, name) {\n  if (!pattern) return logger.error(\"Simple naming rules require a pattern.\")\n\n  var json = {\n    match_expression: pattern,\n    eval_order: 0,\n    terminate_chain: true,\n    replace_all: false,\n    replacement: null,\n    ignore: false\n  }\n\n  if (name) {\n    json.replacement = name\n  } else {\n    json.ignore = true\n  }\n\n  this.rules.unshift(new Rule(json))\n}\n\n/**\n * Turn a (scrubbed) URL path into partial metric name.\n *\n * @param {string} path - The URL path to turn into a name.\n *\n * @returns {NormalizationResults} - The results of normalization.\n */\nMetricNormalizer.prototype.normalize = function normalize(path) {\n  var last = path\n  var length = this.rules.length\n  var normalized\n  var matched = false\n  var ignored = false\n\n  // Apply each of our rules in turn.\n  for (var i = 0; i < length; i++) {\n    var rule = this.rules[i]\n    var applied = rule.apply(last)\n    if (!rule.matched) {\n      continue\n    }\n\n    if (rule.ignore) {\n      ignored = true\n    } else {\n      matched = true\n      normalized = applied\n\n      // emit event when a rule is matched\n      // we could also include an array of matched rules in the returned map, but\n      // that would increase memory overhead by creating additional array\n      this.emit('appliedRule', rule, normalized, last)\n\n      logger.trace({rule: rule, type: this.type},\n        \"Normalized %s to %s.\", last, normalized)\n      last = normalized\n    }\n\n    if (rule.isTerminal) {\n      logger.trace({rule: rule}, \"Terminating normalization.\")\n      break\n    }\n  }\n\n  // Return the normalized path.\n  return {\n    matched: matched,\n    ignore: ignored,\n    value: this.formatter(normalized, path, this.config)\n  }\n}\n\nmodule.exports = MetricNormalizer\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/util/arrays.js":"'use strict'\n\nexports.find = arrayFind\nexports.findLast = arrayFindLast\nexports.findIndex = arrayFindIndex\nexports.findLastIndex = arrayFindLastIndex\n\n/**\n * Finds the first element in an array that `pred` matches.\n *\n * Remove once Node v0.10, v0.12, v1, v2, and v3 are no longer supported.\n *\n * @deprecated With Node.js v4\n *\n * @param {Array}     arr   - The array to search.\n * @param {Function}  pred  - A predicate function which returns `true` on matches.\n * @param {*}         [ctx] - The `this` arg for `pred`.\n *\n * @return {*?} - The first matching item if found, otherwise `undefined`.\n */\nfunction arrayFind(arr, pred, ctx) {\n  var idx = arrayFindIndex(arr, pred, ctx)\n  if (idx >= 0) {\n    return arr[idx]\n  }\n}\n\n/**\n* Finds the last element in an array that `pred` matches.\n *\n * @param {Array}     arr   - The array to search.\n * @param {Function}  pred  - A predicate function which returns `true` on matches.\n * @param {*}         [ctx] - The `this` arg for `pred`.\n *\n * @return {*?} - The last matching item if found, otherwise `undefined`.\n */\nfunction arrayFindLast(arr, pred, ctx) {\n  var idx = arrayFindLastIndex(arr, pred, ctx)\n  if (idx >= 0) {\n    return arr[idx]\n  }\n}\n\n/**\n * Finds the first index of a single element in an array matching `pred`.\n *\n * Remove once Node v0.10, v0.12, v1, v2, and v3 are no longer supported.\n *\n * @deprecated With Node.js v4\n *\n * @param {Array}     arr   - The array to search.\n * @param {Function}  pred  - A predicate function which returns `true` on matches.\n * @param {*}         [ctx] - The `this` arg for `pred`.\n *\n * @return {number} - The index of the first matching item if found, otherwise `-1`.\n */\nfunction arrayFindIndex(arr, pred, ctx) {\n  for (var i = 0; i < arr.length; ++i) {\n    if (pred.call(ctx, arr[i], i, arr)) {\n      return i\n    }\n  }\n  return -1\n}\n\n/**\n * Finds the last index of a single element in an array matching `pred`.\n *\n * @param {Array}     arr   - The array to search.\n * @param {Function}  pred  - A predicate function which returns `true` on matches.\n * @param {*}         [ctx] - The `this` arg for `pred`.\n *\n * @return {number} - The index of the last matching item if found, otherwise `-1`.\n */\nfunction arrayFindLastIndex(arr, pred, ctx) {\n  for (var i = arr.length - 1; i >= 0; --i) {\n    if (pred.call(ctx, arr[i], i, arr)) {\n      return i\n    }\n  }\n  return -1\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/util/deep-equal.js":"'use strict'\n\nfunction isArguments(object) {\n  return Object.prototype.toString.call(object) === '[object Arguments]'\n}\n\nfunction slice(args) {\n  // Array.prototype.slice on arguments array-like is expensive\n  var l = args.length, a = [], i\n  for (i = 0; i < l; i++) {\n    a[i] = args[i]\n  }\n  return a\n}\n\n/**\n * This is a node-specific version of deepEquals, modeled on bits and pieces\n * of loads of other implementations of this algorithm, most notably the\n * one in the Node.js source and Underscore's. It doesn't throw and handles\n * cycles.\n *\n * Everybody who writes one of these functions puts the documentation\n * inline, which makes it incredibly hard to follow. Here's what this version\n * of the algorithm does, in order:\n *\n * 1. === only tests objects and and functions by reference. Null is an object.\n *    Any pair of identical entities failing this test are therefore objects\n *    (including null), which need a recursive compare by attribute.\n * 2. Since the only matching entities to get to this test must be objects, if\n *    a or b is not an object, they're clearly not the same. All unfiltered a\n *    and b getting are objects (including null).\n * 3. null is an object, but null === null. All unfiltered a and b are non-null\n *    objects.\n * 4. Buffers need to be special-cased because they live partially on the wrong\n *    side of the C++ / JavaScript barrier. Still, calling this on structures\n *    that can contain Buffers is a bad idea, because they can contain\n *    multiple megabytes of data and comparing them byte-by-byte is very\n *    expensive. buffertools is a better solution here, but this version of\n *    this code is dependency free.\n * 5. It's much faster to compare dates by numeric value than by lexical value.\n * 6. Same goes for Regexps.\n * 7. The parts of an arguments list most people care about are the arguments\n *    themselves, not the callee, which you shouldn't be looking at anyway.\n * 8. Objects are more complex:\n *    a. ensure that a and b are on the same constructor chain\n *    b. ensure that a and b have the same number of own properties (which is\n *       what Object.keys returns).\n *    c. ensure that cyclical references don't blow up the stack.\n *    d. ensure that all the key names match (faster)\n *    e. ensure that all of the associated values match, recursively (slower)\n *\n * (SOMEWHAT UNTESTED) ASSUMPTIONS:\n *\n * o Functions are only considered identical if they unify to the same\n *   reference. To anything else is to invite the wrath of the halting problem.\n * o V8 is smart enough to optimize treating an Array like any other kind of\n *   object.\n * o Users of this function are cool with mutually recursive data structures\n *   that are otherwise identical being treated as the same.\n */\nfunction deeper(a, b, ca, cb) {\n  if (a === b) {\n    return true\n  } else if (typeof a !== 'object' || typeof b !== 'object') {\n    return false\n  } else if (a === null || b === null) {\n    return false\n  } else if (Buffer.isBuffer(a) && Buffer.isBuffer(b)) {\n    if (a.length !== b.length) return false\n\n    // potentially incredibly expensive\n    for (var i = 0; i < a.length; i++) if (a[i] !== b[i]) return false\n\n    return true\n  } else if (a instanceof Date && b instanceof Date) {\n    return a.getTime() === b.getTime()\n  } else if (a instanceof RegExp && b instanceof RegExp) {\n    return a.source === b.source &&\n           a.global === b.global &&\n           a.multiline === b.multiline &&\n           a.lastIndex === b.lastIndex &&\n           a.ignoreCase === b.ignoreCase\n  } else if (isArguments(a) || isArguments(b)) {\n    if (!(isArguments(a) && isArguments(b))) return false\n\n    return deeper(slice(a), slice(b), ca, cb)\n  }\n\n  if (a.constructor !== b.constructor) return false\n\n  var ka = Object.keys(a), kb = Object.keys(b)\n  if (ka.length !== kb.length) return false\n\n  var cal = ca.length\n  while (cal--) if (ca[cal] === a) return cb[cal] === b\n  ca.push(a); cb.push(b)\n\n  ka.sort(); kb.sort()\n  for (var j = ka.length - 1; j >= 0; j--) if (ka[j] !== kb[j]) return false\n\n  var key\n  for (var k = ka.length - 1; k >= 0; k--) {\n    key = ka[k]\n    if (!deeper(a[key], b[key], ca, cb)) return false\n  }\n\n  ca.pop(); cb.pop()\n\n  return true\n}\n\nmodule.exports = function exports(a, b) {\n  return deeper(a, b, [], [])\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/metrics/normalizer/rule.js":"'use strict'\n\nvar logger = require('../../logger').child({component: 'normalizer_rule'})\n\n\n/**\n * JavaScript just has to do things slightly differently.\n */\nvar replaceReplacer = function replaceReplacer(input) {\n  return input.replace(/\\\\/g, '$')\n}\n\n/**\n * Be liberal about accepting incomplete information, because we don't want\n * bad rules from the collector to crash client apps. Otherwise, this is a\n * fairly straightforward mapping of the concepts in metric normalization\n * rules into an object form.\n *\n * @param {Object} json A JavaScript object literal parsed out from the JSON\n *                      from the collector.\n */\nfunction NormalizerRule(json) {\n  if (!json) {\n    logger.debug(\n      \"Received incompletely specified metric normalization rule from collector.\"\n    )\n    json = {}\n  }\n\n  this.eachSegment = json.each_segment || false\n  this.precedence = json.eval_order || 0\n  this.isTerminal = json.terminate_chain || false\n  this.replacement = replaceReplacer(json.replacement || '$0')\n  this.replaceAll = json.replace_all || false\n  this.ignore = json.ignore || false\n  this.matched = false\n\n  var modifiers = 'i'\n  if (this.replaceAll) modifiers += 'g'\n\n  // don't allow this to fail\n  if (json.match_expression instanceof RegExp) {\n    this.pattern = _addRegExpFlags(json.match_expression, modifiers)\n  } else {\n    try {\n      this.pattern = new RegExp(json.match_expression || '^$', modifiers)\n    } catch (error) {\n      logger.warn(error, \"Problem compiling metric normalization rule pattern.\")\n      this.pattern = /^$/\n    }\n  }\n}\n\n/**\n * Allow the higher-level functions to operate on input uniformly.\n *\n * @param {string} input URL to potentially be split.\n */\nNormalizerRule.prototype.getSegments = function getSegments(input) {\n  if (this.eachSegment) {\n    return input.split('/')\n  }\n\n  return [input]\n}\n\n/**\n * Check if a URL matches a rule.\n *\n * Does not set {NormalizerRule#matched}.\n *\n * @param {string} input - URL to match.\n *\n * @return {bool} - True if this rule matches the given input, otherwise false.\n */\nNormalizerRule.prototype.matches = function matches(input) {\n  var segments = this.getSegments(input)\n\n  for (var i = 0; i < segments.length; ++i) {\n    if (this.pattern.test(segments[i])) {\n      return true\n    }\n  }\n\n  return false\n}\n\n/**\n * Apply the substitutions, if any, to the input.\n *\n * Also sets {NormalizerRule#matched} to true if this rule did match the given\n * input.\n *\n * String.split will return empty segments when the path has a leading slash or\n * contains a run of slashes. Don't inadvertently substitute or drop these empty\n * segments, or the normalized path will be wrong.\n *\n * XXX In Node v0.8 and Node v0.10, `RegExp#test` advances internal state and\n * XXX tracks where it left off from the previous match. This has the side\n * XXX effect that reusing the same object may cause false negatives if you do\n * XXX not reset that state. The only way to reset the state is to set\n * XXX `RegExp#lastIndex` to `0`.\n *\n * @param {string} input - URL to normalize.\n *\n * @return {string?} - The normalized url, or `null` if this is an ignore rule\n *  that matched this url.\n */\nNormalizerRule.prototype.apply = function apply(input) {\n  // For ignore rules, just see if we match and return either `null` or the\n  // original input.\n  if (this.ignore) {\n    return (this.matched = this.matches(input)) ? null : input\n  }\n\n  this.matched = false\n  var result = this.getSegments(input)\n    .map(function applyMap(segment) {\n      // Discussion of why we use `lastIndex` in function documentation to\n      // prevent de-opt due to long function.\n      this.pattern.lastIndex = 0\n      if (segment && this.pattern.test(segment)) {\n        this.matched = true\n        return segment.replace(this.pattern, this.replacement)\n      }\n      return segment\n    }, this)\n    .join('/')\n  return input[0] === '/' && result[0] !== '/' ? '/' + result : result\n}\n\nNormalizerRule.prototype.toJSON = function toJSON() {\n  return {\n    eachSegment: this.eachSegment,\n    precedence: this.precedence,\n    isTerminal: this.isTerminal,\n    replacement: this.replacement,\n    replaceAll: this.replaceAll,\n    ignore: this.ignore,\n    pattern: this.pattern.source\n  }\n}\n\n/**\n * Merges the given flags with those already in a regular expression.\n *\n * @param {RegExp} re     - The regular expression to add flags to.\n * @param {string} flags  - The flags to add to the regex.\n *\n * @return {RegExp} - A regular expression with all the given flags added.\n */\nfunction _addRegExpFlags(re, flags) {\n  var foundMissing = false\n  var reFlags = _getRegExpFlags(re)\n  for (var i = 0; i < flags.length; ++i) {\n    if (reFlags.indexOf(flags[i]) === -1) {\n      foundMissing = true\n      reFlags += flags[i]\n    }\n  }\n  return foundMissing ? new RegExp(re.source, reFlags) : re\n}\n\n/**\n * Pulls all the flags for a regular expression.\n *\n * @param {RegExp} re - The regular expression to extract the flags of.\n *\n * @return {string} - The regex flags.\n */\nfunction _getRegExpFlags(re) {\n  // Available in Node >6.\n  if ('flags' in re) {\n    return re.flags\n  }\n\n  // Remove this logic once we've deprecated Node <=4, so in 2030.\n  var flags = ''\n  if (re.global) {\n    flags += 'g'\n  }\n  if (re.ignoreCase) {\n    flags += 'i'\n  }\n  if (re.multiline) {\n    flags += 'm'\n  }\n  if (re.sticky) {\n    flags += 'y'\n  }\n  if (re.unicode) {\n    flags += 'u'\n  }\n  return flags\n}\n\nmodule.exports = NormalizerRule\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/metrics/normalizer/tx_segment.js":"'use strict'\n\nvar logger = require('../../logger').child({component: 'tx_segment_normalizer'})\n\nmodule.exports = TxSegmentNormalizer\n\nfunction TxSegmentNormalizer() {\n  this.terms = []\n}\n\n/**\n * This normalize method is wicked. The best bet is to read the spec:\n * https://newrelic.atlassian.net/wiki/pages/viewpage.action?spaceKey=eng&title=Language+agent+transaction+segment+terms+rules\n *\n * A copy paste of the rules that were followed:\n *  1. Find the first rule where the prefix key matches the prefix of the\n *     transaction name. If no matching rules are found, abort.\n *  2. Strip the prefix from the transaction name.\n *  3. Split the rest of the transaction name into segments on slashes ('/').\n *  4. For each segment:\n *      If the segment appears in the array of strings given under the terms key,\n *      keep it unchanged. Else, replace it with a placeholder ('*')\n *  5. Collapse all adjacent placeholder segments into a single '*' segment.\n *  6. Join together the modified segments with slashes, and re-prepend the prefix.\n *\n * @param {string} path - The transaction metric path to normalize.\n *\n * @return {NormalizationResults} - The results of normalizing the given path.\n */\nTxSegmentNormalizer.prototype.normalize = function normalize(path) {\n  var currentTerm\n  var prefix\n  for (var i = 0; i < this.terms.length; i++) {\n    currentTerm = this.terms[i]\n    prefix = currentTerm.prefix\n    if (path.lastIndexOf(prefix, 0) === -1) {\n      continue\n    }\n    var fragment = path.slice(prefix.length)\n    var parts = fragment.split('/')\n    var result = []\n    var prev\n\n    var segment\n    for (var j = 0; j < parts.length; j++) {\n      segment = parts[j]\n\n      if (segment === '' && j + 1 === parts.length) break\n\n      if (currentTerm.terms.indexOf(segment) === -1) {\n        if (prev === '*') continue\n        result.push(prev = '*')\n      } else {\n        result.push(prev = segment)\n      }\n    }\n    logger.trace('Normalizing %s because of rule: %s', path, currentTerm)\n    return {\n      matched: true, // To match MetricNormalizer\n      ignore: false, // ^^\n      value: prefix + result.join('/')\n    }\n  }\n\n  return {\n    matched: false, // To match MetricNormalizer\n    ignore: false,  // ^^\n    value: path\n  }\n}\n\nTxSegmentNormalizer.prototype.load = function load(json) {\n  if (Array.isArray(json)) {\n    this.terms = filterRules(json)\n  } else {\n    logger.warn(\n      'transaction_segment_terms was not an array got: %s (%s)',\n      typeof json,\n      json\n    )\n  }\n}\n\nfunction filterRules(rules) {\n  var map = {}\n\n  for (var i = 0, l = rules.length; i < l; ++i) {\n    var prefix = rules[i].prefix\n\n    if (!prefix || typeof prefix !== 'string') continue\n\n    if (prefix[prefix.length - 1] !== '/') {\n      prefix = prefix + '/'\n      rules[i].prefix = prefix\n    }\n\n    var segments = prefix.split('/')\n    if (segments.length !== 3 || !segments[0] || !segments[1] || segments[3]) continue\n\n    if (Array.isArray(rules[i].terms)) {\n      map[prefix] = rules[i]\n    }\n  }\n\n  var keys = Object.keys(map)\n  var filtered = new Array(keys.length)\n\n  for (i = 0, l = keys.length; i < l; ++i) {\n    filtered[i] = map[keys[i]]\n  }\n\n  return filtered\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/metrics/mapper.js":"'use strict'\n\nvar logger = require('../logger').child({component: 'mapper'})\n\n\n/**\n * To tighten up the metrics JSON, the collector will maintain a list of\n * mappings from metric names (which sometimes include scopes as well) to\n * numeric IDs. As the agent sends new metric names to the collector, the\n * collector will return corresponding metric IDs, in the expectation that the\n * agent will uses those IDs instead of the names going forward.\n *\n * @param {Array} raw A list of metric spec -> ID mappings represented as\n *                    2-element arrays: [{name : 'Metric', scope : 'Scope'}, 1]\n */\nfunction MetricMapper(raw) {\n  this.unscoped = {}\n  this.scoped = {}\n  this.length = 0\n\n  this.load(raw)\n}\n\n/**\n * Parse the list of metric mappings returned on metric_data responses from the\n * collector. These continue to stream in as the agent runs, so keep adding to\n * the collection rather than resetting.\n *\n * https://hudson.newrelic.com/job/collector-master/javadoc/com/nr/collector/datatypes/MetricData.html\n *\n * @param {Array} raw A list of metric spec -> ID mappings represented as\n *                    2-element arrays: [{name : 'Metric', scope : 'Scope'}, 1]\n */\nMetricMapper.prototype.load = function load(raw) {\n  if (!(raw && raw.length)) {\n    logger.debug(\"No new metric mappings from server.\")\n    return\n  }\n\n  for (var i = 0; i < raw.length; i++) {\n    var spec = raw[i][0]\n    var scope = spec.scope\n    var name = spec.name\n    var id = raw[i][1]\n    var resolved\n\n\n    if (scope) {\n      if (!this.scoped[scope]) this.scoped[scope] = {}\n      resolved = this.scoped[scope]\n    } else {\n      resolved = this.unscoped\n    }\n\n    if (!resolved[name]) this.length++\n    resolved[name] = id\n    logger.trace(\"Metric spec %s has been mapped to ID %s.\", spec, id)\n  }\n  logger.debug(\"Parsed %d metric ids (%d total).\", raw.length, this.length)\n}\n\n/**\n * @param {String} name  The metric name.\n * @param {String} scope The scope for the metric, if set.\n *\n * @returns {object} Either a metric spec based on the parameters, or the\n *                   server-sent ID.\n */\nMetricMapper.prototype.map = function map(name, scope) {\n  if (scope) {\n    if (this.scoped[scope] && this.scoped[scope][name]) {\n      return this.scoped[scope][name]\n    }\n    return {name: name, scope: scope}\n  }\n\n  if (this.unscoped[name]) {\n    return this.unscoped[name]\n  }\n\n  return {name: name}\n}\n\nmodule.exports = MetricMapper\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/transaction/trace/aggregator.js":"'use strict'\n\nvar logger = require('../../logger').child({component: 'trace-aggregator'})\n\n/*\n *\n * CONSTANTS\n *\n */\nvar TO_MILLIS = 1e3\n\n/**\n * Locus for the complicated logic surrounding the selection of slow\n * transaction traces for submission to the collector.\n *\n * @param {object} config Dictionary containing transaction tracing\n *                        parameters. Required.\n */\nfunction TraceAggregator(config) {\n  if (!config) throw new Error(\"Trace aggregator needs configuration at creation.\")\n  /*eslint-disable */\n  /*\n   * From\n   * \n   * https://newrelic.atlassian.net/wiki/display/eng/Transaction+Trace+Collection+Improvements\n   *\n   * 5 Transaction Trace Guarantee\n   *\n   * For the initial experience problem, the Agent will sample up to 1\n   * transaction per minute until it has sampled 5 transactions. This\n   * guarantees that the agent will always report some transaction traces.\n   * There is no time out for this sampling period - the agent always\n   * samples until it has collected 5 transactions. The agent doesn't\n   * simply report the first 5 transactions that it sees because it's\n   * likely (particularly for a local dev test) that all 5 transactions\n   * would be associated with one request (a single web page and its\n   * resources).\n   */\n  /*eslint-enable */\n\n\n  this.reported = 0\n  this.config = config\n\n  // Setting up top n capacity.\n  this.capacity = 1\n  if (config.transaction_tracer &&\n      config.transaction_tracer.top_n) {\n    this.capacity = config.transaction_tracer.top_n\n  }\n\n  // hidden class optimization\n  this.trace = null\n  this.syntheticsTraces = []\n  this.requestTimes = {}\n  this.noTraceSubmitted = 0\n}\n\n/**\n * For every five harvest cycles (or \"minutes\"), if no new slow transactions\n * have been added, reset the requestTime match and allow a new set of five\n * to start populating the Top N Slow Trace list.\n */\nTraceAggregator.prototype.resetTimingTracker = function resetTT() {\n  this.requestTimes = {}\n  this.noTraceSubmitted = 0\n}\n\n/**\n * Add a trace to the slow trace list, if and only if it fulfills the necessary\n * criteria.\n *\n * @param {Transaction} transaction The transaction, which we need to check\n *                                  apdexT, as well as getting the trace.\n */\nTraceAggregator.prototype.add = function add(transaction) {\n  if (this.config.collect_traces &&\n      this.config.transaction_tracer && this.config.transaction_tracer.enabled &&\n      transaction && transaction.metrics) {\n    var trace = transaction.trace\n    var name = transaction.name\n    var duration = trace.getDurationInMillis()\n    var apdexT = transaction.metrics.apdexT\n\n    if (transaction.syntheticsData && this.syntheticsTraces.length < 20) {\n      this.syntheticsTraces.push(trace)\n    } else if (this.isBetter(name, duration, apdexT)) {\n      this.trace = trace\n\n      // because of the \"first 5\" rule, this may or may not be the slowest\n      if (!this.requestTimes[name] || this.requestTimes[name] < duration) {\n        this.requestTimes[name] = duration\n      }\n    }\n\n    this.config.measureInternal('Transaction/Count', duration)\n  }\n}\n\n/**\n * If there's a slow trace to be sent, encode it and pass it along\n * to the callback, otherwise update the relevant trace diversity settings.\n *\n * @param Function callback The receiver of the encoded trace or errors.\n */\nTraceAggregator.prototype.harvest = function harvest(callback) {\n  var tracesToAggregate = 0\n  var encodedTraces = []\n  var errored = false\n  var normalTrace = null\n\n  // Synthetics\n  for (var i = 0, len = this.syntheticsTraces.length; i < len; ++i) {\n    this.syntheticsTraces[i].generateJSON(resultAggregator)\n    tracesToAggregate++\n  }\n\n  if (this.trace) {\n    var max = this.trace.transaction.agent.config.max_trace_segments\n    if (this.trace.segmentsSeen > max) {\n      logger.warn(\n        'transaction %s contained %d segments, only collecting the first %d',\n        this.trace.transaction.name,\n        this.trace.segmentsSeen,\n        max\n      )\n    }\n    normalTrace = this.trace\n    this.noTraceSubmitted = 0\n    this.trace.generateJSON(resultAggregator)\n    tracesToAggregate++\n  } else {\n    this.noTraceSubmitted++\n    if (this.noTraceSubmitted >= 5) this.resetTimingTracker()\n  }\n\n  if (tracesToAggregate === 0) {\n    process.nextTick(function cb_nextTick() {\n      callback(null, null, null)\n    })\n  }\n\n  function resultAggregator(err, encoded) {\n    if (errored) {\n      return\n    }\n\n    if (err) {\n      errored = true\n      callback(err)\n    }\n\n    encodedTraces.push(encoded)\n\n    if (encodedTraces.length === tracesToAggregate) {\n      callback(null, encodedTraces, normalTrace)\n    }\n  }\n}\n\n/**\n * Reset the trace diversity settings after a successful harvest.\n *\n * @param {Trace} trace Because the harvest cycle can take a while,\n *                      it's possible a better trace came along\n *                      in the window between the start and end of\n *                      the harvest cycle, so don't throw that away.\n */\nTraceAggregator.prototype.reset = function reset(trace) {\n  this.reported++\n  if (trace === this.trace) this.trace = null\n  this.syntheticsTraces = []\n}\n\n/*eslint-disable */\n/**\n * Determine whether a new trace is more worth keeping than an old one.\n * This gets called on every single transactionFinished event, so return as\n * quickly as possible and call as few external functions as possible. On the\n * converse, there's some complicated logic here, so spell things out.\n *\n * All specifications are from\n * https://newrelic.atlassian.net/wiki/display/eng/Transaction+Trace+Collection+Improvements\n *\n * @param {string} name     Name of this transaction's key metric.\n * @param {number} duration Time the transaction took, in milliseconds.\n * @param {number} apdexT   Apdex tolerating threshold, in seconds.\n */\n/*eslint-enable */\nTraceAggregator.prototype.isBetter = function isBetter(name, duration, apdexT) {\n  /* 1. If the transaction duration is below the tracing threshold, the\n   *    transaction is skipped.\n   *\n   * The threshold for slow traces defaults to apdex_f, which is 4 * apdex_t.\n   */\n  var config = this.config.transaction_tracer\n  var isOverThreshold\n\n  if (config &&\n      config.transaction_threshold &&\n      config.transaction_threshold !== 'apdex_f' &&\n      typeof config.transaction_threshold === 'number') {\n    isOverThreshold = duration > config.transaction_threshold * TO_MILLIS\n  } else {\n    isOverThreshold = duration > 4 * TO_MILLIS * apdexT\n  }\n  if (!isOverThreshold) return false\n\n  /* 2. If the transaction duration is less than the duration of the current\n   *    slow transaction, the transaction is skipped.\n   */\n  var slowerThanExisting = true\n  if (this.trace) {\n    slowerThanExisting = this.trace.getDurationInMillis() < duration\n  }\n  if (!slowerThanExisting) return false\n\n  /* We always gather some slow transactions at the start, regardless of\n   * the size of Top N. This changes the behavior of the rest of the\n   * decision-making process in some subtle ways.\n   */\n  var hasMetGuarantee = this.reported >= 5\n\n  /* 3. If the transaction's name is in the transaction map and its duration\n   *    is less than the response time in the map, it is skipped.\n   */\n  var slowerThanCaptured = true\n  if (hasMetGuarantee) {\n    if (this.requestTimes[name]) {\n      slowerThanCaptured = this.requestTimes[name] < duration\n    }\n  }\n  if (!slowerThanCaptured) return false\n\n  /* Not part of enumerated rules, but necessary for Top N support:\n   * Ensure this name is either already in the request time map\n   * or that the map still hasn't hit capacity.\n   */\n  if (hasMetGuarantee &&\n      !this.requestTimes[name] &&\n      Object.keys(this.requestTimes).length >= this.capacity) {\n    return false\n  }\n\n  /* 4. The transaction is held as the slowest transaction.\n   */\n  return true\n}\n\nmodule.exports = TraceAggregator\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/uninstrumented.js":"'use strict'\n\nvar path = require('path')\nvar logger = require('./logger')\nvar NAMES = require('./metrics/names')\nvar INSTRUMENTATIONS = require('./instrumentations')()\n\nmodule.exports = {\n  check: check,\n  createMetrics: createMetrics\n}\n\n\n// Special case since we do some hackish stuff in lib/shimmer.js to make pg.js\n// work\nINSTRUMENTATIONS.push('pg.js')\n\n// Static variable holding list of un-instrumented modules for use in the future\nvar uninstrumented = []\n\n// Log a helpful message about un-instrumented modules\nfunction logUninstrumented() {\n  if (uninstrumented.length > 0) {\n    var message =\n      'The newrelic module must be the first module required.\\n' +\n      'The following modules were required before newrelic and are not being ' +\n      'instrumented:'\n\n    uninstrumented.forEach(function buildMessage(module) {\n      message += '\\n\\t' + module.name + ': ' + module.filename\n    })\n\n    logger.warn(message)\n  }\n}\n\n// Create Supportability/Uninstrumented/<module> metrics\n//\n// @param metrics Agent metrics aggregator\nfunction createMetrics(metrics) {\n  if (uninstrumented.length > 0) {\n    metrics.getOrCreateMetric(NAMES.SUPPORTABILITY.UNINSTRUMENTED).incrementCallCount()\n  }\n\n  uninstrumented.forEach(function addMetrics(module) {\n    metrics.getOrCreateMetric(\n      NAMES.SUPPORTABILITY.UNINSTRUMENTED + '/' + module.name\n    ).incrementCallCount()\n  })\n}\n\n// Determine module name from filename of module's main script\n//\n// Heuristic: take the first path name that isn't 'index.js' or 'lib'.\n//\n// @param filename Filename of module's main script\n// @return Name of module\nfunction moduleNameFromFilename(filename) {\n  var name = path.basename(filename, '.js')\n  if (name !== 'index') return name\n\n  var paths = filename.split(path.sep).slice(0, -1)\n  for (var i = paths.length - 1; i >= 0; i--) {\n    if (paths[i] !== 'lib') return paths[i]\n  }\n}\n\n// Check for any instrument-able modules that have already been loaded. This does\n// not check core modules as we don't have access to the core module loader\n// cache. But, users probably are missing instrumentation for other modules if\n// they are missing instrumentation for core modules.\nfunction check() {\n  for (var filename in require.cache) {\n    if (!require.cache.hasOwnProperty(filename)) {\n      continue\n    }\n    var name = moduleNameFromFilename(filename)\n\n    if (INSTRUMENTATIONS.indexOf(name) !== -1) {\n      uninstrumented.push({name: name, filename: filename})\n    }\n  }\n\n  logUninstrumented()\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/instrumentations.js":"'use strict'\n\n// Return a new copy of this array every time we're called\nmodule.exports = function instrumentations() {\n  return [\n    'connect',\n    'bluebird',\n    'director',\n    'express',\n    'generic-pool',\n    'hapi',\n    'memcached',\n    'mongodb',\n    'mysql',\n    'node-cassandra-cql',\n    'cassandra-driver',\n    'pg',\n    'q',\n    'redis',\n    'ioredis',\n    'restify',\n    'oracle',\n    'when'\n  ]\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/db/tracer.js":"'use strict'\n\nvar logger = require('../logger').child({component: 'query_tracer'})\nvar obfuscate = require('../util/sql/obfuscate')\nvar Stats = require('../stats')\nvar util = require('util')\nvar crypto = require('crypto')\nvar encode = require('../util/codec.js').encode\nvar path = require('path')\n\nvar NR_ROOT = path.resolve(__dirname, '..')\n\nmodule.exports = QueryTracer\n\nfunction QueryTracer(config) {\n  if (!(this instanceof QueryTracer)) {\n    return new QueryTracer(config)\n  }\n  this.samples = {}\n  this.config = config\n}\n\nQueryTracer.prototype.removeShortest = function removeShortest() {\n  var keys = Object.keys(this.samples)\n  var shortest\n\n\n  for (var i = 0, len = keys.length; i < len; ++i) {\n    var sample = this.samples[keys[i]].trace\n    if (!shortest || shortest.duration > sample.duration) {\n      shortest = sample\n    }\n  }\n\n  delete this.samples[shortest.normalized]\n}\n\nQueryTracer.prototype.merge = function merge(tracer) {\n  var keys = Object.keys(tracer.samples)\n\n  for (var i = 0, len = keys.length; i < len; ++i) {\n    if (this.samples[keys[i]]) {\n      this.samples[keys[i]].merge(tracer.samples[keys[i]])\n    } else {\n      this.samples[keys[i]] = tracer.samples[keys[i]]\n    }\n  }\n}\n\nQueryTracer.prototype.addQuery = function addQuery(segment, type, query, trace) {\n  var duration = segment.getDurationInMillis()\n\n  if (duration < this.config.transaction_tracer.explain_threshold) return\n\n  var slowQuery = new SlowQuery(segment, type, query, trace)\n\n  switch (this.config.transaction_tracer.record_sql) {\n    case 'raw':\n      logger.info('recording raw sql')\n      segment.parameters.sql = slowQuery.query\n      break\n    case 'obfuscated':\n      logger.info('recording obfuscated sql')\n      segment.parameters.sql_obfuscated = slowQuery.obfuscated\n      break\n    default:\n      logger.info(\n        'not collecting slow-query because transaction_tracer.record_sql was set to %s',\n        this.config.transaction_tracer.record_sql\n      )\n      return\n  }\n  segment.parameters.backtrace = slowQuery.trace\n\n  if (!this.config.slow_sql.enabled) return\n\n  if (this.samples[slowQuery.normalized]) {\n    return this.samples[slowQuery.normalized].aggregate(slowQuery)\n  }\n\n  this.samples[slowQuery.normalized] = new QuerySample(this, slowQuery)\n\n  if (Object.keys(this.samples).length > this.config.slow_sql.max_samples) {\n    this.removeShortest()\n  }\n}\n\nQueryTracer.prototype.prepareJSON = function prepareJSON(done) {\n  var keys = Object.keys(this.samples)\n  var remaining = keys.length\n  var data = []\n\n  if (!remaining) return done(null, data)\n\n  for (var i = 0; i < keys.length; ++i) {\n    this.samples[keys[i]].prepareJSON(collect)\n  }\n\n  function collect(err, json) {\n    if (err) {\n      done(err)\n      // turn callback into a noop so it can't be called more than once\n      done = noop\n      return\n    }\n\n    data.push(json)\n    if (!--remaining) done(null, data)\n  }\n\n  function noop() {}\n}\n\nfunction QuerySample(tracer, slowQuery) {\n  Stats.call(this)\n  this.tracer = tracer\n  this.trace = slowQuery\n  this.aggregate(slowQuery)\n}\n\nutil.inherits(QuerySample, Stats)\n\nQuerySample.prototype.aggregate = function aggregate(slowQuery) {\n  this.recordValue(slowQuery.duration)\n  if (this.trace && this.trace.duration >= slowQuery.duration) return\n  this.trace = slowQuery\n}\n\nQuerySample.prototype.merge = function merge(sample) {\n  Stats.prototype.merge.call(this, sample)\n  if (this.trace.duration < sample.trace.duration) {\n    this.trace = sample.trace\n  }\n}\n\nQuerySample.prototype.prepareJSON = function prepareJSON(done) {\n  var transaction = this.trace.segment.transaction\n  var sample = this\n  var trace = sample.trace\n\n  var params = sample.getParams()\n  if (!this.tracer.config.simple_compression) {\n    encode(params, respond)\n  } else {\n    process.nextTick(respond.bind(null, null, params))\n  }\n\n  function respond(err, data) {\n    if (err) return done(err)\n\n    done(null, [\n      transaction.name,\n      transaction.url || '<unknown>',\n      trace.id,\n      getQuery(sample.tracer.config, trace),\n      trace.metric,\n      sample.callCount,\n      sample.total,\n      sample.min,\n      sample.max,\n      data\n    ])\n  }\n}\n\nQuerySample.prototype.getParams = function getParams() {\n  var segmentParams = this.trace.segment.parameters\n  var params = {\n    backtrace: this.trace.trace,\n  }\n\n  if (segmentParams.host) {\n    params.host = segmentParams.host\n  }\n\n  if (segmentParams.port_path_or_id) {\n    params.port_path_or_id = segmentParams.port_path_or_id\n  }\n\n  if (segmentParams.database_name) {\n    params.database_name = segmentParams.database_name\n  }\n\n  return params\n}\n\nfunction SlowQuery(segment, type, query, trace) {\n  this.obfuscated = obfuscate(query, type)\n  this.normalized = this.obfuscated.replace(/\\?\\s*,\\s*|\\s*/g, '')\n  this.id = normalizedHash(this.normalized)\n  this.segment = segment\n  this.query = query\n  this.metric = segment.name\n  this.trace = formatTrace(trace)\n  this.duration = segment.getDurationInMillis()\n}\n\nfunction normalizedHash(value) {\n  return parseInt(crypto.createHash('md5').update(value).digest('hex').slice(-4), 16)\n}\n\nfunction formatTrace(trace) {\n  // remove error message and instrumentation frames from stack trace\n  return trace ? trace.stack.split('\\n').slice(1).filter(notNR).join('\\n') : ''\n}\n\nfunction notNR(frame) {\n  return frame.indexOf(NR_ROOT) === -1\n}\n\nfunction getQuery(config, trace) {\n  switch (config.transaction_tracer.record_sql) {\n    case 'raw':\n      return trace.query\n    case 'obfuscated':\n      return trace.obfuscated\n    default:\n      return '?'\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/util/sql/obfuscate.js":"'use strict'\n\nmodule.exports = obfuscate\n\nvar singleQuote = /'(?:[^']|'')*?(?:\\\\'.*|'(?!'))/\nvar doubleQuote = /\"(?:[^\"]|\"\")*?(?:\\\\\".*|\"(?!\"))/\nvar dollarQuote = /(\\$(?!\\d)[^$]*?\\$).*?(?:\\1|$)/\nvar oracleQuote = /q'\\[.*?(?:\\]'|$)|q'\\{.*?(?:\\}'|$)|q'\\<.*?(?:\\>'|$)|q'\\(.*?(?:\\)'|$)/\nvar comment = /(?:#|--).*?(?=\\r|\\n|$)/\nvar multilineComment = /\\/\\*(?:[^/]|\\/[^*])*?(?:\\*\\/|\\/\\*.*)/\nvar uuid = /\\{?(?:[0-9a-f]\\-*){32}\\}?/\nvar hex = /0x[0-9a-f]+/\nvar boolean = /true|false|null/\nvar number = /\\b-?(?:[0-9]+\\.)?[0-9]+([eE][+-]?[0-9]+)?/\n\nvar dialects = {}\n\ndialects.mysql = [\n  replacer(join(\n    [doubleQuote, singleQuote, comment, multilineComment, hex, boolean, number],\n    'gi'\n  )),\n  unmatchedPairs(/'|\"|\\/\\*|\\*\\//)\n]\n\ndialects.postgres = [\n  replacer(join(\n    [dollarQuote, singleQuote, comment, multilineComment, uuid, boolean, number],\n    'gi'\n  )),\n  unmatchedPairs(/'|\\/\\*|\\*\\/|\\$/)\n]\n\ndialects.cassandra = [\n  replacer(join(\n    [singleQuote, comment, multilineComment, uuid, hex, boolean, number],\n    'gi'\n  )),\n  unmatchedPairs(/'|\\/\\*|\\*\\//)\n]\n\ndialects.oracle = [\n  replacer(join(\n    [oracleQuote, singleQuote, comment, multilineComment, number],\n    'gi'\n  )),\n  unmatchedPairs(/'|\\/\\*|\\*\\//)\n]\n\nfunction obfuscate(raw, dialect) {\n  if (!dialects[dialect]) throw new Error('Unknown sql implementation')\n  var replacers = dialects[dialect]\n  var obfuscated = raw\n  for (var i = 0, l = replacers.length; i < l; ++i) {\n    obfuscated = replacers[i](obfuscated)\n  }\n\n  return obfuscated\n}\n\nfunction join(expressions, flags) {\n  return new RegExp(expressions.map(toPart).join('|'), flags)\n}\n\nfunction toPart(expressions) {\n  return expressions.toString().slice(1, -1)\n}\n\nfunction replacer(regex) {\n  return function replace(sql) {\n    return sql.replace(regex, '?')\n  }\n}\n\nfunction unmatchedPairs(regex) {\n  return function check(sql) {\n    return regex.test(sql) ? '?' : sql\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/util/codec.js":"'use strict'\n\nvar safeJSON = require('./safe-json')\nvar zlib = require('zlib')\n\nmodule.exports = {\n  /**\n   * Take in an object literal, and deflate and then Base64 encode it.\n   *\n   * zlib works with streams, so this must be used asynchronously.\n   *\n   * @param {object} data\n   *  The data to encode.\n   *\n   * @param {Function} callback\n   *  The callback to take the results. The first parameter is any errors from\n   *  encoding, and the second parameter is the encoded data object.\n   */\n  encode: function encode(data, callback) {\n    try {\n      zlib.deflate(safeJSON.stringifySync(data), function cb_deflate(err, raw) {\n        if (err) return callback(err)\n\n        return callback(null, raw.toString('base64'))\n      })\n    } catch (err) {\n      return callback(err)\n    }\n  },\n\n  /**\n   * Base64 decode a string, decompress it, and then turn the results back into\n   * a JavaScript object.\n   *\n   * zlib works with streams, so this must be used asynchronously.\n   *\n   * @param {object} encoded\n   *  The data to decode.\n   *\n   * @param {Function} callback\n   *  The callback to take the results. The first parameter is any errors from\n   *  decoding, and the second parameter is the decoded data object.\n   */\n  decode: function decode(encoded, callback) {\n    zlib.inflate(new Buffer(encoded, 'base64'), function cb_inflate(err, raw) {\n      if (err) return callback(err)\n\n      try {\n        return callback(null, JSON.parse(raw))\n      } catch (error) {\n        return callback(error)\n      }\n    })\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/environment.js":"'use strict'\n\nvar path = require('path')\nvar fs = require('fs')\nvar os = require('os')\nvar logger = require('../lib/logger').child({component: 'environment'})\nvar stringifySync = require('./util/safe-json').stringifySync\n\n\nvar exists = fs.existsSync || path.existsSync\n\n// As of 1.7.0 you can no longer dynamically link v8\n// https://github.com/nodejs/io.js/commit/d726a177ed\nvar remapping = {\n  node_install_npm: \"npm installed?\",\n  node_install_waf: \"WAF build system installed?\",\n  node_use_openssl: \"OpenSSL support?\",\n  node_shared_openssl: \"Dynamically linked to OpenSSL?\",\n  node_shared_v8: \"Dynamically linked to V8?\",\n  node_shared_zlib: \"Dynamically linked to Zlib?\",\n  node_use_dtrace: \"DTrace support?\",\n  node_use_etw: \"Event Tracing for Windows (ETW) support?\"\n}\n\nvar settings = {}\n\n/**\n * Fetches the setting of the given name, defaulting to an empty array.\n *\n * @param {string} name - The name of the setting to look for.\n *\n * @return {Array.<string>} An array of values matching that name.\n */\nfunction getSetting(name) {\n  return settings[name] || []\n}\n\n/**\n * Add a setting to the module's shared settings object.\n *\n * @param {string} name   - The name of the setting value being added.\n * @param {string} value  - The value to add or the setting.\n */\nfunction addSetting(name, value) {\n  if (!settings[name]) {\n    settings[name] = [value]\n  } else if (settings[name].indexOf(value) === -1) {\n    settings[name].push(value)\n  }\n}\n\n/**\n * Remove settings with the given name.\n *\n * @param {string} name - The name of the setting to remove.\n */\nfunction clearSetting(name) {\n  delete settings[name]\n}\n\n/**\n * Build up a list of top-level packages available to an application relative to\n * the provided root.\n *\n * @param {string}  root        - Path to start listing packages from.\n * @param {Array}   [packages]  - Array to append found packages to.\n *\n * @return {Array} List of packages.\n */\nfunction listPackages(root, packages) {\n  if (!packages) {\n    packages = []\n  }\n\n  try {\n    fs.readdirSync(root).forEach(function forEachReadDirSync(dir) {\n      // Skip npm's binary directory where it stores executables.\n      if (dir === '.bin') {\n        return\n      }\n\n      var version = null\n      try {\n        var pck = path.resolve(root, dir, 'package.json')\n        version = JSON.parse(fs.readFileSync(pck)).version\n      } catch (e) {\n        logger.debug('Could not load %s for environment scan', pck || dir)\n      }\n\n      packages.push([dir, version || '<unknown>'])\n    })\n  } catch (e) {\n    logger.trace(e, 'Failed to list packages in %s', root)\n  }\n\n  return packages\n}\n\n/**\n * Build up a list of dependencies from a given node_module root.\n *\n * @param {string}  root        - Path to start listing dependencies from.\n * @param {Array}   [children]  - Array to append found dependencies to.\n *\n * @return {Array} List of dependencies.\n */\nfunction listDependencies(root, children) {\n  if (!children) {\n    children = []\n  }\n\n  try {\n    fs.readdirSync(root).forEach(function forEachReadDirSync(entry) {\n      var candidate = path.resolve(root, entry, 'node_modules')\n\n      // Performing this exists check is cheaper than unwinding the stack for\n      // all the failed read attempts.\n      if (exists(candidate)) {\n        listPackages(candidate, children)\n        listDependencies(candidate, children)\n      }\n    })\n  } catch (e) {\n    logger.trace(e, 'Failed to list dependencies in %s', root)\n  }\n\n  return children\n}\n\n/**\n * Build up a list of packages, starting from the current directory.\n *\n * @param {string} start - Root directory to start generation from.\n *\n * @return {Object} Two lists, of packages and dependencies, with the\n *  appropriate names.\n */\nfunction getLocalPackages(start) {\n  var packages = []\n  var dependencies = []\n  var candidate = start\n\n  while (candidate) {\n    var root = path.resolve(candidate, 'node_modules')\n    listPackages(root, packages)\n    listDependencies(root, dependencies)\n\n    var last = candidate\n    candidate = path.dirname(candidate)\n    if (last === candidate) break\n  }\n\n  return {packages: packages, dependencies: dependencies}\n}\n\n/**\n * Generic method for getting packages and dependencies relative to a\n * provided root directory.\n *\n * @param {string} root - Where to start looking -- doesn't add node_modules.\n *\n * @return {Object} Two lists, of packages and dependencies, with the\n *  appropriate names.\n */\nfunction getPackages(root) {\n  var packages = []\n  var dependencies = []\n\n  listPackages(root, packages)\n  listDependencies(root, dependencies)\n\n  return {packages: packages, dependencies: dependencies}\n}\n\n/**\n * Generate a list of globally-installed packages, if available / accessible\n * via the environment.\n *\n * @return {Object} Two lists, of packages and dependencies, with the\n *  appropriate names.\n */\nfunction getGlobalPackages() {\n  if (process.config && process.config.variables) {\n    var prefix = process.config.variables.node_prefix\n    if (prefix) {\n      var root = path.resolve(prefix, 'lib', 'node_modules')\n      return getPackages(root)\n    }\n  }\n\n  return {packages: [], dependencies: []}\n}\n\n/**\n * Take a list of packages and reduce it to a list of pairs serialized\n * to JSON (to simplify things on the collector end) where each\n * package appears at most once, with all the versions joined into a\n * comma-delimited list.\n *\n * @return {Array.<String>[]} Sorted list of [name, version] pairs.\n */\nfunction flattenVersions(packages) {\n  var info = Object.create(null)\n  packages.forEach(function cb_forEach(pair) {\n    var p = pair[0]\n    var v = pair[1]\n\n\n    if (info[p]) {\n      if (info[p].indexOf(v) < 0) info[p].push(v)\n    } else {\n      info[p] = [v]\n    }\n  })\n\n  return Object.keys(info)\n    .map(function cb_map(key) {\n      return [key, info[key].join(', ')]\n    })\n    .sort()\n    .map(function cb_map(pair) {\n      return stringifySync(pair)\n    })\n}\n\n/**\n * There are a bunch of settings generated at build time that are useful to\n * know for troubleshooting purposes. These settings are only available in 0.7\n * and up.\n *\n * This function works entirely via side effects using the\n * addSetting function.\n */\nfunction remapConfigSettings() {\n  if (process.config && process.config.variables) {\n    var variables = process.config.variables\n    Object.keys(variables).forEach(function cb_forEach(key) {\n      if (remapping[key]) {\n        var value = variables[key]\n\n        if (value === true || value === 1) value = 'yes'\n        if (value === false || value === 0) value = 'no'\n\n        addSetting(remapping[key], value)\n      }\n    })\n  }\n}\n\n/**\n * Scrape the list of packages, following the algorithm as described in the\n * node module page:\n *\n * http://nodejs.org/docs/latest/api/modules.html\n *\n * This function works entirely via side effects using the addSetting\n * function.\n */\nfunction findPackages() {\n  var local = getLocalPackages(process.cwd())\n  var all = getGlobalPackages()\n  var other = {packages: [], dependencies: []}\n\n\n  if (process.env.NODE_PATH) {\n    var paths\n    if (process.platform === 'win32') { // why. WHY.\n      paths = process.env.NODE_PATH.split(';')\n    } else {\n      paths = process.env.NODE_PATH.split(':')\n    }\n\n    paths.forEach(function cb_forEach(nodePath) {\n      if (nodePath[0] !== '/') nodePath = path.resolve(process.cwd(), nodePath)\n      var nextSet = getPackages(nodePath)\n      other.packages.push.apply(other.packages, nextSet.packages)\n      other.dependencies.push.apply(other.dependencies, nextSet.dependencies)\n    })\n  }\n\n  var packages = local.packages\n  packages.push.apply(packages, all.packages)\n  packages.push.apply(packages, other.packages)\n\n  var dependencies = local.dependencies\n  dependencies.push.apply(dependencies, all.dependencies)\n  dependencies.push.apply(dependencies, other.dependencies)\n\n  var home\n  var homeOld\n\n  if (process.platform === 'win32') {\n    if (process.env.USERDIR) {\n      home = getPackages(path.resolve(process.env.USERDIR, '.node_modules'))\n      homeOld = getPackages(path.resolve(process.env.USERDIR, '.node_libraries'))\n    }\n  } else if (process.env.HOME) {\n    home = getPackages(path.resolve(process.env.HOME, '.node_modules'))\n    homeOld = getPackages(path.resolve(process.env.HOME, '.node_libraries'))\n  }\n\n  if (home) {\n    packages.unshift.apply(packages, home.packages)\n    dependencies.unshift.apply(dependencies, home.dependencies)\n  }\n\n  if (homeOld) {\n    packages.unshift.apply(packages, homeOld.packages)\n    dependencies.unshift.apply(dependencies, homeOld.dependencies)\n  }\n\n  addSetting('Packages', flattenVersions(packages))\n  addSetting('Dependencies', flattenVersions(dependencies))\n}\n\nfunction badOS() {\n  var badVersion = false\n\n  if (!process.versions) {\n    badVersion = true\n  } else {\n    var version = process.versions.node.split('.')\n    if (version[1] <= 8 && version[2] <= 5) badVersion = true\n  }\n\n  return badVersion &&\n         os.arch() === 'x64' &&\n         os.type() === 'SunOS'\n}\n\n/**\n * Settings actually get scraped below.\n */\nfunction gatherEnv() {\n  // in 64-bit SmartOS zones, node <= 0.8.5 pukes on os.cpus()\n  if (!badOS()) addSetting('Processors', os.cpus().length)\n\n  addSetting('OS', os.type())\n  addSetting('OS version', os.release())\n  addSetting('Node.js version', process.version)\n  addSetting('Architecture', process.arch)\n\n  if ('NODE_ENV' in process.env) {\n    addSetting('NODE_ENV', process.env.NODE_ENV)\n  }\n}\n\n/**\n * Reset settings and gather them, built to minimally refactor this file.\n */\nfunction refresh() {\n  // gather persisted settings\n  var framework = getSetting('Framework')\n  var dispatcher = getSetting('Dispatcher')\n  var packages = getSetting('Packages')\n  var dependencies = getSetting('Dependencies')\n\n  // clearing and rebuilding a global variable\n  settings = {}\n  // add persisted settings\n  if (framework.length) {\n    framework.forEach(function addFrameworks(fw) {\n      addSetting('Framework', fw)\n    })\n  }\n\n  if (dispatcher.length) {\n    dispatcher.forEach(function addDispatchers(d) {\n      addSetting('Dispatcher', d)\n    })\n  }\n\n  gatherEnv()\n  remapConfigSettings()\n\n  if (packages.length && dependencies.length) {\n    settings.Packages = packages\n    settings.Dependencies = dependencies\n  } else {\n    findPackages()\n  }\n}\n\n// initialize settings\n// TODO:  Remove this function call and make all environment loading async. At\n//        the moment, removing this causes tests to fail and it is unclear if it\n//        is an issue in the tests or in the agent.\nrefresh()\n\n/**\n * Refreshes settings and returns the settings object.\n */\nfunction toJSON() {\n  // TODO:  Do not refresh when JSON-ifying. This takes a _long_ time and blocks\n  //        the event loop. Currently, removing this causes a couple of tests to\n  //        fail (ironically from timing out).\n  refresh()\n  var items = []\n  Object.keys(settings).forEach(function settingKeysForEach(key) {\n    settings[key].forEach(function settingsValuesForEach(setting) {\n      items.push([key, setting])\n    })\n  })\n\n  return items\n}\n\nmodule.exports = {\n  setFramework: function setFramework(framework) {\n    addSetting('Framework', framework)\n  },\n  setDispatcher: function setDispatcher(dispatcher) {\n    addSetting('Dispatcher', dispatcher)\n  },\n  clearFramework: function clearFramework() {\n    clearSetting('Framework')\n  },\n  clearDispatcher: function clearDispatcher() {\n    clearSetting('Dispatcher')\n  },\n  listPackages: listPackages,\n  toJSON: toJSON,\n  get: getSetting,\n  refresh: refresh\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/lib/shimmer.js":"'use strict'\n\nvar path = require('path')\nvar fs = require('fs')\nvar logger = require('./logger').child({component: 'shimmer'})\nvar INSTRUMENTATION = require('./instrumentations')()\n\n/*\n *\n * CONSTANTS\n *\n */\n\nvar CORE_INSTRUMENTATION = {\n  child_process: 'child_process.js',\n  crypto: 'crypto.js',\n  domain: 'domain.js',\n  dns: 'dns.js',\n  fs: 'fs.js',\n  http: 'http.js',\n  https: 'http.js',\n  net: 'net.js',\n  timers: 'timers.js',\n  zlib: 'zlib.js'\n}\n\n/**\n * Unwrapping is only likely to be used by test code, and is a fairly drastic\n * maneuver, but it should be pretty safe if there's a desire to reboot the\n * agent in flight.\n *\n * All of the wrapped methods are tracked in this variable and used by unwrapAll\n * below.\n */\nvar instrumented = []\n\n/**\n * All instrumentation files must export the same interface: a single\n * initialization function that takes the agent and the module to be\n * instrumented.\n */\nfunction instrument(agent, shortName, fileName, nodule, moduleName) {\n  var fullPath = path.resolve(fileName)\n  if (!fs.existsSync(fileName)) {\n    return logger.warn(\n      'Tried to load instrumentation from %s, but file does not exist',\n      fullPath\n    )\n  }\n  try {\n    require(fileName)(agent, nodule, moduleName)\n  } catch (error) {\n    logger.warn(\n      error,\n      'Failed to instrument module %s using %s',\n      path.basename(shortName, '.js'),\n      fullPath\n    )\n  }\n}\n\nfunction _postLoad(agent, nodule, name) {\n  var instrumentation\n  var base = path.basename(name)\n\n  // to allow for instrumenting both 'pg' and 'pg.js'.\n  if (name === 'pg.js') {\n    instrumentation = 'pg'\n  } if (name === 'mysql2') {\n    // mysql2 (https://github.com/sidorares/node-mysql2) is a drop in replacement for\n    // mysql which conforms to the existing mysql API. If we see mysql2, treat it as\n    // mysql\n    instrumentation = 'mysql'\n  } else {\n    instrumentation = base\n  }\n\n  // necessary to prevent instrument() from causing an infinite loop\n  if (INSTRUMENTATION.indexOf(instrumentation) !== -1) {\n    logger.trace('Instrumenting %s.', base)\n    var filename = path.join(__dirname, 'instrumentation', instrumentation + '.js')\n    instrument(agent, base, filename, nodule)\n  }\n\n  return nodule\n}\n\nvar shimmer = module.exports = {\n  /**\n   * If debug isn't false, the agent will retain references to wrapped methods\n   * for the entire lifetime of the agent. Some instrumentation depends on\n   * wrapping functions on individual objects, and this will cause the agent\n   * to retain references to a large number of dead objects.\n   */\n  debug: false,\n\n  /**\n   * Detects if the given function has already been wrapped.\n   *\n   * @param {function} fn - The function to look for a wrapper on.\n   *\n   * @return {bool} True if `fn` exists and has an attached original, else false.\n   */\n  isWrapped: function isWrapped(fn) {\n    return !!(fn && fn.__NR_original)\n  },\n\n  /**\n   * Don't throw, but do log and bail out if wrapping fails.\n   *\n   * Provide an escape hatch by creating a closure around the original method\n   * and object / module wrapped into a helper function that will restore the\n   * original function / method. See Sinon for a systematic use of this\n   * pattern.\n   *\n   * @param {object} nodule Class or module containing the function to wrap.\n   * @param {object} noduleName Human-readable module / Class name. More\n   *                            helpful than you'd think.\n   * @param {string} methods One or more names of methods or functions to extract\n   *                         and wrap.\n   * @param {function} wrapper A generator that, when called, returns a\n   *                           wrapped version of the original function.\n   */\n  wrapMethod: function wrapMethod(nodule, noduleName, methods, wrapper) {\n    if (!methods) {\n      return logger.warn(new Error(),\n                         \"Must include a method name to wrap. Called from:\")\n    }\n\n    if (!noduleName) noduleName = '[unknown]'\n    if (!Array.isArray(methods)) methods = [methods]\n\n    methods.forEach(function cb_forEach(method) {\n      var fqmn = noduleName + '.' + method\n\n      if (!nodule) return logger.debug(\"Can't wrap %s from nonexistent object.\",\n                                       fqmn)\n      if (!wrapper) return logger.debug(\"Can't wrap %s without a wrapper generator.\",\n                                        fqmn)\n\n      var original = nodule[method]\n\n      if (!original) return logger.trace(\"%s not defined, so not wrapping.\", fqmn)\n      if (original.__NR_unwrap) return logger.debug(\"%s already wrapped by agent.\", fqmn)\n\n      var wrapped = wrapper(original, method)\n      wrapped.__NR_original = original\n      wrapped.__NR_unwrap = function __NR_unwrap() {\n        nodule[method] = original\n        logger.trace(\"Removed instrumentation from %s.\", fqmn)\n      }\n\n      nodule[method] = wrapped\n      if (shimmer.debug) instrumented.push(wrapped)\n      logger.trace(\"Instrumented %s.\", fqmn)\n    })\n  },\n\n  /**\n   * Sometimes you gotta do some crazy stuff to get the job done. Instead of using\n   * regular monkeypatching, wrapDeprecated allows you to pass in a getter and setter\n   * and then uses defineProperty to replace the original property with an\n   * accessor. Note that responsibility for unwrapping is not handled by this\n   * function.\n   *\n   * @param {object}   nodule     Class or module containing the property to\n   *                              wrap.\n   * @param {object}   noduleName Human-readable module / Class name. More\n   *                              helpful than you'd think.\n   * @param {string}   property   The property to replace with the accessor.\n   * @param {function} options    Optional getter and setter to use for the accessor.\n   *\n   * @returns {object} The original value of the property.\n   */\n  wrapDeprecated: function wrapDeprecated(nodule, noduleName, property, options) {\n    if (!property) {\n      logger.warn(new Error(), \"Must include a function name to wrap. Called from:\")\n      return\n    }\n\n    if (!noduleName) noduleName = '[unknown]'\n\n    var fqmn = noduleName + '.' + property\n    if (!nodule) {\n      logger.debug(\"Can't wrap %s from nonexistent object.\", fqmn)\n      return\n    }\n\n    var original = nodule[property]\n    if (!original) {\n      logger.trace(\"%s not defined, so not wrapping.\", fqmn)\n      return\n    }\n\n    delete nodule[property]\n\n    var descriptor = {\n      configurable: true,\n      enumerable: true\n    }\n    if (options.get) descriptor.get = options.get\n    if (options.set) descriptor.set = options.set\n    Object.defineProperty(nodule, property, descriptor)\n    logger.trace(\"Instrumented %s.\", fqmn)\n\n    if (shimmer.debug) {\n      instrumented.push({\n        __NR_unwrap: function unwrapDeprecated() {\n          delete nodule[property]\n          nodule[property] = original\n        }\n      })\n    }\n\n    return original\n  },\n\n  unwrapMethod: function unwrapMethod(nodule, noduleName, method) {\n    if (!noduleName) noduleName = '[unknown]'\n    if (!method) return logger.debug(\"Must include a method name to unwrap. \" +\n                                     \"Called from: %s\", new Error().stack)\n\n    var fqmn = noduleName + '.' + method\n\n    if (!nodule) return logger.debug(\"Can't unwrap %s from nonexistent object.\",\n                                     fqmn)\n    var wrapped = nodule[method]\n\n    // keep instrumented up to date\n    var pos = instrumented.indexOf(wrapped)\n    if (pos !== -1) instrumented.splice(pos, 1)\n\n    if (!wrapped) return logger.debug(\"%s not defined, so not unwrapping.\", fqmn)\n    if (!wrapped.__NR_unwrap) return logger.debug(\"%s isn't unwrappable.\", fqmn)\n\n    wrapped.__NR_unwrap()\n  },\n\n  unwrapAll: function unwrapAll() {\n    instrumented.forEach(function cb_forEach(wrapper) {\n      wrapper.__NR_unwrap()\n    })\n    instrumented = []\n  },\n\n  /**\n   * Patch the module.load function so that we see modules loading and\n   * have an opportunity to patch them with instrumentation.\n   */\n  patchModule: function patchModule(agent) {\n    logger.trace(\"Wrapping module loader.\")\n    var Module = require('module')\n\n    shimmer.wrapMethod(Module, 'Module', '_load', function cb_wrapMethod(load) {\n      return function cls_wrapMethod(file) {\n        return _postLoad(agent, load.apply(this, arguments), file)\n      }\n    })\n  },\n\n  unpatchModule: function unpatchModule() {\n    logger.trace(\"Unwrapping to previous module loader.\")\n    var Module = require('module')\n\n    shimmer.unwrapMethod(Module, 'Module', '_load')\n  },\n\n  bootstrapInstrumentation: function bootstrapInstrumentation(agent) {\n    var globalsFilepath = path.join(__dirname, 'instrumentation', 'core', 'globals.js')\n    instrument(agent, 'globals', globalsFilepath, global)\n\n    Object.keys(CORE_INSTRUMENTATION).forEach(function cb_forEach(mojule) {\n      var filename = CORE_INSTRUMENTATION[mojule]\n      var filepath = path.join(__dirname, 'instrumentation/core', filename)\n      var uninstrumented\n\n      try {\n        uninstrumented = require(mojule)\n      } catch (err) {\n        logger.trace(\n          'Could not load core module %s got error %s',\n          mojule,\n          err\n        )\n      }\n\n      instrument(agent, filename, filepath, uninstrumented, mojule)\n    })\n  },\n\n  /**\n   * NOT FOR USE IN PRODUCTION CODE\n   *\n   * If an instrumented module has a dependency on another instrumented module,\n   * and multiple tests are being run in a single test suite with their own\n   * setup and teardown between tests, it's possible transitive dependencies\n   * will be unwrapped in the module cache in-place (which needs to happen to\n   * prevent stale closures from channeling instrumentation data to incorrect\n   * agents, but which means the transitive dependencies won't get re-wrapped\n   * the next time the parent module is required).\n   *\n   * Since this only applies in test code, it's not worth the drastic\n   * monkeypatching to Module necessary to walk the list of child modules and\n   * re-wrap them.\n   *\n   * Use this to re-apply any applicable instrumentation.\n   */\n  reinstrument: function reinstrument(agent, modulePath) {\n    return _postLoad(agent, require(modulePath), modulePath)\n  }\n}\n","/home/travis/build/npmtest/node-npmtest-newrelic/node_modules/newrelic/newrelic.js":"'use strict'\n\n/**\n * New Relic agent configuration.\n *\n * See lib/config.defaults.js in the agent distribution for a more complete\n * description of configuration variables and their potential values.\n */\nexports.config = {\n  /**\n   * Array of application names.\n   */\n  app_name: ['My Application'],\n  /**\n   * Your New Relic license key.\n   */\n  license_key: 'license key here',\n  logging: {\n    /**\n     * Level at which to log. 'trace' is most useful to New Relic when diagnosing\n     * issues with the agent, 'info' and higher will impose the least overhead on\n     * production applications.\n     */\n    level: 'info'\n  }\n}\n"}